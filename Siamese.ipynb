{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn    \n",
    "    \n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.nn.functional import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 406\u001b[0m\n\u001b[1;32m    395\u001b[0m             torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSiam_cell_new.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    397\u001b[0m \u001b[38;5;66;03m# Usage:\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;66;03m#data = ... # Load your ground truth data here, for instance as a Pandas DataFrame\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# '/home/mo/Desktop/IWR/TimeGraph2.0/dot_folder/'\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;66;03m#for folder in os.listdir(root_dir):\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;66;03m#    print(folder, os.listdir(os.path.join(root_dir, folder)))\u001b[39;00m\n\u001b[0;32m--> 406\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mstop\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "\n",
    "        # Define the CNN backbone (shared for both inputs)\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(32, 16, 3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2)\n",
    "        )\n",
    "\n",
    "        # Fully connected layer for similarity\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(144, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 64)\n",
    "           # Binary classification: Similar (1) or Not Similar (0)\n",
    "        )\n",
    "\n",
    "    def forward_one(self, x):\n",
    "        # Forward pass for one input\n",
    "        x = self.backbone(x)\n",
    "        \n",
    "        x = x.view(x.size()[0], -1)\n",
    "        #print('x',x.size())\n",
    "        x=self.fc(x) # Flatten\n",
    "        return x\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        # Forward pass for both inputs\n",
    "        output1 = self.forward_one(input1)\n",
    "        output2 = self.forward_one(input2)\n",
    "        \n",
    "        #print('out1',output1.size())\n",
    "        \n",
    "        # Compute the cosine similarity between the two embeddings.\n",
    "        cos_sim = cosine_similarity(output1, output2, dim=1, eps=1e-6)\n",
    "        cos_sim = cos_sim.unsqueeze(1)  # Add an extra dimension to match the shape required for the fc layer.\n",
    "        #print('cos_sim',cos_sim,cos_sim.size())\n",
    "        # Similarity prediction\n",
    "        #similarity = self.fc(cos_sim)\n",
    "        prob_sim = torch.sigmoid(cos_sim)\n",
    "        return prob_sim\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        # Method to get the embedding of a single image\n",
    "        return self.forward_one(x)\n",
    "    \n",
    "class CellTrackingDataset(Dataset):\n",
    "    def __init__(self, root_dir, window,transform=None):\n",
    "        # Load all TXT files in root_dir into a list of dataframes\n",
    "        all_dfs = []\n",
    "        for folder in os.listdir(root_dir):\n",
    "            print('folder',folder)\n",
    "            # Check if the folder's name ends with '_GT'\n",
    "            if folder.endswith(\"_GT\"):#folder=='1_GT': #!!!!!!!!\n",
    "                file_path = os.path.join(root_dir, folder, 'TRA','pos_GT.txt')\n",
    "                print('file_path',file_path)\n",
    "                # Check if 'pos_GT.txt' actually exists in the folder\n",
    "                if os.path.exists(file_path):\n",
    "                    print('file', file_path)\n",
    "                    run = int(folder.split('_')[0])  # extract run number from folder name\n",
    "                    print('run', run)\n",
    "                    df = pd.read_csv(file_path, delimiter='\\t', skiprows=1, \n",
    "                                     names=['x', 'y', 'r', 'id', 'split_id', 's_prob', 't'])\n",
    "                    df['run'] = run  # Add a run column\n",
    "                    all_dfs.append(df)\n",
    "\n",
    "        self.data = pd.concat(all_dfs, ignore_index=True)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.window=window\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # TODO: Implement logic to decide positive or negative pair\n",
    "        # For example, 50% of the time it returns positive pairs, and 50% negative pairs\n",
    "        positive_sample = np.random.choice([True, False])\n",
    "\n",
    "        if positive_sample:\n",
    "            # Load two consecutive frames of the same cell\n",
    "            #print(\"IDX:\", idx, \"DATA LENGTH:\", len(self.data), self.data.iloc[idx])\n",
    "            frame_t, frame_t_plus_1 = self._load_consecutive_frames(self.data.iloc[idx])\n",
    "            label = torch.tensor([1.0])\n",
    "        else:\n",
    "            # Load frames of two different cells (from consecutive frames)\n",
    "            #print(\"IDX:\", idx, \"DATA LENGTH:\", len(self.data), self.data.iloc[idx])\n",
    "            frame_t, frame_t_plus_1 = self._load_different_cells_frames(self.data.iloc[idx])\n",
    "            label = torch.tensor([0.0])\n",
    "\n",
    "        return (frame_t, frame_t_plus_1), label\n",
    "\n",
    "    def _load_consecutive_frames(self, row):\n",
    "        # Find the next frame's cell that has either the same 'id' \n",
    "        # or has 'split_id' matching the current 'id'\n",
    "        if row['id'] ==-1 or row['id']==-2:\n",
    "            same_cell_or_daughter = self.data[(self.data['run'] == row['run']) & \n",
    "                                          ((self.data['id'] == row['id']) | \n",
    "                                           (self.data['split_id'] == row['id'])|\n",
    "                                           (self.data['id'] == row['split_id']))]\n",
    "        else:\n",
    "            same_cell_or_daughter = self.data[(self.data['t'] == row['t'] + 1) & \n",
    "                                              (self.data['run'] == row['run']) & \n",
    "                                              ((self.data['id'] == row['id']) | \n",
    "                                               (self.data['split_id'] == row['id']))]\n",
    "\n",
    "        if not same_cell_or_daughter.empty:\n",
    "            next_frame_same_cell = same_cell_or_daughter.sample(n=1).iloc[0]\n",
    "            frame_t_plus_1 = self._load_frame(next_frame_same_cell)\n",
    "        else:\n",
    "            # Handle the scenario when no such cell exists in the next frame\n",
    "            frame_t_plus_1 = torch.zeros_like(self._load_frame(row))  # Placeholder, modify as needed\n",
    "\n",
    "        frame_t = self._load_frame(row)\n",
    "\n",
    "        return frame_t, frame_t_plus_1\n",
    "\n",
    "    def _load_different_cells_frames(self, row):\n",
    "        # Find another cell from the next frame but within the same run \n",
    "        # and is not a daughter cell (i.e., its 'split_id' doesn't match the current cell's 'id')\n",
    "        \n",
    "        if row['id'] ==-1:\n",
    "            next_frame_data = self.data[(self.data['run'] == row['run']) & \n",
    "                                        (self.data['split_id'] != row['id'])]\n",
    "        else:\n",
    "             next_frame_data = self.data[(self.data['t'] == row['t'] + 1) & \n",
    "                                        (self.data['run'] == row['run']) & \n",
    "                                        (self.data['split_id'] != row['id'])]\n",
    "            \n",
    "\n",
    "        # Ensure that you're getting a different cell, but from the same run\n",
    "        different_cell = next_frame_data[next_frame_data['id'] != row['id']]\n",
    "\n",
    "        if not different_cell.empty:\n",
    "            different_cell_row = different_cell.sample(n=1).iloc[0]\n",
    "            frame_t_plus_1 = self._load_frame(different_cell_row)\n",
    "        else:\n",
    "            # Handle the scenario when no different cell exists in t+1 frame\n",
    "            frame_t_plus_1 = torch.zeros_like(self._load_frame(row))  # Placeholder, modify as needed\n",
    "\n",
    "        frame_t = self._load_frame(row)\n",
    "\n",
    "        return frame_t, frame_t_plus_1\n",
    "    def _load_frame(self, row):\n",
    "        # Extract position and run from the row\n",
    "        pos_x, pos_y, run, t = row['x'], row['y'], row['run'], row['t']\n",
    "        # Using the fingerprint_cnn function to get the tensor\n",
    "        im_tens = fingerprint_cnn(pos_x, pos_y, self.window, t, run,path0=self.root_dir)\n",
    "        return im_tens\n",
    "    \n",
    "def fingerprint_cnn(pos_x,pos_y,window,t,run,void_node=False,a_x=113.89266922,b_x=19.51478307,a_y=-114.14194117,b_y=131.3404747,path0='.'):\n",
    "    v_flag=False\n",
    "    if pos_x==2:\n",
    "        #print('void')\n",
    "        #pos_x = 0.5\n",
    "        #pos_y = 0.5\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        pathm1=path0+'void.png'\n",
    "        path=path0+'void.png'\n",
    "        pathp1=path0+'void.png'\n",
    "        v_flag=True\n",
    "        \n",
    "    else:\n",
    "        pathm1=path0+str(int(run))+'/'+str(int(t-1))+'.png'\n",
    "        path=path0+str(int(run))+'/'+str(int(t))+'.png'\n",
    "        pathp1=path0+str(int(run))+'/'+str(int(t+1))+'.png'\n",
    "\n",
    "\n",
    "    x_l,x_r,y_l,y_u=calibrate_pix_pos(pos_x,pos_y,a_x,b_x,a_y,b_y,window)\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "    im = Image.open(path).convert('L')\n",
    "    shape = np.asarray(im).shape\n",
    "    try:\n",
    "        im_m = Image.open(pathm1).convert('L')\n",
    "    except:\n",
    "        pix=255*np.ones(shape)\n",
    "        im_m = Image.fromarray(pix).convert('L')\n",
    "    try:\n",
    "        im_p = Image.open(pathp1).convert('L')\n",
    "    except:\n",
    "        pix=255*np.ones(shape)\n",
    "        im_p = Image.fromarray(pix).convert('L')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if v_flag:\n",
    "        im_crop = im\n",
    "        im_m_crop = im_m\n",
    "        im_p_crop = im_p\n",
    "    else:\n",
    "        im_crop = im.crop((x_l, y_l, x_r, y_u))\n",
    "        im_m_crop = im_m.crop((x_l, y_l, x_r, y_u))\n",
    "        im_p_crop = im_p.crop((x_l, y_l, x_r, y_u))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #if t==9 and run==95:\n",
    "    #    im_crop.show()\n",
    "\n",
    "\n",
    "    im_crop = im_crop.resize((20,20),Image.ANTIALIAS)\n",
    "    im_m_crop = im_m_crop.resize((20,20),Image.ANTIALIAS)\n",
    "    im_p_crop = im_p_crop.resize((20,20),Image.ANTIALIAS)\n",
    "\n",
    "    imarray = np.asarray(im_crop)\n",
    "    #print('shape',imarray.shape)\n",
    "    im_m_array = np.asarray(im_m_crop)\n",
    "    im_p_array = np.asarray(im_p_crop)\n",
    "\n",
    "\n",
    "    im_tens=torch.zeros(3, 20,20)\n",
    "\n",
    "\n",
    "    convert_tensor = transforms.ToTensor()\n",
    "    im_tens[1]=convert_tensor(imarray)\n",
    "    im_tens[0]=convert_tensor(im_m_array)\n",
    "    im_tens[2]=convert_tensor(im_p_array)\n",
    "    \n",
    "    #if v_flag:\n",
    "    #    plt.imshow(im_tens.numpy().transpose(1, 2, 0))\n",
    "\n",
    "    return im_tens\n",
    "\n",
    "def calibrate_pix_pos(pos_x,pos_y,a_x,b_x,a_y,b_y,window):\n",
    "    #pix_x0=int(fit_func(pos_x,a_x,b_x))\n",
    "    #pix_y0 = pos_x* 512\n",
    "    #pix_x0 = (1-pos_y) * 512\n",
    "    pix_x0 = pos_x* 512\n",
    "    pix_y0 = (1-pos_y) * 512\n",
    "    #pix_y0=int(fit_func(pos_y,a_y,b_y))\n",
    "    #print(pix_x0,pix_y0,int(pix_x0-window))\n",
    "    return int(pix_x0-window),int(pix_x0+window),int(pix_y0-window),int(pix_y0+window)\n",
    "\n",
    "\n",
    "def imshow(img1, img2, label):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    # Assuming images are normalized pytorch tensors, convert them to numpy and de-normalize if necessary\n",
    "    ax1.imshow(img1[0].numpy().transpose(1, 2, 0))\n",
    "    ax2.imshow(img2[0].numpy().transpose(1, 2, 0))\n",
    "    \n",
    "    # Display the label\n",
    "    fig.suptitle(f\"Label: {label.item()}\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def fit_func(x,a,b):\n",
    "    return a*x+b\n",
    "\n",
    "\n",
    "def extract_embeddings_subset(dataloader, model):\n",
    "    model.eval()\n",
    "    \n",
    "    embeddings = np.zeros((20, 64))\n",
    "    labels = np.zeros(20)\n",
    "    k = 0\n",
    "    positive_count, negative_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (input1, input2), batch_targets in dataloader:\n",
    "            for idx, label in enumerate(batch_targets):  # Iterate through each label in the batch\n",
    "                if label.item() == 1.0 and positive_count < 5:\n",
    "                    embeddings[k] = model.get_embedding(input1[idx].unsqueeze(0)).data.cpu().numpy()\n",
    "                    embeddings[k+1] = model.get_embedding(input2[idx].unsqueeze(0)).data.cpu().numpy()\n",
    "                    labels[k] = 1.0\n",
    "                    labels[k+1] = 1.0\n",
    "                    k += 2\n",
    "                    positive_count += 1\n",
    "\n",
    "                elif label.item() == 0.0 and negative_count < 5:\n",
    "                    embeddings[k] = model.get_embedding(input1[idx].unsqueeze(0)).data.cpu().numpy()\n",
    "                    embeddings[k+1] = model.get_embedding(input2[idx].unsqueeze(0)).data.cpu().numpy()\n",
    "                    labels[k] = 0.0\n",
    "                    labels[k+1] = 0.0\n",
    "                    k += 2\n",
    "                    negative_count += 1\n",
    "\n",
    "                if positive_count >= 5 and negative_count >= 5:\n",
    "                    break\n",
    "\n",
    "    return embeddings, labels\n",
    "\n",
    "def plot_embeddings(embeddings, labels, title=''):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    colors = ['blue' if label == 1.0 else 'red' for label in labels]\n",
    "    \n",
    "    for i in range(0, len(labels), 2):  # We are skipping every second one because we know they come in pairs\n",
    "        plt.plot(embeddings[i:i+2, 0], embeddings[i:i+2, 1], '-o', c=colors[i], mfc='white') # Line between pair\n",
    "        \n",
    "    plt.scatter(embeddings[:, 0], embeddings[:, 1], c=colors, s=60, edgecolors='w')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def visualize_tsne_pca(dataloader, model):\n",
    "    embeddings, labels = extract_embeddings_subset(dataloader, model)\n",
    "    embeddings_tsne = TSNE(n_components=2, perplexity=5).fit_transform(embeddings)  # Adjusted perplexity here\n",
    "    embeddings_pca = PCA(n_components=2).fit_transform(embeddings)\n",
    "    plot_embeddings(embeddings_tsne, labels, title=\"t-SNE visualization of embeddings\")\n",
    "    plot_embeddings(embeddings_pca, labels, title=\"PCA visualization of embeddings\")\n",
    "\n",
    "def train_one_epoch(model, dataloader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for (input1, input2), labels in dataloader:\n",
    "        #imshow(input1, input2, labels[0])\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input1, input2).squeeze()\n",
    "        #print('out',outputs)\n",
    "\n",
    "        predicted_labels = (outputs > 0.5).float()\n",
    "        correct_predictions += (predicted_labels == labels.squeeze()).float().sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "        outputs = torch.clamp(outputs, min=1e-7, max=1-1e-7)\n",
    "        #print('out',outputs)\n",
    "        \n",
    "        loss = F.binary_cross_entropy(outputs, labels.squeeze())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    epoch_accuracy = 100 * correct_predictions / total_samples\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss, epoch_accuracy\n",
    "\n",
    "def validate(model, dataloader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for (input1, input2), labels in dataloader:\n",
    "            outputs = model(input1, input2).squeeze()\n",
    "            predicted_labels = (outputs > 0.8).float()\n",
    "            correct_predictions += (predicted_labels == labels.squeeze()).float().sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "            outputs = torch.clamp(outputs, min=1e-7, max=1-1e-7)\n",
    "            loss = F.binary_cross_entropy(outputs, labels.squeeze())\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "    epoch_accuracy = 100 * correct_predictions / total_samples\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss, epoch_accuracy\n",
    "\n",
    "def main():\n",
    "    win = 115\n",
    "    root_dir_train = '/media/mo/Label/HeLa_2_track_train/'\n",
    "    train_dataset = CellTrackingDataset(root_dir_train,window=win)\n",
    "    root_dir_test = '/media/mo/Label/HeLa_2_track_test/'\n",
    "    test_dataset = CellTrackingDataset(root_dir_test,window=win)\n",
    "    \n",
    "    # Split the dataset into train and test\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    model = SiameseNetwork()\n",
    "    model.load_state_dict(torch.load('Siam_cell_new.pt'))\n",
    "    optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    num_epochs = 10\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_accuracy = train_one_epoch(model, train_dataloader, optimizer)\n",
    "        val_loss,test_accuracy = validate(model, test_dataloader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Val Loss: {val_loss:.4f}, Test Accuracy:{test_accuracy:.2f}%\")\n",
    "\n",
    "        # Save checkpoint with minimal validation loss\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'Siam_cell_new.pt')\n",
    "    \n",
    "# Usage:\n",
    "#data = ... # Load your ground truth data here, for instance as a Pandas DataFrame\n",
    "# '/home/mo/Desktop/IWR/TimeGraph2.0/dot_folder/'\n",
    "#import os\n",
    "\n",
    "#for folder in os.listdir(root_dir):\n",
    "#    print(folder, os.listdir(os.path.join(root_dir, folder)))\n",
    "\n",
    "\n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "root_dir = '/media/mo/Label/HeLa_track/'\n",
    "\n",
    "dataset = CellTrackingDataset(root_dir)\n",
    "model = SiameseNetwork()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for (input1, input2), labels in dataloader:\n",
    "        #print(input1.shape)\n",
    "        imshow(input1, input2, labels[0])\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        \n",
    "        outputs = model(input1, input2).squeeze()\n",
    "        \n",
    "        # Convert the continuous valued outputs to binary predictions\n",
    "        predicted_labels = (outputs > 0.5).float()\n",
    "        correct_predictions += (predicted_labels == labels.squeeze()).float().sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = F.binary_cross_entropy(outputs, labels.squeeze())\n",
    "        \n",
    "        # Backpropagation and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    epoch_accuracy = 100 * correct_predictions / total_samples\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(dataloader)}, Accuracy: {epoch_accuracy:.2f}%\")\n",
    "torch.save(model.state_dict(), 'Siam_cell.pt')\n",
    "visualize_tsne_pca(dataloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder 10\n",
      "folder 19\n",
      "folder 29\n",
      "folder 38\n",
      "folder 61\n",
      "folder 1\n",
      "folder 10_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/10_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/10_GT/TRA/pos_GT.txt\n",
      "run 10\n",
      "folder 11\n",
      "folder 11_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/11_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/11_GT/TRA/pos_GT.txt\n",
      "run 11\n",
      "folder 12\n",
      "folder 12_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/12_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/12_GT/TRA/pos_GT.txt\n",
      "run 12\n",
      "folder 13\n",
      "folder 13_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/13_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/13_GT/TRA/pos_GT.txt\n",
      "run 13\n",
      "folder 14\n",
      "folder 14_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/14_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/14_GT/TRA/pos_GT.txt\n",
      "run 14\n",
      "folder 15\n",
      "folder 15_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/15_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/15_GT/TRA/pos_GT.txt\n",
      "run 15\n",
      "folder void.png\n",
      "folder 17\n",
      "folder 17_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/17_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/17_GT/TRA/pos_GT.txt\n",
      "run 17\n",
      "folder 18\n",
      "folder 18_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/18_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/18_GT/TRA/pos_GT.txt\n",
      "run 18\n",
      "folder 19_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/19_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/19_GT/TRA/pos_GT.txt\n",
      "run 19\n",
      "folder 2\n",
      "folder 1_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/1_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/1_GT/TRA/pos_GT.txt\n",
      "run 1\n",
      "folder 20\n",
      "folder 20_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/20_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/20_GT/TRA/pos_GT.txt\n",
      "run 20\n",
      "folder 21\n",
      "folder 21_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/21_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/21_GT/TRA/pos_GT.txt\n",
      "run 21\n",
      "folder 22\n",
      "folder 22_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/22_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/22_GT/TRA/pos_GT.txt\n",
      "run 22\n",
      "folder 23\n",
      "folder 23_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/23_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/23_GT/TRA/pos_GT.txt\n",
      "run 23\n",
      "folder 24\n",
      "folder 24_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/24_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/24_GT/TRA/pos_GT.txt\n",
      "run 24\n",
      "folder 25\n",
      "folder 25_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/25_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/25_GT/TRA/pos_GT.txt\n",
      "run 25\n",
      "folder 26\n",
      "folder 26_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/26_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/26_GT/TRA/pos_GT.txt\n",
      "run 26\n",
      "folder 28\n",
      "folder 27\n",
      "folder 27_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/27_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/27_GT/TRA/pos_GT.txt\n",
      "run 27\n",
      "folder 28_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/28_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/28_GT/TRA/pos_GT.txt\n",
      "run 28\n",
      "folder 29_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/29_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/29_GT/TRA/pos_GT.txt\n",
      "run 29\n",
      "folder 2_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/2_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/2_GT/TRA/pos_GT.txt\n",
      "run 2\n",
      "folder 3\n",
      "folder 31\n",
      "folder 31_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/31_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/31_GT/TRA/pos_GT.txt\n",
      "run 31\n",
      "folder 32\n",
      "folder 32_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/32_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/32_GT/TRA/pos_GT.txt\n",
      "run 32\n",
      "folder 33\n",
      "folder 33_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/33_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/33_GT/TRA/pos_GT.txt\n",
      "run 33\n",
      "folder 35\n",
      "folder 35_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/35_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/35_GT/TRA/pos_GT.txt\n",
      "run 35\n",
      "folder 36_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/36_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/36_GT/TRA/pos_GT.txt\n",
      "run 36\n",
      "folder 37\n",
      "folder 36\n",
      "folder 37_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/37_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/37_GT/TRA/pos_GT.txt\n",
      "run 37\n",
      "folder 38_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/38_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/38_GT/TRA/pos_GT.txt\n",
      "run 38\n",
      "folder 39\n",
      "folder 39_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/39_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/39_GT/TRA/pos_GT.txt\n",
      "run 39\n",
      "folder 3_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/3_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/3_GT/TRA/pos_GT.txt\n",
      "run 3\n",
      "folder 4\n",
      "folder 40\n",
      "folder 40_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/40_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/40_GT/TRA/pos_GT.txt\n",
      "run 40\n",
      "folder 41\n",
      "folder 41_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/41_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/41_GT/TRA/pos_GT.txt\n",
      "run 41\n",
      "folder 42\n",
      "folder 42_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/42_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/42_GT/TRA/pos_GT.txt\n",
      "run 42\n",
      "folder 43\n",
      "folder 43_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/43_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/43_GT/TRA/pos_GT.txt\n",
      "run 43\n",
      "folder 45\n",
      "folder 45_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/45_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/45_GT/TRA/pos_GT.txt\n",
      "run 45\n",
      "folder 46\n",
      "folder 46_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/46_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/46_GT/TRA/pos_GT.txt\n",
      "run 46\n",
      "folder 47\n",
      "folder 47_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/47_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/47_GT/TRA/pos_GT.txt\n",
      "run 47\n",
      "folder 48\n",
      "folder 48_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/48_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/48_GT/TRA/pos_GT.txt\n",
      "run 48\n",
      "folder 49\n",
      "folder 49_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/49_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/49_GT/TRA/pos_GT.txt\n",
      "run 49\n",
      "folder 4_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/4_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/4_GT/TRA/pos_GT.txt\n",
      "run 4\n",
      "folder 5\n",
      "folder 50\n",
      "folder 50_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/50_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/50_GT/TRA/pos_GT.txt\n",
      "run 50\n",
      "folder 51\n",
      "folder 51_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/51_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/51_GT/TRA/pos_GT.txt\n",
      "run 51\n",
      "folder 52\n",
      "folder 52_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/52_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/52_GT/TRA/pos_GT.txt\n",
      "run 52\n",
      "folder 53\n",
      "folder 53_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/53_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/53_GT/TRA/pos_GT.txt\n",
      "run 53\n",
      "folder 54\n",
      "folder 56\n",
      "folder 56_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/56_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/56_GT/TRA/pos_GT.txt\n",
      "run 56\n",
      "folder 54_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/54_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/54_GT/TRA/pos_GT.txt\n",
      "run 54\n",
      "folder 58\n",
      "folder 55\n",
      "folder 55_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/55_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/55_GT/TRA/pos_GT.txt\n",
      "run 55\n",
      "folder 58_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/58_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/58_GT/TRA/pos_GT.txt\n",
      "run 58\n",
      "folder 59\n",
      "folder 59_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/59_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/59_GT/TRA/pos_GT.txt\n",
      "run 59\n",
      "folder 5_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/5_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/5_GT/TRA/pos_GT.txt\n",
      "run 5\n",
      "folder 60\n",
      "folder 60_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/60_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/60_GT/TRA/pos_GT.txt\n",
      "run 60\n",
      "folder 61_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/61_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/61_GT/TRA/pos_GT.txt\n",
      "run 61\n",
      "folder 63\n",
      "folder 63_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/63_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/63_GT/TRA/pos_GT.txt\n",
      "run 63\n",
      "folder 64\n",
      "folder 64_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/64_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/64_GT/TRA/pos_GT.txt\n",
      "run 64\n",
      "folder 65\n",
      "folder 65_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/65_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/65_GT/TRA/pos_GT.txt\n",
      "run 65\n",
      "folder 66\n",
      "folder 66_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/66_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/66_GT/TRA/pos_GT.txt\n",
      "run 66\n",
      "folder 67\n",
      "folder 67_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/67_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/67_GT/TRA/pos_GT.txt\n",
      "run 67\n",
      "folder 68\n",
      "folder 68_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/68_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/68_GT/TRA/pos_GT.txt\n",
      "run 68\n",
      "folder 69\n",
      "folder 69_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/69_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/69_GT/TRA/pos_GT.txt\n",
      "run 69\n",
      "folder 7\n",
      "folder 70\n",
      "folder 70_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/70_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/70_GT/TRA/pos_GT.txt\n",
      "run 70\n",
      "folder 71\n",
      "folder 71_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/71_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/71_GT/TRA/pos_GT.txt\n",
      "run 71\n",
      "folder 72\n",
      "folder 72_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/72_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/72_GT/TRA/pos_GT.txt\n",
      "run 72\n",
      "folder 73\n",
      "folder 73_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/73_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/73_GT/TRA/pos_GT.txt\n",
      "run 73\n",
      "folder 74\n",
      "folder 74_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/74_GT/TRA/pos_GT.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file /media/mo/Label/HeLa_2_track_train/74_GT/TRA/pos_GT.txt\n",
      "run 74\n",
      "folder 75\n",
      "folder 75_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/75_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/75_GT/TRA/pos_GT.txt\n",
      "run 75\n",
      "folder 77\n",
      "folder 77_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/77_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/77_GT/TRA/pos_GT.txt\n",
      "run 77\n",
      "folder 78\n",
      "folder 78_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/78_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/78_GT/TRA/pos_GT.txt\n",
      "run 78\n",
      "folder 79\n",
      "folder 79_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/79_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/79_GT/TRA/pos_GT.txt\n",
      "run 79\n",
      "folder 7_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/7_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/7_GT/TRA/pos_GT.txt\n",
      "run 7\n",
      "folder 8\n",
      "folder 80\n",
      "folder 80_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/80_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/80_GT/TRA/pos_GT.txt\n",
      "run 80\n",
      "folder 82\n",
      "folder 82_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/82_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/82_GT/TRA/pos_GT.txt\n",
      "run 82\n",
      "folder 83\n",
      "folder 83_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/83_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/83_GT/TRA/pos_GT.txt\n",
      "run 83\n",
      "folder 84\n",
      "folder 84_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/84_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/84_GT/TRA/pos_GT.txt\n",
      "run 84\n",
      "folder 85_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/85_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/85_GT/TRA/pos_GT.txt\n",
      "run 85\n",
      "folder 85\n",
      "folder 86\n",
      "folder 86_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/86_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/86_GT/TRA/pos_GT.txt\n",
      "run 86\n",
      "folder 87\n",
      "folder 87_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/87_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/87_GT/TRA/pos_GT.txt\n",
      "run 87\n",
      "folder 88\n",
      "folder 88_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/88_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/88_GT/TRA/pos_GT.txt\n",
      "run 88\n",
      "folder 89\n",
      "folder 8_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/8_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/8_GT/TRA/pos_GT.txt\n",
      "run 8\n",
      "folder 89_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/89_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/89_GT/TRA/pos_GT.txt\n",
      "run 89\n",
      "folder 9\n",
      "folder 9_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_train/9_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_train/9_GT/TRA/pos_GT.txt\n",
      "run 9\n",
      "folder 6\n",
      "folder 6_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_test/6_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_test/6_GT/TRA/pos_GT.txt\n",
      "run 6\n",
      "folder 16\n",
      "folder 16_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_test/16_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_test/16_GT/TRA/pos_GT.txt\n",
      "run 16\n",
      "folder 30\n",
      "folder 30_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_test/30_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_test/30_GT/TRA/pos_GT.txt\n",
      "run 30\n",
      "folder 34\n",
      "folder 34_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_test/34_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_test/34_GT/TRA/pos_GT.txt\n",
      "run 34\n",
      "folder 44\n",
      "folder 44_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_test/44_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_test/44_GT/TRA/pos_GT.txt\n",
      "run 44\n",
      "folder 57\n",
      "folder 57_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_test/57_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_test/57_GT/TRA/pos_GT.txt\n",
      "run 57\n",
      "folder 62\n",
      "folder 62_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_test/62_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_test/62_GT/TRA/pos_GT.txt\n",
      "run 62\n",
      "folder 76\n",
      "folder 76_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_test/76_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_test/76_GT/TRA/pos_GT.txt\n",
      "run 76\n",
      "folder 81\n",
      "folder 81_GT\n",
      "file_path /media/mo/Label/HeLa_2_track_test/81_GT/TRA/pos_GT.txt\n",
      "file /media/mo/Label/HeLa_2_track_test/81_GT/TRA/pos_GT.txt\n",
      "run 81\n",
      "folder void.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_149974/947111407.py:219: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  im_crop = im_crop.resize((20,20),Image.ANTIALIAS)\n",
      "/tmp/ipykernel_149974/947111407.py:220: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  im_m_crop = im_m_crop.resize((20,20),Image.ANTIALIAS)\n",
      "/tmp/ipykernel_149974/947111407.py:221: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  im_p_crop = im_p_crop.resize((20,20),Image.ANTIALIAS)\n",
      "/home/mo/anaconda3/lib/python3.10/site-packages/torchvision/transforms/functional.py:152: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1678402312629/work/torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.5655, Train Accuracy: 73.87%, Val Loss: 0.5593, Test Accuracy:50.12%\n",
      "Epoch 2/10, Train Loss: 0.5674, Train Accuracy: 73.49%, Val Loss: 0.5685, Test Accuracy:47.60%\n",
      "Epoch 3/10, Train Loss: 0.5651, Train Accuracy: 73.91%, Val Loss: 0.5711, Test Accuracy:52.58%\n",
      "Epoch 4/10, Train Loss: 0.5646, Train Accuracy: 74.09%, Val Loss: 0.5559, Test Accuracy:49.46%\n",
      "Epoch 5/10, Train Loss: 0.5610, Train Accuracy: 74.32%, Val Loss: 0.5595, Test Accuracy:51.80%\n",
      "Epoch 6/10, Train Loss: 0.5649, Train Accuracy: 73.93%, Val Loss: 0.5701, Test Accuracy:50.66%\n",
      "Epoch 7/10, Train Loss: 0.5628, Train Accuracy: 73.69%, Val Loss: 0.5778, Test Accuracy:51.74%\n",
      "Epoch 8/10, Train Loss: 0.5624, Train Accuracy: 74.63%, Val Loss: 0.5570, Test Accuracy:51.56%\n",
      "Epoch 9/10, Train Loss: 0.5543, Train Accuracy: 75.79%, Val Loss: 0.5558, Test Accuracy:49.76%\n",
      "Epoch 10/10, Train Loss: 0.5504, Train Accuracy: 76.05%, Val Loss: 0.5697, Test Accuracy:52.64%\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SiameseNetwork()\n",
    "# 2. Load the state dictionary\n",
    "model.load_state_dict(torch.load('Siam_cell_best.pt'))\n",
    "# 3. If you're doing inference, set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "\n",
    "dataset = CellTrackingDataset('/media/mo/Label/HeLa_track_test/') \n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "visualize_tsne_pca(dataloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
