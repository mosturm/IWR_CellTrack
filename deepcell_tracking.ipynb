{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mo/.local/lib/python3.9/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n",
      "2023-07-07 22:10:35.305613: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/mo/anaconda3/envs/cell/lib/python3.9/site-packages/cv2/../../../../lib:\n",
      "2023-07-07 22:10:35.305639: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/mo/anaconda3/envs/cell/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/mo/anaconda3/envs/cell/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIlEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import errno\n",
    "\n",
    "import traceback\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import deepcell\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from deepcell.datasets.tracked import hek293,nih_3t3_bench,nih_3t3,hek293_bench,hela_s3_bench,raw2647_bench\n",
    "from deepcell.datasets.cytoplasm import hela,nih_3t3,cho\n",
    "from PIL import Image\n",
    "import imageio\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "from skimage import io\n",
    "import tifffile as tiff\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from skimage.transform import resize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ctc_2_CNet_track(path_X,suff_X,path_Y,suff_Y,start_ind,prompt='hela_ctc',alt=0,save_dir_org='/home/mo/Desktop/IWR/Cell_GT_Proj/CNet_cells_track/',test=False,step=1,specific_i=None):\n",
    "    \n",
    "    #data=[]\n",
    "    test_entries = []\n",
    "    train_entries = []\n",
    "    l_ind=start_ind\n",
    "    if specific_i is not None:\n",
    "        end=1\n",
    "    else:\n",
    "        end=350\n",
    "        \n",
    "    for i in range(end):\n",
    "        test=False\n",
    "        save_dir=save_dir_org\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            \n",
    "            ind=i+step\n",
    "            path_r_X0 = path_X + suff_X + '{:03d}'.format(ind) + '.tif'\n",
    "            path_r_Y0 = path_Y + suff_Y + '{:03d}'.format(ind) + '.tif'\n",
    "            path_r_X1 = path_X + suff_X + '{:03d}'.format(i) + '.tif'\n",
    "            path_r_Y1 = path_Y + suff_Y + '{:03d}'.format(i) + '.tif'\n",
    "            \n",
    "            if specific_i is not None:\n",
    "            \n",
    "                path_r_X0 = path_X + suff_X + '{:03d}'.format(specific_i+1) + '.tif'\n",
    "                path_r_Y0 = path_Y + suff_Y + '{:03d}'.format(specific_i+1) + '.tif'\n",
    "                path_r_X1 = path_X + suff_X + '{:03d}'.format(specific_i) + '.tif'\n",
    "                path_r_Y1 = path_Y + suff_Y + '{:03d}'.format(specific_i) + '.tif'\n",
    "              \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "            img_r_X0 = tiff.imread(path_r_X0)\n",
    "            img_r_Y0 = tiff.imread(path_r_Y0)\n",
    "            img_r_X1 = tiff.imread(path_r_X1)\n",
    "            img_r_Y1 = tiff.imread(path_r_Y1)\n",
    "\n",
    "            max_X = np.max(img_r_X0)\n",
    "            img_r_X0 = (img_r_X0/max_X)*255\n",
    "            img_r_X1 = (img_r_X1/max_X)*255\n",
    "            \n",
    "         \n",
    "\n",
    "            \n",
    "         \n",
    "            start_x = np.random.randint(0, img_r_X0.shape[1] - 512)\n",
    "            end_x = start_x + 512\n",
    "            start_y = np.random.randint(0, img_r_X0.shape[0] - 512)\n",
    "            end_y = start_y + 512\n",
    "\n",
    "            img_r_X0 = img_r_X0[start_y:end_y, start_x:end_x]\n",
    "            img_r_X1 = img_r_X1[start_y:end_y, start_x:end_x]\n",
    "            img_r_Y0 = img_r_Y0[start_y:end_y, start_x:end_x]\n",
    "            img_r_Y1 = img_r_Y1[start_y:end_y, start_x:end_x]\n",
    "\n",
    "            \n",
    "            probability = 0.1  # 10% probability\n",
    "\n",
    "            # Generate a random number between 0 and 1\n",
    "            random_number = random.random()\n",
    "\n",
    "            # Check if the random number is less than the desired probability\n",
    "            if random_number < probability:\n",
    "                test=True\n",
    "                #print('is_True',)\n",
    "                \n",
    "            if test:\n",
    "                save_dir='/home/mo/Desktop/IWR/Cell_GT_Proj/CNet_cells_track_rd/'\n",
    "                \n",
    "            \n",
    "            img_r_Y1=connect_matching_dots(img_r_Y0,img_r_Y1,path_Y,ind, img_r_X0)\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "            im0 = ax.imshow(img_r_Y0, cmap='viridis')\n",
    "            fig.colorbar(im0, ax=ax)\n",
    "            fig.canvas.draw()\n",
    "            combined_imag0 = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "            combined_imag0 = combined_imag0.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "            im1 = ax.imshow(img_r_Y1, cmap='viridis')\n",
    "            fig.colorbar(im1, ax=ax)\n",
    "            fig.canvas.draw()\n",
    "            combined_imag1 = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "            combined_imag1 = combined_imag1.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "\n",
    "            combined_imag0 = (combined_imag0 * 255).astype(np.uint8)\n",
    "            combined_imag1 = (combined_imag1 * 255).astype(np.uint8)\n",
    "            \n",
    "            j=random.randint(1, 10000)\n",
    "\n",
    "            output_path_X0 = save_dir + 'target/' + str(start_ind + i + 1)+'_'+ str(i)+ '.png'\n",
    "            output_path_Y0 = save_dir + 'source/' + str(start_ind + i + 1) +'_'+ str(i)+ '.png'\n",
    "            output_path_X1 = save_dir + 'target/' + str(start_ind + i) + '_'+ str(i)+'.png'\n",
    "            output_path_Y1 = save_dir + 'source/' + str(start_ind + i) + '_'+ str(i)+'.png'\n",
    "            \n",
    "            \n",
    "            img_r_Y1 = (img_r_Y1).astype(np.uint8)\n",
    "            \n",
    "            #cv2.imwrite(output_path_Y0, combined_imag0)\n",
    "            cv2.imwrite(output_path_Y1, img_r_Y1)\n",
    "            #cv2.imwrite(output_path_X0, img_r_X0)\n",
    "            cv2.imwrite(output_path_X1, img_r_X1)\n",
    "            l_ind = l_ind + 1\n",
    "        \n",
    "    \n",
    "\n",
    "            \n",
    "\n",
    "            entry = {\n",
    "            \"source\": 'source/' + str(start_ind + i) + '_'+ str(i)+'.png',\n",
    "            \"target\": 'target/' + str(start_ind + i) + '_'+ str(i)+'.png',\n",
    "            \"prompt\": prompt\n",
    "            }\n",
    "\n",
    "            # Append the entry to the data list\n",
    "            #data.append(entry)\n",
    "            \n",
    "            if test:\n",
    "                test_entries.append(entry)\n",
    "                \n",
    "            else:\n",
    "                train_entries.append(entry)\n",
    "                \n",
    "\n",
    "            \n",
    "\n",
    "                # Write the data list as JSON to a file\n",
    "\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            if not str(e).startswith(\"[Errno 2]\"):\n",
    "                 traceback.print_exc()\n",
    "                    #print(\"An error occurred:\", str(e))\n",
    "\n",
    "    save_list=['/home/mo/Desktop/IWR/Cell_GT_Proj/CNet_cells_track/','/home/mo/Desktop/IWR/Cell_GT_Proj/CNet_cells_track_rd/']    \n",
    "    for h in range(2): \n",
    "        save_dir=save_list[h]\n",
    "        if h==0:\n",
    "            data = train_entries\n",
    "        else:\n",
    "            data = test_entries\n",
    "    \n",
    "        output_path = save_dir+\"/prompt.json\"    \n",
    "        existing_data = []\n",
    "\n",
    "\n",
    "\n",
    "        # Read existing data from the JSON file, if it exists\n",
    "        try:\n",
    "            with open(output_path, \"r\") as infile:\n",
    "                for line in infile:\n",
    "                    line = line.strip()  # Remove leading/trailing whitespaces\n",
    "                    if line:\n",
    "                        data_j = json.loads(line)\n",
    "                        existing_data.append(data_j)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "\n",
    "        #print('!!!!!!ex',existing_data)\n",
    "        #print('!!!!!!dat',data)\n",
    "        # Append new entries to the existing data\n",
    "        existing_data=existing_data+data\n",
    "        #print('!!!!!!ex2',existing_data)\n",
    "\n",
    "        # Write the updated data to the JSON file\n",
    "        with open(output_path, \"w\") as outfile:\n",
    "            for entry in existing_data:\n",
    "                #print('ent',entry)\n",
    "                json.dump(entry, outfile)\n",
    "                outfile.write('\\n') \n",
    "\n",
    "    return l_ind\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "def source2CNet(img,aug,art,first=False,u_v=None,test=False):\n",
    "    unique_values, unique_counts = np.unique(img, return_counts=True)\n",
    "    #print('u',unique_values)\n",
    "    #print('c',unique_counts)\n",
    "    \n",
    " \n",
    "    if first:\n",
    "        threshold=1\n",
    "\n",
    "        unique_values = unique_values[unique_counts > threshold]\n",
    "        unique_counts = unique_counts[unique_counts > threshold]\n",
    "        \n",
    "        return unique_values\n",
    "    \n",
    "    else:\n",
    "        \n",
    "\n",
    "        #if art == 'fluo_ctc, cell, microscopy image, grayscale' and alt==1:\n",
    "        #    plt.bar(unique_values[unique_values!=0], unique_counts[unique_values!=0])\n",
    "            #plt.ylim(top=200)\n",
    "        #    plt.xlabel('Values')\n",
    "        #    plt.ylabel('Counts')\n",
    "        #    plt.title('Histogram')\n",
    "\n",
    "        #    r=random.uniform(0, 1000000)\n",
    "\n",
    "        #    plt.savefig('/home/mo/Desktop/IWR/Cell_GT_Proj/CNet_cells/'+str(r)+'_'+str(aug)+'_'+art+'.png')\n",
    "\n",
    "\n",
    "        unique_values=u_v\n",
    "        #unique_values, unique_counts = remove_similar_values(unique_values, unique_counts, 1.5)\n",
    "\n",
    "        ind_list=[]\n",
    "        for j in unique_values:\n",
    "            #print('un',j)\n",
    "            tolerance = 1e-3 # define a tolerance level for the closeness\n",
    "\n",
    "            # create a boolean mask of elements in track_res[k] that are close to j\n",
    "            mask = np.isclose(img, j, atol=tolerance)\n",
    "\n",
    "            # get the indices of elements in track_res[k] that satisfy the mask\n",
    "            indices = np.argwhere(mask)\n",
    "            #indices = np.argwhere(track_res[k] == j)\n",
    "            #print('ind',indices)\n",
    "            new_ind= indices[:, :-1]\n",
    "            #print('new_ind',new_ind)\n",
    "            m_ind= mean_ind(indices)\n",
    "            if j!=0:\n",
    "                ind_list.append(m_ind)\n",
    "\n",
    "        image_tensor =  np.zeros_like(img,dtype=np.uint8)\n",
    "\n",
    "        # Define the radius of the ball\n",
    "        radius = 5\n",
    "\n",
    "        # Define the color of the ball (white)\n",
    "        #color = (255, 255, 255)\n",
    "\n",
    "        # Define the list of positions\n",
    "        positions = ind_list\n",
    "        #print('ind',ind_list)\n",
    "        \n",
    "        if test:\n",
    "            num = random_number()[1]\n",
    "            #print(num)\n",
    "            positions = generate_similar_positions(positions,num)\n",
    "            \n",
    "\n",
    "        # Loop over the positions and draw a circle around each one\n",
    "        for position in positions:\n",
    "            # Convert the position to integer coordinates\n",
    "            #try:\n",
    "            x, y = int(position[0]), int(position[1])\n",
    "\n",
    "            # Draw a circle with the given radius and color\n",
    "            for i in range(-radius, radius+1):\n",
    "                for j in range(-radius, radius+1):\n",
    "                    if i**2 + j**2 <= radius**2:\n",
    "                        try:\n",
    "                            image_tensor[x+i, y+j] = 255\n",
    "                        except IndexError:\n",
    "                            pass#print('IndErr',i,j)\n",
    "            #except: \n",
    "               # pass\n",
    "    \n",
    "    \n",
    "    return image_tensor\n",
    "\n",
    "\n",
    "\n",
    "def augment_images(image_X, image_Y, alt):\n",
    "\n",
    "    # Rotate the images based on the 'alt' value\n",
    "    rotate_degrees = alt * 90  # Rotate by 90, 180, 270, or 360 degrees\n",
    "    aug = iaa.Affine(rotate=rotate_degrees)\n",
    "    augmented_images = aug(images=[image_X, image_Y])\n",
    "    \n",
    "    # Return the augmented images\n",
    "    augmented_image_X, augmented_image_Y = augmented_images\n",
    "    return augmented_image_X, augmented_image_Y\n",
    "\n",
    "\n",
    "\n",
    "def generate_similar_positions(positions,num):\n",
    "    positions = np.array(positions)\n",
    "    # Step 1: Calculate pairwise distances\n",
    "    pairwise_distances = np.linalg.norm(positions[:, None] - positions, axis=2)\n",
    "\n",
    "    # Step 2: Create an empty list for new positions\n",
    "    new_positions = []\n",
    "    \n",
    "    n_clusters=int(np.sqrt(len(positions)/2))\n",
    "    n_clusters=int(len(positions)/2)\n",
    "\n",
    "    # Step 3: Generate random distances with the same distribution\n",
    "    random_distances = np.random.choice(pairwise_distances.flatten(), size=len(positions)-1)\n",
    "\n",
    "    # Step 4: Apply KMeans clustering to the positions\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    kmeans.fit(positions)\n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "    # Step 5-11: Generate new positions\n",
    "    for random_distance in random_distances:\n",
    "        # Step 6: Randomly select two cluster centers\n",
    "        idx1, idx2 = np.random.choice(len(cluster_centers), size=2, replace=False)\n",
    "        p1, p2 = cluster_centers[idx1], cluster_centers[idx2]\n",
    "\n",
    "        # Step 7-9: Calculate displacement vector and new position\n",
    "        displacement = (p2 - p1) / np.linalg.norm(p2 - p1)\n",
    "        new_position = p1 + displacement * random_distance\n",
    "\n",
    "        # Step 10: Append new position to the list\n",
    "        new_positions.append(new_position)\n",
    "\n",
    "    # Step 11: Convert the list to numpy array\n",
    "    new_positions = np.array(new_positions)\n",
    "    \n",
    "    if num != None and len(new_positions)-num > 2:\n",
    "        #print('nn1',new_positions,num)\n",
    "        #new_positions = random.sample(new_positions, len(new_positions))\n",
    "        #print('nn2',new_positions,num)\n",
    "        new_positions=new_positions[:num]\n",
    "        \n",
    "\n",
    "    return new_positions\n",
    "\n",
    "\n",
    "def random_number():\n",
    "    if random.random() < 0.25:  # Random float:  0.0 <= x < 1.0\n",
    "        return True, random.randint(1, 6)  # Random int: 1 <= x <= 6\n",
    "    else:\n",
    "        return False, None\n",
    "\n",
    "\n",
    "def connect_matching_dots(img1, img2, path, t, cells, test=False):\n",
    "    # Find unique pixel values in both images\n",
    "    unique_values_1 = np.unique(img1)\n",
    "    unique_values_2 = np.unique(img2)\n",
    "\n",
    "    # Create an output image for dots and lines separately\n",
    "    output_img_dots = np.zeros_like(img1)\n",
    "    output_img_lines = np.zeros_like(img1)\n",
    "    output_img_splits = np.zeros_like(img1)\n",
    "\n",
    "    # Initialize 3-channel image with zeros\n",
    "    output_img_dots = np.stack((output_img_dots,)*3, axis=-1)\n",
    "    output_img_lines = np.stack((output_img_lines,)*3, axis=-1)\n",
    "    output_img_splits = np.stack((np.zeros_like(img1),)*3, axis=-1)\n",
    "\n",
    "    # Draw dots in blue\n",
    "    output_img_dots[:, :, 2] = cells  # RGB color for Blue \n",
    "\n",
    "    # Draw lines and circles in green\n",
    "    for value in unique_values_1[unique_values_1 > 0]:\n",
    "        # Find the coordinates of matching dots in both images\n",
    "        coordinates_img1 = np.argwhere(img1 == value)\n",
    "        coordinates_img2 = np.argwhere(img2 == value)\n",
    "\n",
    "        if coordinates_img2.size > 0: \n",
    "            coord1 = np.mean(coordinates_img1, axis=0, dtype=int)\n",
    "            coord2 = np.mean(coordinates_img2, axis=0, dtype=int)\n",
    "            if test:\n",
    "                coord2 = test_transform(coord1, coord2)\n",
    "            cv2.line(output_img_lines, tuple(coord1[::-1]), tuple(coord2[::-1]), color=[0, 255, 0], thickness=3)\n",
    "            cv2.circle(output_img_lines, tuple(coord2[::-1]), 8, color=[0, 255, 0], thickness=-1)  # Filled circle\n",
    "        else:\n",
    "            cs = check_split(path, t, value)\n",
    "            print('cs', cs)\n",
    "            if cs[0]:\n",
    "                coordinates_img1 = np.argwhere(img1 == value)\n",
    "                coordinates_img2 = np.argwhere(img2 == cs[1])\n",
    "                if coordinates_img2.size > 0: \n",
    "                    coord1 = np.mean(coordinates_img1, axis=0, dtype=int)\n",
    "                    coord2 = np.mean(coordinates_img2, axis=0, dtype=int)\n",
    "                    \n",
    "                    cv2.line(output_img_splits, tuple(coord1[::-1]), tuple(coord2[::-1]), color=[255, 0, 0], thickness=3)\n",
    "                    cv2.circle(output_img_splits, tuple(coord2[::-1]), 8, color=[255, 0, 0], thickness=-1)  # Filled circle\n",
    "\n",
    "    # Stack images along the channel dimension: Red for splits, Green for lines, Blue for dots\n",
    "    output_img = output_img_dots + output_img_lines + output_img_splits\n",
    "    return output_img\n",
    "\n",
    "\n",
    "def check_split(path,t,value):\n",
    "    data = np.loadtxt(path+'man_track.txt')\n",
    "\n",
    "    # Split the data into columns\n",
    "    start = data[:, 1]\n",
    "    ide = data[:, 0][start==t]\n",
    "    \n",
    "    end = data[:, 2][start==t]\n",
    "    parent = data[:, 3][start==t]\n",
    "    \n",
    "    try:\n",
    "        par = parent[ide==value]\n",
    "        print('p_t_pa_v',par,t,path,value)\n",
    "        \n",
    "        if len(ide[parent==par])==2:\n",
    "            print('ide',ide[parent==par])\n",
    "            return True,par[0]\n",
    "        else:\n",
    "            return False,0\n",
    "        \n",
    "    except:\n",
    "        return False,0\n",
    "    \n",
    "    \n",
    "def test_transform(coord1, coord2_mean):\n",
    "    distance = np.linalg.norm(coord2_mean - coord1)\n",
    "    scale_factor = 3  # Distance scale factor\n",
    "\n",
    "    if distance > 0:\n",
    "        # Generate a random orientation\n",
    "        angle = random.uniform(0, 2 * np.pi)\n",
    "\n",
    "        # Calculate the new coordinate\n",
    "        direction = (coord2_mean - coord1) / distance\n",
    "        offset = direction * scale_factor * distance\n",
    "        offset_rotated = np.array([np.cos(angle), -np.sin(angle), np.sin(angle), np.cos(angle)]).reshape((2, 2)).dot(offset)\n",
    "        coord2 = coord2_mean + offset_rotated.astype(int)\n",
    "    else:\n",
    "        # If the distance is 0, set coord2 to coord2_mean\n",
    "        coord2 = coord2_mean\n",
    "    return coord2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mstop\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "print(stop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_X = ['/home/mo/Desktop/IWR/Cell_GT_Proj/CTC_datasets/Fluo-C2DL-Huh7/01/',\n",
    "          '/home/mo/Desktop/IWR/Cell_GT_Proj/CTC_datasets/Fluo-C2DL-Huh7/02/']\n",
    "suff_X = 't' \n",
    "\n",
    "\n",
    "path_Y = ['/home/mo/Desktop/IWR/Cell_GT_Proj/CTC_datasets/Fluo-C2DL-Huh7/01_GT/TRA/',\n",
    "          '/home/mo/Desktop/IWR/Cell_GT_Proj/CTC_datasets/Fluo-C2DL-Huh7/02_GT/TRA/']\n",
    "suff_Y='man_track'\n",
    "\n",
    "prompt_a='hela_ctc, cell, microscopy image, grayscale'\n",
    "prompt_b='fluo_ctc, cell, tracking, microscopy image, grayscale'\n",
    "\n",
    "alt=[0,1,2,3]\n",
    "steps=[1,3,5]\n",
    "l_ind=0\n",
    "split_path_0=[3]\n",
    "split_path_1=[23,17,25,14,26]\n",
    "\n",
    "for g in range(2):\n",
    "    for k in range(len(path_X)):\n",
    "        for q in steps:\n",
    "            for h in range(len(alt)):\n",
    "                if k < 2:\n",
    "                    prompt_ctc=prompt_a\n",
    "                else:\n",
    "                    prompt_ctc=prompt_b\n",
    "                l_ind=ctc_2_CNet_track(path_X[k],suff_X,path_Y[k],suff_Y,start_ind=l_ind,prompt=prompt_b,alt=alt[h],step=q)\n",
    "            #print(l_ind)\n",
    "\n",
    "\n",
    "        if k==0:\n",
    "            split_i=split_path_0\n",
    "        else:\n",
    "            split_i=split_path_1\n",
    "\n",
    "        for t in split_i:\n",
    "            l_ind=ctc_2_CNet_track(path_X[k],suff_X,path_Y[k],suff_Y,start_ind=l_ind,prompt=prompt_b,alt=alt[h],specific_i=t)\n",
    "\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path='/home/mo/Desktop/IWR/Cell_GT_Proj/red_dots'\n",
    "out_path='/home/mo/Desktop/IWR/Cell_GT_Proj/CNet_cells_rd/'\n",
    "\n",
    "\n",
    "red_dots2Cnet(in_path,out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the image folder\n",
    "image_folder = \"/home/mo/Desktop/IWR/Cell_GT_Proj/image_log/val\"\n",
    "\n",
    "# Create a new folder for the combined images\n",
    "output_folder = \"/home/mo/Desktop/IWR/Cell_GT_Proj/image_log/assembled_val\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Get a list of all image files in the folder\n",
    "image_files = [filename for filename in os.listdir(image_folder) if filename.endswith(\".png\")]\n",
    "\n",
    "# Process each set of corresponding images\n",
    "for image_file in image_files:\n",
    "    # Extract the common identifier from the image filename\n",
    "    identifier = image_file.split(\"_gs-\", 1)[1].split(\".\")[0]\n",
    "\n",
    "    # Construct the filenames of the three corresponding images\n",
    "    samples_file = os.path.join(image_folder, f\"samples_cfg_scale_9.00_gs-{identifier}.png\")\n",
    "    reconstruction_file = os.path.join(image_folder, f\"reconstruction_gs-{identifier}.png\")\n",
    "    control_file = os.path.join(image_folder, f\"control_gs-{identifier}.png\")\n",
    "\n",
    "    # Open the images\n",
    "    samples_image = Image.open(samples_file)\n",
    "    reconstruction_image = Image.open(reconstruction_file)\n",
    "    control_image = Image.open(control_file)\n",
    "\n",
    "    # Resize the images by half\n",
    "    new_size = (samples_image.width // 2, samples_image.height // 2)\n",
    "    samples_image = samples_image.resize(new_size)\n",
    "    reconstruction_image = reconstruction_image.resize(new_size)\n",
    "    control_image = control_image.resize(new_size)\n",
    "\n",
    "    # Create a new image with the combined images\n",
    "    combined_image = Image.new(\"RGB\", (new_size[0], new_size[1] * 2))\n",
    "    combined_image.paste(samples_image, (0, 0))\n",
    "    #combined_image.paste(reconstruction_image, (0, new_size[1]))\n",
    "    combined_image.paste(control_image, (0, new_size[1]))\n",
    "\n",
    "    # Save the combined image in the output folder\n",
    "    output_file = os.path.join(output_folder, f\"combined_{identifier}.png\")\n",
    "    combined_image.save(output_file)\n",
    "\n",
    "    # Print the saved file path\n",
    "    print(f\"Combined image saved: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
