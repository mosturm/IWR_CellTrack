{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-16 14:36:54.225035: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/mo/anaconda3/envs/cell/lib/python3.9/site-packages/cv2/../../../../lib:\n",
      "2023-08-16 14:36:54.225063: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/mo/anaconda3/envs/cell/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/mo/anaconda3/envs/cell/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIlEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import errno\n",
    "\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import tarfile\n",
    "import tempfile\n",
    "\n",
    "import traceback\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import deepcell\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from deepcell.datasets.tracked import hek293,nih_3t3_bench,nih_3t3,hek293_bench,hela_s3_bench,raw2647_bench\n",
    "from deepcell.datasets.cytoplasm import hela,nih_3t3,cho\n",
    "from PIL import Image\n",
    "import imageio\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "#from skimage import io\n",
    "import tifffile as tiff\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from skimage.transform import resize\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "\n",
    "from deepcell_tracking.trk_io import load_trks\n",
    "from scipy.spatial import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gt_to_pos(track):\n",
    "    \n",
    "    plt.imshow(track[8].squeeze(), cmap='gray')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    resized_tensor = np.zeros((track.shape[0], 150, 150, 1))\n",
    "\n",
    "    for i in range(track.shape[0]):\n",
    "        #print(i)\n",
    "        resized_tensor[i,:,:,0] = resize(track[i,:,:,0], (150, 150))\n",
    "\n",
    "    track_res = (resized_tensor/np.max(resized_tensor))*np.max(track)\n",
    "    \n",
    "    plt.imshow(track_res[8].squeeze(), cmap='gray')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "    black_im = np.zeros_like(track_res,dtype=np.uint8)\n",
    "    frames = []\n",
    "    #print('gt',track.shape)\n",
    "    for k in range(track.shape[0]):\n",
    "        #print(k)\n",
    "        unique_values, unique_counts = np.unique(track[k], return_counts=True)\n",
    "        #print('u',unique_values)\n",
    "        ind_list=[]\n",
    "        for j in unique_values:\n",
    "            #print('un',j,k)\n",
    "            tolerance = 1e-3 # define a tolerance level for the closeness\n",
    "\n",
    "            # create a boolean mask of elements in track_res[k] that are close to j\n",
    "            mask = np.isclose(track_res[k], j, atol=tolerance)\n",
    "\n",
    "            # get the indices of elements in track_res[k] that satisfy the mask\n",
    "            indices = np.argwhere(mask)\n",
    "            #indices = np.argwhere(track_res[k] == j)\n",
    "            new_ind= indices[:, :-1]\n",
    "            m_ind= mean_ind(new_ind)\n",
    "            if j!=0:\n",
    "                ind_list.append(m_ind)\n",
    "        im_paint=black_im[k]\n",
    "        image_tensor = im_paint\n",
    "\n",
    "        # Define the radius of the ball\n",
    "        radius = 2\n",
    "\n",
    "        # Define the color of the ball (white)\n",
    "        color = (255, 255, 255)\n",
    "\n",
    "        # Define the list of positions\n",
    "        positions = ind_list\n",
    "\n",
    "        # Loop over the positions and draw a circle around each one\n",
    "        for position in positions:\n",
    "            # Convert the position to integer coordinates\n",
    "            try:\n",
    "                x, y = int(position[0]), int(position[1])\n",
    "\n",
    "                # Draw a circle with the given radius and color\n",
    "                for i in range(-radius, radius+1):\n",
    "                    for j in range(-radius, radius+1):\n",
    "                        if i**2 + j**2 <= radius**2:\n",
    "                            try:\n",
    "                                image_tensor[x+i, y+j, :] = 255\n",
    "                            except IndexError:\n",
    "                                pass#print('IndErr',i,j)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # Convert the numpy array to an image and display it\n",
    "        black_im[k]=image_tensor\n",
    "        im=image_tensor.squeeze()\n",
    "        frame = Image.fromarray(im)\n",
    "        frames.append(frame)\n",
    "\n",
    "# Save the list of frames as a gif\n",
    "\n",
    "        #plt.imshow(im, cmap='gray')\n",
    "        #plt.show()\n",
    "    #imageio.mimsave('video.gif', frames)\n",
    "    return black_im,ind_list\n",
    "\n",
    "    \n",
    "def mean_ind(ind):\n",
    "    l=len(ind)\n",
    "    return np.sum(ind,axis=0)/l\n",
    "\n",
    "\n",
    "def downsample_save_cyto(v_t,name,pos=False,vid=False,vid_nr=0,alt=0):\n",
    "\n",
    "\n",
    "    # Load the video tensor\n",
    "    video_tensor = v_t\n",
    "\n",
    "    # Define the downsampling factor\n",
    "    downsample_factor = 3\n",
    "\n",
    "    # Define the pooling layer\n",
    "    pooling_layer = torch.nn.MaxPool2d(kernel_size=downsample_factor, stride=downsample_factor)\n",
    "\n",
    "    # Downsample the video tensor using max pooling\n",
    "    downsampled_tensor = []\n",
    "    maxi=np.max(video_tensor)\n",
    "    for i in range(video_tensor.shape[0]):\n",
    "        frame = (video_tensor[i, :, :, :]/maxi)*255\n",
    "        frame = frame.astype('float32')\n",
    "        frame = TF.to_pil_image(frame.squeeze())\n",
    "        frame = TF.resize(frame, (150, 150))\n",
    "        \n",
    "            \n",
    "        #print('frame_size',frame.size)\n",
    "        frame = TF.to_tensor(frame).unsqueeze(0)\n",
    "        \n",
    "      \n",
    "        #frame = pooling_layer(frame)\n",
    "        downsampled_tensor.append(frame)\n",
    "    downsampled_tensor = torch.cat(downsampled_tensor, dim=0)\n",
    "    downsampled_tensor = downsampled_tensor.permute(0, 2, 3, 1).squeeze()\n",
    "    #print('down_shape',downsampled_tensor.shape)\n",
    "    # Save every 5 consecutive frames to a file\n",
    "    num_frames = downsampled_tensor.shape[0]\n",
    "    for i in range(0, num_frames-5, 1):\n",
    "        frames_to_save = downsampled_tensor[i:i+5]\n",
    "        single_frame=downsampled_tensor[i]\n",
    "        frames_to_save = frames_to_save.numpy()\n",
    "        #print('f_to_s',frames_to_save.shape)\n",
    "        path=cons_path(i,name,pos,vid,vid_nr,alt)\n",
    "        #print('path',path)\n",
    "        np.save(path, frames_to_save)\n",
    "        \n",
    "        \n",
    "\n",
    "        if pos:\n",
    "            pos_t=2\n",
    "            path2=cons_path(i,name,pos_t,vid,vid_nr,alt)\n",
    "            #print('path2',path2)\n",
    "            if path2 != 0:\n",
    "                np.save(path2, single_frame)\n",
    "        else:\n",
    "            if random.random() < 1:\n",
    "                pos_t=2\n",
    "                path2=cons_path(i,name,pos_t,vid,vid_nr,alt)\n",
    "                #print('path3',path2)\n",
    "                if path2 != 0:\n",
    "                    np.save(path2, single_frame)\n",
    "\n",
    "            \n",
    "            \n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "def cons_path(i,name,pos,vid,vid_nr,alt):\n",
    "    #print('pos',pos)\n",
    "    \n",
    "    \n",
    "    if pos==True:\n",
    "        pre='posit_train/'\n",
    "            \n",
    "    elif pos==2:\n",
    "        #print('pos2',pos)\n",
    "        if random.random() < 1/10:\n",
    "            #print('embtest')\n",
    "            pre='emb_test/'\n",
    "        else:\n",
    "            pre='emb_train/'\n",
    "        j = np.random.randint(1, 100001)\n",
    "        return pre+name+str(j)+'.npy'\n",
    "    \n",
    "    else:\n",
    "        pre='images_train/'\n",
    "    \n",
    "    \n",
    "    mid=name+'/'\n",
    "    \n",
    "    if vid:\n",
    "        end='vn_'+str(vid_nr)+'_alt'+alt+'_'+str(i)+'.npy'\n",
    "    else:\n",
    "        end='alt'+alt+'_'+str(i)+'.npy'\n",
    "    return pre+mid+end\n",
    "\n",
    "def verify(path1,path2,single=None):\n",
    "    \n",
    "    if single:\n",
    "        tensor1 = np.load(path1)\n",
    "        tensor2 = np.load(path2)\n",
    "\n",
    "        # Create a figure with subplots to display the frames side by side\n",
    "        fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 20))\n",
    "\n",
    "        # Loop over each frame and display them in the subplots\n",
    "        \n",
    "        # Display the frame from the first tensor in the left subplot\n",
    "        im1=axs[0].imshow(tensor1, cmap=\"gray\")\n",
    "        axs[0].axis(\"off\")\n",
    "        plt.colorbar(im1, ax=axs[0])\n",
    "\n",
    "        # Display the frame from the second tensor in the right subplot\n",
    "        im2=axs[1].imshow(tensor2, cmap=\"gray\")\n",
    "        axs[1].axis(\"off\")\n",
    "        plt.colorbar(im2, ax=axs[1])\n",
    "\n",
    "        # Show the figure with the subplots\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "    # Load the tensors from the .npy files\n",
    "    tensor1 = np.load(path1)\n",
    "    tensor2 = np.load(path2)\n",
    "\n",
    "    # Create a figure with subplots to display the frames side by side\n",
    "    fig, axs = plt.subplots(nrows=tensor1.shape[0], ncols=2, figsize=(10, 20))\n",
    "\n",
    "    # Loop over each frame and display them in the subplots\n",
    "    for i in range(tensor1.shape[0]):\n",
    "        # Display the frame from the first tensor in the left subplot\n",
    "        im1=axs[i, 0].imshow(tensor1[i], cmap=\"gray\")\n",
    "        axs[i, 0].axis(\"off\")\n",
    "        plt.colorbar(im1, ax=axs[i, 0])\n",
    "\n",
    "\n",
    "        # Display the frame from the second tensor in the right subplot\n",
    "        im2=axs[i, 1].imshow(tensor2[i], cmap=\"gray\")\n",
    "        axs[i, 1].axis(\"off\")\n",
    "        plt.colorbar(im2, ax=axs[i, 1])\n",
    "\n",
    "\n",
    "    # Show the figure with the subplots\n",
    "    plt.show()\n",
    "    return 0\n",
    "\n",
    "\n",
    "def save_vid_tens(tens,pos,name,alt):\n",
    "    for i in range(tens.shape[0]):\n",
    "        if pos:\n",
    "            v_t=gt_to_pos(tens[i])[0]\n",
    "        else:\n",
    "            v_t=tens[i]\n",
    "        downsample_save_cyto(v_t,name,pos=pos,vid=True,vid_nr=i,alt=alt)\n",
    "\n",
    "def save_im_tens(tens,pos,name,alt):\n",
    "    if pos:\n",
    "        v_t=gt_to_pos(tens)[0]\n",
    "    else:\n",
    "        v_t=tens\n",
    "    downsample_save_cyto(v_t,name,pos=pos,alt=alt)\n",
    "\n",
    "        \n",
    "def alt(X,y,a=None,t_c=None):\n",
    "    #alt_s=str(0)+'+'+str(0)\n",
    "    #return X,y,alt_s \n",
    "    \n",
    "    if t_c == None:\n",
    "        time_cons=get_bit(0.2)\n",
    "    else:\n",
    "        time_cons=t_c\n",
    "        \n",
    "    if time_cons==1:\n",
    "        X,y=shuffle(X,y)\n",
    "        \n",
    "    if a == None:\n",
    "        alt = random.randint(0, 1)\n",
    "    else:\n",
    "        alt = a\n",
    "        \n",
    "        \n",
    "    if alt==0:\n",
    "        X = X\n",
    "        y = y\n",
    "        #arr_flipped = np.swapaxes(arr_flipped, 1, 2)\n",
    "    elif alt==1:\n",
    "        X = np.fliplr(X)\n",
    "        y = np.fliplr(y)\n",
    "        \n",
    "    else:\n",
    "        X = np.fliplr(X)\n",
    "        y = np.fliplr(y)\n",
    "        X = np.flipud(X)\n",
    "        y = np.flipud(y)\n",
    "    alt_s=str(time_cons)+'+'+str(alt)\n",
    "    return X,y,alt_s      \n",
    "    \n",
    "    \n",
    "    \n",
    "def shuffle(arr1, arr2):\n",
    "    print('shuffling')\n",
    "    # Get the number of samples\n",
    "    n_samples = arr1.shape[0]\n",
    "\n",
    "    # Generate a random permutation of indices\n",
    "    perm = np.random.permutation(n_samples)\n",
    "\n",
    "    # Shuffle the arrays using the same permutation\n",
    "    shuffled_arr1 = arr1[perm]\n",
    "    shuffled_arr2 = arr2[perm]\n",
    "\n",
    "    return shuffled_arr1, shuffled_arr2\n",
    "\n",
    "\n",
    "\n",
    "def get_bit(probability):\n",
    "    if random.random() < probability:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "    \n",
    "def alt_vid(X,y,a=None):\n",
    "    t_c=get_bit(0.2)\n",
    "    t_c=0 #####\n",
    "    if a == None:\n",
    "        a=random.randint(0, 1)\n",
    "    X_n= np.zeros_like(X)\n",
    "    y_n= np.zeros_like(X)\n",
    "    for i in range(X.shape[0]):\n",
    "        print('i',i,t_c,a)\n",
    "        X_n[i],y_n[i],alt_s = alt(X[i],y[i],t_c=t_c,a=a)\n",
    "    \n",
    "    return X_n,y_n,alt_s\n",
    "    \n",
    "    \n",
    "def tif_to_vt(path,suff):\n",
    "    \n",
    "    path_0=path+suff+'{:03d}'.format(0)+'.tif'\n",
    "        # read the tif file\n",
    "    img = tiff.imread(path_0)\n",
    "    #print('i_shape',img.shape)\n",
    "    \n",
    "    image_array = np.zeros((120, img.shape[0], img.shape[1], 1))\n",
    "\n",
    "    # loop over the tif files\n",
    "    for i in range(120):\n",
    "        \n",
    "        path_r=path+suff+'{:03d}'.format(i)+'.tif'\n",
    "        # read the tif file\n",
    "        #print('p',path_r)\n",
    "        try:\n",
    "            img_r = tiff.imread(path_r)\n",
    "        except:\n",
    "            img_r = np.zeros((img.shape[0], img.shape[1]))\n",
    "        #print('i_shape',img.shape)\n",
    "        # add the image to the numpy array\n",
    "        image_array[i,:,:,0] = img_r\n",
    "    \n",
    "    #image_a = np.zeros((120, img.shape[0], img.shape[1], 1))\n",
    "    nonzero_indices = np.nonzero(np.any(image_array, axis=(1,2,3)))[0]\n",
    "    crop_im = image_array[nonzero_indices]\n",
    "    return crop_im\n",
    "\n",
    "def ctc_2_CNet(path_X,suff_X,path_Y,suff_Y,start_ind,prompt='hela_ctc',alt=0,save_dir='/home/mo/Desktop/IWR/Cell_GT_Proj/CNet_cells/',test=False):\n",
    "    \n",
    "    data=[]\n",
    "    l_ind=start_ind\n",
    "    for i in range(350):\n",
    "        \n",
    "        try:\n",
    "            output_path_Y_c = save_dir+'source/'+str(start_ind+i)+'contr.png'\n",
    "            \n",
    "            path_r_X=path_X+suff_X+'{:03d}'.format(i)+'.tif'\n",
    "            path_r_Y=path_Y+suff_Y+'{:03d}'.format(i)+'_cp_masks.png'\n",
    "            # read the tif file\n",
    "            #print('p',path_r)\n",
    "            #try:\n",
    "            #img_r_X = tiff.imread(path_r_X)\n",
    "            #img_r_Y = tiff.imread(path_r_Y)\n",
    "            img_r_X = imread(path_r_X)\n",
    "            img_r_Y = imread(path_r_Y)\n",
    "\n",
    "\n",
    "            max_X=np.max(img_r_X)\n",
    "            img_r_X = (img_r_X/max_X)*255\n",
    "            max_y=np.max(img_r_Y)\n",
    "            img_r_Y = (img_r_Y/max_y)*255\n",
    "            \n",
    "            \n",
    "            if prompt=='fluo_ctc, cell, microscopy image, grayscale':\n",
    "                \n",
    "                start_x = np.random.randint(0, img_r_X.shape[1] - 512)\n",
    "                end_x = start_x + 512\n",
    "                start_y = np.random.randint(0, img_r_X.shape[0] - 512)\n",
    "                end_y = start_y + 512\n",
    "\n",
    "                # Crop the random region from img_r_X\n",
    "                img_r_X = img_r_X[start_y:end_y, start_x:end_x]\n",
    "\n",
    "                # Crop the random region from img_r_Y\n",
    "                img_r_Y = img_r_Y[start_y:end_y, start_x:end_x]\n",
    "            \n",
    "\n",
    "\n",
    "            u_val = source2CNet(img_r_Y,alt,prompt,first=True)\n",
    "\n",
    "     \n",
    "            img_r_X,img_r_Y=augment_images(img_r_X, img_r_Y,alt=alt)\n",
    "\n",
    "\n",
    "            #if alt==1:\n",
    "            #    cv2.imwrite(output_path_Y_c, img_r_Y)\n",
    "\n",
    "\n",
    "\n",
    "            resized_X = cv2.resize(img_r_X, (512, 512))\n",
    "            resized_Y = cv2.resize(img_r_Y, (512, 512))\n",
    "\n",
    "            resized_Y_s = source2CNet(resized_Y,alt,prompt,u_v=u_val,test=test)\n",
    "\n",
    "            # Specify the output file path\n",
    "            if test:\n",
    "                save_dir='/home/mo/Desktop/IWR/Cell_GT_Proj/CNet_cells_rd/'\n",
    "                \n",
    "            \n",
    "            \n",
    "            output_path_X = save_dir+'target/'+str(start_ind+i)+'.png'\n",
    "            output_path_Y = save_dir+'source/'+str(start_ind+i)+'.png'\n",
    "            #output_path_Y_c = save_dir+'source/'+str(start_ind+i)+'contr.png'\n",
    "\n",
    "\n",
    "\n",
    "            # Save the resized image as PNG\n",
    "            cv2.imwrite(output_path_X, resized_X)\n",
    "            cv2.imwrite(output_path_Y, resized_Y_s)\n",
    "            \n",
    "\n",
    "            entry = {\n",
    "            \"source\": \"source/\" + str(start_ind+i) + \".png\",\n",
    "            \"target\": \"target/\" + str(start_ind+i) + \".png\",\n",
    "            \"prompt\": prompt\n",
    "            }\n",
    "\n",
    "            # Append the entry to the data list\n",
    "            data.append(entry)\n",
    "\n",
    "            l_ind=l_ind+1\n",
    "\n",
    "                # Write the data list as JSON to a file\n",
    "\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            if not str(e).startswith(\"[Errno 2]\"):\n",
    "                traceback.print_exc()\n",
    "            #print(\"An error occurred:\", str(e))\n",
    "\n",
    "        \n",
    "        \n",
    "    output_path = save_dir+\"/prompt.json\"    \n",
    "    existing_data = []\n",
    "\n",
    "\n",
    "\n",
    "    # Read existing data from the JSON file, if it exists\n",
    "    try:\n",
    "        with open(output_path, \"r\") as infile:\n",
    "            for line in infile:\n",
    "                line = line.strip()  # Remove leading/trailing whitespaces\n",
    "                if line:\n",
    "                    data_j = json.loads(line)\n",
    "                    existing_data.append(data_j)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n",
    "    #print('!!!!!!ex',existing_data)\n",
    "    #print('!!!!!!dat',data)\n",
    "    # Append new entries to the existing data\n",
    "    existing_data=existing_data+data\n",
    "    #print('!!!!!!ex2',existing_data)\n",
    "\n",
    "    # Write the updated data to the JSON file\n",
    "    with open(output_path, \"w\") as outfile:\n",
    "        for entry in existing_data:\n",
    "            #print('ent',entry)\n",
    "            json.dump(entry, outfile)\n",
    "            outfile.write('\\n')    \n",
    "        \n",
    "    return l_ind\n",
    "    \n",
    "    \n",
    "def source2CNet(img, aug, art, first=False, u_v=None, test=False):\n",
    "    unique_values, unique_counts = np.unique(img, return_counts=True)\n",
    "    unique_counts=unique_counts[1:]\n",
    "    unique_values=unique_values[1:]\n",
    "\n",
    "    if first:\n",
    "        threshold=1\n",
    "        unique_values = unique_values[unique_counts > threshold]\n",
    "        unique_counts = unique_counts[unique_counts > threshold]\n",
    "        \n",
    "        return unique_values\n",
    "    else:\n",
    "        #unique_values=u_v\n",
    "        pos_list=[]\n",
    "        count_list=[]\n",
    "        for idx, j in enumerate(unique_values):\n",
    "            tolerance = 1e-4 \n",
    "            mask = np.isclose(img, j, atol=tolerance)\n",
    "            indices = np.argwhere(mask)\n",
    "            new_ind= indices[:, :-1]\n",
    "            m_ind= mean_ind(indices)\n",
    "            pos_list.append(m_ind)  # Save only the position to pos_list\n",
    "            count_list.append(unique_counts[idx])  # Save the count separately\n",
    "\n",
    "        image_tensor =  np.zeros_like(img,dtype=np.uint8)\n",
    "\n",
    "        if test:\n",
    "            num = None\n",
    "            pos_list = generate_similar_positions2(pos_list)\n",
    "\n",
    "        for position, value in zip(pos_list, count_list):  # Iterate over pos_list and count_list together\n",
    "            x, y = int(position[0]), int(position[1])\n",
    "\n",
    "            # Define the radius for this specific point.\n",
    "            radius =  map_value_linear(value, 10, 1500, 2, 8)\n",
    "\n",
    "            for i in range(-radius, radius+1):\n",
    "                for j in range(-radius, radius+1):\n",
    "                    if i**2 + j**2 <= radius**2:\n",
    "                        try:\n",
    "                            image_tensor[x+i, y+j] = 255\n",
    "                        except IndexError:\n",
    "                            pass\n",
    "\n",
    "    return image_tensor\n",
    "\n",
    "\n",
    "def augment_images(image_X, image_Y, alt):\n",
    "\n",
    "    # Rotate the images based on the 'alt' value\n",
    "    rotate_degrees = alt * 90  # Rotate by 90, 180, 270, or 360 degrees\n",
    "    aug = iaa.Affine(rotate=rotate_degrees)\n",
    "    augmented_images = aug(images=[image_X, image_Y])\n",
    "    \n",
    "    # Return the augmented images\n",
    "    augmented_image_X, augmented_image_Y = augmented_images\n",
    "    return augmented_image_X, augmented_image_Y\n",
    "\n",
    "\n",
    "\n",
    "def generate_similar_positions(positions,num):\n",
    "    \n",
    "    # Step 1: Calculate pairwise distances\n",
    "    \n",
    "    try:\n",
    "        positions = np.array(positions)\n",
    "        print(positions,positions.ndim)\n",
    "        pairwise_distances = np.linalg.norm(positions[:, None] - positions, axis=2)\n",
    "    except:\n",
    "        positions =  np.array(positions)#np.random.uniform(low=0, high=512, size=(12, 2))\n",
    "        pairwise_distances = np.linalg.norm(positions[:, None] - positions, axis=2)\n",
    "    \n",
    "    #print('pwd', pairwise_distances.shape,pairwise_distances)\n",
    "\n",
    "    # Step 2: Create an empty list for new positions\n",
    "    new_positions = []\n",
    "    \n",
    "    #n_clusters=int(np.sqrt(len(positions)/2))\n",
    "    n_clusters=int(len(positions)/2)\n",
    "\n",
    "    # Step 3: Generate random distances with the same distribution\n",
    "    random_distances = np.random.choice(pairwise_distances.flatten(), size=len(positions))\n",
    "\n",
    "    # Step 4: Apply KMeans clustering to the positions\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    kmeans.fit(positions)\n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "    # Step 5-11: Generate new positions\n",
    "    for random_distance in random_distances:\n",
    "        # Step 6: Randomly select two cluster centers\n",
    "        if len(cluster_centers) >= 2:\n",
    "            idx1, idx2 = np.random.choice(len(cluster_centers), size=2, replace=False)\n",
    "            p1, p2 = cluster_centers[idx1], cluster_centers[idx2]\n",
    "            displacement = (p2 - p1) / np.linalg.norm(p2 - p1)\n",
    "        elif len(cluster_centers) == 1:\n",
    "            p1 = p2 = cluster_centers[0]\n",
    "            displacement = 1\n",
    "        # Step 7-9: Calculate displacement vector and new position\n",
    "       \n",
    "        new_position = p1 + displacement * random_distance\n",
    "\n",
    "        # Step 10: Append new position to the list\n",
    "        new_positions.append(new_position)\n",
    "\n",
    "    # Step 11: Convert the list to numpy array\n",
    "    new_positions = np.array(new_positions)\n",
    "    \n",
    "    if num != None and len(new_positions)-num > 2:\n",
    "        #print('nn1',new_positions,num)\n",
    "        #new_positions = random.sample(new_positions, len(new_positions))\n",
    "        #print('nn2',new_positions,num)\n",
    "        new_positions=new_positions[:num]\n",
    "        \n",
    "\n",
    "    return new_positions\n",
    "\n",
    "\n",
    "\n",
    "def generate_similar_positions2(positions):\n",
    "    # Calculate pairwise distances\n",
    "    positions = np.array(positions)\n",
    "    pairwise_distances = np.linalg.norm(positions[:, None] - positions, axis=2)\n",
    "\n",
    "    # Get the minimum distance from the pairwise_distances\n",
    "    min_distance = np.min(pairwise_distances + np.eye(pairwise_distances.shape[0]) * np.max(pairwise_distances))\n",
    "\n",
    "    # Create an empty list for new positions\n",
    "    new_positions = []\n",
    "\n",
    "    # Initial random position\n",
    "    new_positions.append(np.random.uniform(low=positions.min(axis=0), high=positions.max(axis=0)))\n",
    "\n",
    "    # Maximal number of attempts to generate a point that keeps minimal distance\n",
    "    max_attempts = 1000\n",
    "    attempts = 0\n",
    "\n",
    "    while len(new_positions) < len(positions):\n",
    "        if attempts > max_attempts:\n",
    "            print(\"Cannot generate desired number of positions with the current minimal distance.\")\n",
    "            break\n",
    "\n",
    "        # Sample random point\n",
    "        random_point = np.random.uniform(low=positions.min(axis=0), high=positions.max(axis=0))\n",
    "\n",
    "        # Construct KDTree\n",
    "        tree = KDTree(new_positions)\n",
    "\n",
    "        # Get the distances and indices of the closest points to the random_point\n",
    "        distances, indices = tree.query(random_point, k=1)\n",
    "\n",
    "        # Check if the minimum distance condition holds\n",
    "        if distances >= min_distance:\n",
    "            new_positions.append(random_point.tolist())\n",
    "        else:\n",
    "            attempts += 1\n",
    "\n",
    "    # Convert list to numpy array\n",
    "    new_positions = np.array(new_positions)\n",
    "\n",
    "    return new_positions\n",
    "\n",
    "\n",
    "def random_number():\n",
    "    if random.random() < 0.25:  # Random float:  0.0 <= x < 1.0\n",
    "        return True, random.randint(1, 6)  # Random int: 1 <= x <= 6\n",
    "    else:\n",
    "        return False, None\n",
    "\n",
    "\n",
    "def deep_2_CNet(X,Y, start_ind, prompt='hela_ctc', alt=0, save_dir='/media/mo/Label/CNet_deepcell/', test=False):\n",
    "\n",
    "    data=[]\n",
    "    l_ind=start_ind\n",
    "    if test:\n",
    "        end_j= 1\n",
    "    else:\n",
    "        end_j= X.shape[0]\n",
    "        \n",
    "    \n",
    "    for j in range(end_j):\n",
    "        for i in range(X.shape[1]):\n",
    "            if test:\n",
    "                f=random.randint(0, X.shape[0]-1)\n",
    "                s=random.randint(0, X.shape[1]-1)\n",
    "                frame_X = X[f, s, :, :, :]\n",
    "                frame_Y = Y[f, s, :, :, :]\n",
    "            else:    \n",
    "                frame_X = X[j, i, :, :, :]\n",
    "                frame_Y = Y[j, i, :, :, :]\n",
    "            if np.mean(frame_X) != 0:\n",
    "\n",
    "                #print('mean_j_i',j,i, np.mean(frame_X))\n",
    "                #output_path_Y_c = save_dir+'source/'+str(start_ind+i)+'contr.png'\n",
    "                if test:\n",
    "                    max_X=np.max(X[f,...])\n",
    "                else:\n",
    "                    max_X=np.max(X[j,...])\n",
    "                frame_X = (frame_X/max_X)*255\n",
    "                #frame_Y = (frame_Y/max_X)*255\n",
    "\n",
    "\n",
    "                #print('shape',frame_X.shape)\n",
    "                #start_x = np.random.randint(0, frame_X.shape[0] - 512)\n",
    "                start_x = 0\n",
    "                end_x = start_x + 512\n",
    "                #start_y = np.random.randint(0, frame_X.shape[1] - 512)\n",
    "                start_y=0\n",
    "                end_y = start_y + 512\n",
    "\n",
    "                # Crop the random region from img_r_X\n",
    "                img_r_X = frame_X[start_y:end_y, start_x:end_x]\n",
    "\n",
    "                # Crop the random region from img_r_Y\n",
    "                img_r_Y = frame_Y[start_y:end_y, start_x:end_x]\n",
    "\n",
    "                #u_val = source2CNet(img_r_Y,alt,prompt,first=True)\n",
    "\n",
    "\n",
    "                img_r_X,img_r_Y=augment_images(img_r_X, img_r_Y,alt=alt)\n",
    "\n",
    "\n",
    "                #if alt==1:\n",
    "                #    cv2.imwrite(output_path_Y_c, img_r_Y)\n",
    "\n",
    "\n",
    "\n",
    "                resized_X = cv2.resize(img_r_X, (512, 512))\n",
    "                resized_Y = cv2.resize(img_r_Y, (512, 512))\n",
    "\n",
    "                resized_Y_s = source2CNet(resized_Y,alt,prompt,u_v=None,test=test)\n",
    "\n",
    "                # Specify the output file path\n",
    "                if test:\n",
    "                    save_dir='/media/mo/Label/CNet_deepcell_rd/'\n",
    "\n",
    "\n",
    "\n",
    "                output_path_X = save_dir+'target/'+str(start_ind+i)+'_'+str(j)+'.png'\n",
    "                output_path_Y = save_dir+'source/'+str(start_ind+i)+'_'+str(j)+'.png'\n",
    "                #output_path_Y_c = save_dir+'source/'+str(start_ind+i)+'contr.png'\n",
    "\n",
    "\n",
    "\n",
    "                # Save the resized image as PNG\n",
    "                cv2.imwrite(output_path_X, resized_X)\n",
    "                cv2.imwrite(output_path_Y, resized_Y_s)\n",
    "\n",
    "\n",
    "                entry = {\n",
    "                \"source\": \"source/\" +str(start_ind+i)+'_'+str(j)+'.png',\n",
    "                \"target\": \"target/\" +str(start_ind+i)+'_'+str(j)+'.png',\n",
    "                \"prompt\": prompt\n",
    "                }\n",
    "\n",
    "                # Append the entry to the data list\n",
    "                data.append(entry)\n",
    "\n",
    "                l_ind=l_ind+1\n",
    "\n",
    "                # Write the data list as JSON to a file\n",
    "            else:\n",
    "                i = X.shape[1]\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    output_path = save_dir+\"/prompt.json\"    \n",
    "    existing_data = []\n",
    "\n",
    "\n",
    "\n",
    "    # Read existing data from the JSON file, if it exists\n",
    "    try:\n",
    "        with open(output_path, \"r\") as infile:\n",
    "            for line in infile:\n",
    "                line = line.strip()  # Remove leading/trailing whitespaces\n",
    "                if line:\n",
    "                    data_j = json.loads(line)\n",
    "                    existing_data.append(data_j)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n",
    "    #print('!!!!!!ex',existing_data)\n",
    "    #print('!!!!!!dat',data)\n",
    "    # Append new entries to the existing data\n",
    "    existing_data=existing_data+data\n",
    "    #print('!!!!!!ex2',existing_data)\n",
    "\n",
    "    # Write the updated data to the JSON file\n",
    "    with open(output_path, \"w\") as outfile:\n",
    "        for entry in existing_data:\n",
    "            #print('ent',entry)\n",
    "            json.dump(entry, outfile)\n",
    "            outfile.write('\\n')    \n",
    "        \n",
    "    return l_ind\n",
    "\n",
    "def map_value_linear(value, in_min, in_max, out_min, out_max):\n",
    "    # Ensure the input value is within the input range\n",
    "    value = max(min(value, in_max), in_min)\n",
    "    \n",
    "    if value==in_min:\n",
    "        return 1\n",
    "    elif value== in_max:\n",
    "        return 8\n",
    "\n",
    "    # Map the value to the output range using linear interpolation\n",
    "    return int((value - in_min) * (out_max - out_min) / (in_max - in_min) + out_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mstop\u001b[49m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03mnih_3t3_bench\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03mhek293_bench \u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03mhela_s3_bench \u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03mraw2647_bench\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "print(stop)\n",
    "\n",
    "\n",
    "'''\n",
    "nih_3t3_bench\n",
    "hek293_bench \n",
    "hela_s3_bench \n",
    "raw2647_bench\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#filename = 'sample_tracking.trks'\n",
    "#(X_train, y_train), (X_test, y_test) = nih_3t3_bench.load_tracked_data(filename)\n",
    "(X_train,y_train),(X_test,y_test) = hela.load_data(path='hela_cytoplasm.npz',test_size=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print (X_train[7].shape)\n",
    "print (y_train.shape)\n",
    "\n",
    "plt.imshow(X_train[7].squeeze(), cmap='gray')\n",
    "plt.show()\n",
    "X_train_a,y_train_a,alt_s=alt(X_train,y_train)\n",
    "print (y_train_a.shape)\n",
    "plt.imshow(X_train_a[7].squeeze(), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(alt_s)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "frames = []\n",
    "video_tensor=X_train\n",
    "for i in range(video_tensor.shape[0]):\n",
    "    # Convert each frame to a Pillow image object\n",
    "    print(video_tensor[i].shape)\n",
    "    im=video_tensor[i].squeeze()\n",
    "    print(im.size)\n",
    "    frame = Image.fromarray((im * 255 / np.max(im)).astype(np.uint8))\n",
    "    frames.append(frame)\n",
    "\n",
    "# Save the list of frames as a gif\n",
    "imageio.mimsave('video_hela.gif', frames)\n",
    "\n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train_a,y_train_a,alt_s=alt(X_train,y_train,a=0,t_c=0)\n",
    "\n",
    "save_im_tens(X_train_a,name='cyt_hela',pos=False,alt=alt_s)\n",
    "save_im_tens(y_train_a,name='cyt_hela',pos=True,alt=alt_s)\n",
    "\n",
    "X_train_a,y_train_a,alt_s=alt(X_train,y_train,a=0,t_c=1)\n",
    "\n",
    "save_im_tens(X_train_a,name='cyt_hela',pos=False,alt=alt_s)\n",
    "save_im_tens(y_train_a,name='cyt_hela',pos=True,alt=alt_s)\n",
    "\n",
    "X_train_a,y_train_a,alt_s=alt(X_train,y_train,a=1,t_c=1)\n",
    "\n",
    "save_im_tens(X_train_a,name='cyt_hela',pos=False,alt=alt_s)\n",
    "save_im_tens(y_train_a,name='cyt_hela',pos=True,alt=alt_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cnet positions (no track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_X = ['/home/mo/Desktop/IWR/Cell_GT_Proj/CTC_datasets/Fluo-C2DL-Huh7/01/']\n",
    "          #'/home/mo/Desktop/IWR/Cell_GT_Proj/CTC_datasets/Fluo-C2DL-Huh7/02/']\n",
    "suff_X = 't' \n",
    "\n",
    "\n",
    "path_Y = ['/home/mo/Desktop/IWR/Cell_GT_Proj/CTC_datasets/Fluo-C2DL-Huh7/01_CP/']#,\n",
    "          #'/home/mo/Desktop/IWR/Cell_GT_Proj/CTC_datasets/Fluo-C2DL-Huh7/02_GT/TRA/']\n",
    "suff_Y= 't'#man_track'\n",
    "\n",
    "prompt_a='hela_ctc, cell, microscopy image, grayscale'\n",
    "prompt_b='fluo_ctc, cell, microscopy image, grayscale'\n",
    "\n",
    "alt=[0,1,2,3]\n",
    "\n",
    "l_ind=0\n",
    "for g in range(2):\n",
    "    \n",
    "    for k in range(len(path_X)):\n",
    "        for h in range(len(alt)):\n",
    "            if k < 2:\n",
    "                prompt_ctc=prompt_a\n",
    "            else:\n",
    "                prompt_ctc=prompt_b\n",
    "            l_ind=ctc_2_CNet(path_X[k],suff_X,path_Y[k],suff_Y,start_ind=l_ind,prompt=prompt_b,alt=alt[h])\n",
    "            print(l_ind)\n",
    "        \n",
    "        \n",
    "l_ind=0        \n",
    "for k in range(len(path_X)):\n",
    "    for h in range(len(alt)):\n",
    "        if k < 2:\n",
    "            prompt_ctc=prompt_a\n",
    "        else:\n",
    "            prompt_ctc=prompt_b\n",
    "        l_ind=ctc_2_CNet(path_X[k],suff_X,path_Y[k],suff_Y,start_ind=l_ind,prompt=prompt_b,alt=alt[h],test=True)\n",
    "        print(l_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 71, 584, 600, 1)\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/media/mo/Label/DynamicNuclearNet-tracking-v1_0/'\n",
    "data = load_trks(os.path.join(data_dir, 'test.trks'))\n",
    "\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "\n",
    "print(X.shape)\n",
    "#lineages = data['lineages']\n",
    "\n",
    "#data_source = np.load(os.path.join(data_dir, 'data-source.npz'), allow_pickle=True)\n",
    "#meta = pd.DataFrame(data_source['test'], columns=['filename', 'experiment', 'pixel_size', 'screening_passed', 'time_step', 'specimen'])\n",
    "#track_id = 0\n",
    "#frame_id = 1\n",
    "\n",
    "# Load the data\n",
    "#X_frame = X[track_id, frame_id, ..., 0]  # This is assuming channels are last, adjust if necessary\n",
    "#y_frame = y[track_id, frame_id, ..., 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "617\n",
      "1234\n",
      "1851\n",
      "2468\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "prompt='cell, microscopy, image'\n",
    "\n",
    "\n",
    "alt=[0,1,2,3]\n",
    "\n",
    "\n",
    "l_ind=0\n",
    "for h in range(len(alt)):\n",
    "    l_ind=deep_2_CNet(X,y,start_ind=l_ind,prompt=prompt,alt=alt[h])\n",
    "    print(l_ind)\n",
    "        \n",
    "alt=[0]        \n",
    "l_ind=0\n",
    "for h in range(len(alt)):\n",
    "    l_ind=deep_2_CNet(X,y,start_ind=l_ind,prompt=prompt,alt=alt[h],test=True)\n",
    "    print(l_ind)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_counts = []\n",
    "\n",
    "with open('counts.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    # Load the data from the line\n",
    "    unique_counts = np.fromstring(line, dtype=int, sep=' ')\n",
    "    # Append the unique counts from this line to the master list\n",
    "    all_counts.extend(unique_counts)\n",
    "\n",
    "# Now all_counts contains the counts from all lines, so we can plot a single histogram\n",
    "plt.hist(all_counts, bins='auto')  # 'auto' chooses bin number automatically\n",
    "plt.title('Histogram of Unique Counts')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path='/home/mo/Desktop/IWR/Cell_GT_Proj/red_dots'\n",
    "out_path='/home/mo/Desktop/IWR/Cell_GT_Proj/CNet_cells_rd/'\n",
    "\n",
    "\n",
    "red_dots2Cnet(in_path,out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the image folder\n",
    "image_folder = \"/home/mo/Desktop/IWR/Cell_GT_Proj/image_log/val\"\n",
    "\n",
    "# Create a new folder for the combined images\n",
    "output_folder = \"/home/mo/Desktop/IWR/Cell_GT_Proj/image_log/assembled_val\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Get a list of all image files in the folder\n",
    "image_files = [filename for filename in os.listdir(image_folder) if filename.endswith(\".png\")]\n",
    "\n",
    "# Process each set of corresponding images\n",
    "for image_file in image_files:\n",
    "    # Extract the common identifier from the image filename\n",
    "    identifier = image_file.split(\"_gs-\", 1)[1].split(\".\")[0]\n",
    "\n",
    "    # Construct the filenames of the three corresponding images\n",
    "    samples_file = os.path.join(image_folder, f\"samples_cfg_scale_9.00_gs-{identifier}.png\")\n",
    "    reconstruction_file = os.path.join(image_folder, f\"reconstruction_gs-{identifier}.png\")\n",
    "    control_file = os.path.join(image_folder, f\"control_gs-{identifier}.png\")\n",
    "\n",
    "    # Open the images\n",
    "    samples_image = Image.open(samples_file)\n",
    "    reconstruction_image = Image.open(reconstruction_file)\n",
    "    control_image = Image.open(control_file)\n",
    "\n",
    "    # Resize the images by half\n",
    "    new_size = (samples_image.width // 4, samples_image.height // 4)\n",
    "    samples_image = samples_image.resize(new_size)\n",
    "    reconstruction_image = reconstruction_image.resize(new_size)\n",
    "    control_image = control_image.resize(new_size)\n",
    "\n",
    "    # Create a new image with the combined images\n",
    "    combined_image = Image.new(\"RGB\", (new_size[0], new_size[1] * 2))\n",
    "    combined_image.paste(samples_image, (0, 0))\n",
    "    #combined_image.paste(reconstruction_image, (0, new_size[1]))\n",
    "    combined_image.paste(control_image, (0, new_size[1]))\n",
    "\n",
    "    # Save the combined image in the output folder\n",
    "    output_file = os.path.join(output_folder, f\"combined_{identifier}.png\")\n",
    "    combined_image.save(output_file)\n",
    "\n",
    "    # Print the saved file path\n",
    "    print(f\"Combined image saved: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
