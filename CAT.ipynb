{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "#import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "\n",
    "import copy\n",
    "from typing import Optional, List\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "from ortools.graph.python import min_cost_flow\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import copy\n",
    "import os\n",
    "import random\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        #print('PE',self.pos_embedding[:token_embedding.size(0), :])\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
    "    \n",
    "    \n",
    "def collate_fn(batch_len,PAD_IDX,train=True,recon=False,run=12,path0='.'):\n",
    "    #print('batch',len(batch),batch)\n",
    "    src1_batch, src2_batch, y_batch,d_batch = [], [], [], []\n",
    "    for j in range(batch_len):\n",
    "        \n",
    "        if train:\n",
    "            E1,E2,A,D=loadgraph(path0=path0)\n",
    "        elif recon: \n",
    "            E1,E2,A,D=loadgraph(recon=True, train=False,run_r=run,t_r=j,path0=path0)\n",
    "            #print('recon',run)\n",
    "        else:\n",
    "            E1,E2,A,D=loadgraph(train=False,path0=path0)\n",
    "        #print('src_sample',src_sample)\n",
    "        #print(A)\n",
    "        if torch.sum(A) != 0:\n",
    "            src1_batch.append(E1)\n",
    "            #print('emb',src_batch[-1])\n",
    "            src2_batch.append(E2)\n",
    "            y_batch.append(A)\n",
    "            d_batch.append(D)\n",
    "        \n",
    "        \n",
    "    #print('src_batch',src1_batch[3])\n",
    "    #print('src2_batch',src2_batch[3])\n",
    "    #print('src_batch s',len(src_batch))\n",
    "    src1_batch = pad_sequence(src1_batch, padding_value=PAD_IDX)\n",
    "    #print('src_batch',src_batch)\n",
    "    #print('src_batch s',src_batch.size())\n",
    "    src2_batch = pad_sequence(src2_batch, padding_value=PAD_IDX)\n",
    "    \n",
    "    \n",
    "    #print('src1',src1_batch[:,0,:],src1_batch[:,0,:].size())\n",
    "    #print('src2',src2_batch[:,0,:],src2_batch[:,0,:].size())\n",
    "    #print('y',y_batch)\n",
    "    ##\n",
    "    return src1_batch, src2_batch,y_batch,d_batch\n",
    "\n",
    "\n",
    "def loadgraph(train=True,run_r=None,easy=False,recon=False,t_r=None,path0='.'):\n",
    "    \n",
    "    convert_tensor = transforms.ToTensor()\n",
    "    if train:\n",
    "        run=select_random_run(path0)\n",
    "        \n",
    "        E=np.loadtxt(path0+'/'+str(run)+'/'+'embed.txt')\n",
    "        #print('E',E.shape)\n",
    "        id,tt = np.loadtxt(path0+'/'+str(run)+'/'+'timetable.txt', delimiter='\\t', usecols=(0,1), unpack=True)\n",
    "        A=np.loadtxt(path0+'/'+str(run)+'_GT'+'/TRA/'+'A.txt')\n",
    "        D=np.loadtxt(path0+'/'+str(run)+'/'+'D.txt')\n",
    "        bg=A[0]\n",
    "        for i in range(len(A)):\n",
    "            for j in range(len(A)):\n",
    "                if i>j:\n",
    "                    A[i,j]=0\n",
    "        #A=A+np.eye(len(A), dtype=int)\n",
    "        \n",
    "        t = np.random.randint(find_max_t(path0+'/'+str(run))) #!!!!!!!!how many t??\n",
    "        id1 = id[tt==t].astype(int)\n",
    "        if t==0:\n",
    "            id1=id1[1:]\n",
    "        id2 = id[tt==(t+1)].astype(int)\n",
    "        \n",
    "        #print(run,t,id1,id2)\n",
    "        \n",
    "        E1 = E[id1-1]\n",
    "        E2 = E[id2-1]\n",
    "       \n",
    "        E_bg = E[0]\n",
    "        \n",
    "        E1=np.concatenate((np.array([E_bg]), E1), axis=0)\n",
    "        E2=np.concatenate((np.array([E_bg]), E2), axis=0)\n",
    "        \n",
    "     \n",
    "        \n",
    "        A=A[id1-1]\n",
    "        \n",
    "        A=A[:,id2-1]\n",
    "        \n",
    "        \n",
    "        D=D[id1-1]\n",
    "        D=D[:,id2-1]\n",
    "        \n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "        #print(bg[id1-1])\n",
    "        #print(bg[id2-1])\n",
    "        \n",
    "        \n",
    "        A=np.concatenate((np.array([bg[id2-1]]), A), axis=0)\n",
    "        \n",
    "        bg_a=np.append(1,bg[id1-1])\n",
    "        #print(bg_a)\n",
    "        A=np.concatenate((np.array([bg_a]).T, A), axis=1)\n",
    "        \n",
    "        bg_b = np.append(0,np.zeros(len(bg[id1-1])))\n",
    "        \n",
    "        D=np.concatenate((np.array([np.zeros(len(bg[id2-1]))]), D), axis=0)\n",
    "        D=np.concatenate((np.array([bg_b]).T, D), axis=1)\n",
    "        \n",
    "        #print(D)\n",
    "        #print(np.dot(E1,E2.T))\n",
    "        \n",
    "    elif recon: \n",
    "        run=run_r\n",
    "        #print('recon_run',run)\n",
    "        E=np.loadtxt(path0+'/'+str(run)+'/'+'embed.txt')\n",
    "        #print('E',E.shape)\n",
    "        id,tt = np.loadtxt(path0+'/'+str(run)+'/'+'timetable.txt', delimiter='\\t', usecols=(0,1), unpack=True)\n",
    "        A=np.loadtxt(path0+'/'+str(run)+'_GT'+'/TRA/'+'A.txt')\n",
    "        D=np.loadtxt(path0+'/'+str(run)+'/'+'D.txt')\n",
    "        bg=A[0]\n",
    "        for i in range(len(A)):\n",
    "            for j in range(len(A)):\n",
    "                if i>j:\n",
    "                    A[i,j]=0\n",
    "        #A=A+np.eye(len(A), dtype=int)\n",
    "        \n",
    "        \n",
    "        #print(id)\n",
    "        t = t_r\n",
    "        #print(run,t,id1,id2)\n",
    "        if t < find_max_t(path0+'/'+str(run)):\n",
    "            id1 = id[tt==t].astype(int)\n",
    "            if t==0:\n",
    "                id1=id1[1:]\n",
    "            id2 = id[tt==(t+1)].astype(int)\n",
    "        else:\n",
    "            return torch.zeros(2), torch.zeros(2), torch.zeros(2), torch.zeros(2)\n",
    "        \n",
    "        #print(run,t,id1,id2)\n",
    "        \n",
    "        E1 = E[id1-1]\n",
    "        E2 = E[id2-1]\n",
    "       \n",
    "        E_bg = E[0]\n",
    "        \n",
    "        E1=np.concatenate((np.array([E_bg]), E1), axis=0)\n",
    "        E2=np.concatenate((np.array([E_bg]), E2), axis=0)\n",
    "        \n",
    "     \n",
    "        \n",
    "        A=A[id1-1]\n",
    "        \n",
    "        A=A[:,id2-1]\n",
    "        \n",
    "        \n",
    "        \n",
    "        D=D[id1-1]\n",
    "        D=D[:,id2-1]\n",
    "        \n",
    "        \n",
    "        #print(A)\n",
    "        \n",
    "        \n",
    "        #print(bg[id1-1])\n",
    "        #print(bg[id2-1])\n",
    "        \n",
    "        \n",
    "        A=np.concatenate((np.array([bg[id2-1]]), A), axis=0)\n",
    "        \n",
    "        bg_a=np.append(1,bg[id1-1])\n",
    "        A=np.concatenate((np.array([bg_a]).T, A), axis=1)\n",
    "       \n",
    "        #print(E1,E2)\n",
    "        \n",
    "        bg_b = np.append(0,np.zeros(len(bg[id1-1])))\n",
    "    \n",
    "    \n",
    "    \n",
    "        D=np.concatenate((np.array([np.zeros(len(bg[id2-1]))]), D), axis=0)\n",
    "        D=np.concatenate((np.array([bg_b]).T, D), axis=1)\n",
    "     \n",
    "        \n",
    "        \n",
    "    else:\n",
    "        #print('eval')\n",
    "        run=select_random_run(path0)\n",
    "        E=np.loadtxt(path0+'/'+str(run)+'/'+'embed.txt')\n",
    "        id,tt = np.loadtxt(path0+'/'+str(run)+'/'+'timetable.txt', delimiter='\\t', usecols=(0,1), unpack=True)\n",
    "        A=np.loadtxt(path0+'/'+str(run)+'_GT'+'/TRA/'+'A.txt')\n",
    "        D=np.loadtxt(path0+'/'+str(run)+'/'+'D.txt')\n",
    "        bg=A[0]\n",
    "        for i in range(len(A)):\n",
    "            for j in range(len(A)):\n",
    "                if i>j:\n",
    "                    A[i,j]=0\n",
    "        #A=A+np.eye(len(A), dtype=int)\n",
    "        \n",
    "        t = np.random.randint(find_max_t(path0+'/'+str(run))) #!!!!!!!!how many t??\n",
    "        id1 = id[tt==t].astype(int)\n",
    "        if t==0:\n",
    "            id1=id1[1:]\n",
    "        id2 = id[tt==(t+1)].astype(int)\n",
    "        \n",
    "        #print(run,t,id1,id2)\n",
    "        \n",
    "        E1 = E[id1-1]\n",
    "        E2 = E[id2-1]\n",
    "       \n",
    "        E_bg = E[0]\n",
    "        \n",
    "        E1=np.concatenate((np.array([E_bg]), E1), axis=0)\n",
    "        E2=np.concatenate((np.array([E_bg]), E2), axis=0)\n",
    "        \n",
    "     \n",
    "        \n",
    "        A=A[id1-1]\n",
    "        \n",
    "        A=A[:,id2-1]\n",
    "        \n",
    "        #print(A)\n",
    "        \n",
    "        D=D[id1-1]\n",
    "        D=D[:,id2-1]\n",
    "        \n",
    "       \n",
    "        \n",
    "        #print(bg[id1-1])\n",
    "        #print(bg[id2-1])\n",
    "        \n",
    "        \n",
    "        A=np.concatenate((np.array([bg[id2-1]]), A), axis=0)\n",
    "        \n",
    "        bg_a=np.append(1,bg[id1-1])\n",
    "        A=np.concatenate((np.array([bg_a]).T, A), axis=1)\n",
    "        \n",
    "        bg_b = np.append(0,np.zeros(len(bg[id1-1])))\n",
    "        \n",
    "        D=np.concatenate((np.array([np.zeros(len(bg[id2-1]))]), D), axis=0)\n",
    "        D=np.concatenate((np.array([bg_b]).T, D), axis=1)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    if easy:\n",
    "        n1=np.random.randint(3,6)\n",
    "        n2=n1+np.random.randint(2)\n",
    "        E1=np.ones((n1,6))\n",
    "        E2=np.ones((n2,6))*3\n",
    "        A=np.ones((n1,n2))\n",
    "    \n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    D=D.astype(np.float32)\n",
    "    \n",
    "    vd = np.vectorize(d_mask_function,otypes=[float])\n",
    "    \n",
    "    D = vd(D,0.15,-2.0)\n",
    "    \n",
    "    \n",
    "    E1=E1.astype(np.float32)\n",
    "    E2=E2.astype(np.float32)\n",
    "    A=A.astype(np.float32)\n",
    "    #A=A.astype(np.float32)\n",
    "    \n",
    "    \n",
    "    \n",
    "    E1=convert_tensor(E1) \n",
    "    E2=convert_tensor(E2) \n",
    "    A=convert_tensor(A)\n",
    "    D=convert_tensor(D)\n",
    "    \n",
    "    #print(E1[0].size(),E1[0])\n",
    "    #print(E2[0].size(),E2[0])\n",
    "    #print(A,A.size())\n",
    "    #print('E',E.size())\n",
    "    \n",
    "    return E1[0],E2[0],A[0],D[0]\n",
    "\n",
    "def create_mask(src,PAD_IDX):\n",
    "    \n",
    "    src= src[:,:,0]\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    #print('src_padding_mask',src_padding_mask,src_padding_mask.size())\n",
    "    return src_padding_mask\n",
    "\n",
    "\n",
    "def train_easy(model, optimizer, loss_function, epochs,scheduler,verbose=True,eval=True):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    loss_over_time = []\n",
    "    test_error = []\n",
    "    perf=[]\n",
    "    t0 = time.time()\n",
    "    i=0\n",
    "    while i < epochs:\n",
    "        print(i)\n",
    "        \n",
    "        #u = np.random.random_integers(4998) #4998 for 3_GT\n",
    "        src1, src2, y = collate_fn(10,-100)\n",
    "        \n",
    "        #print('src_batch',src1)\n",
    "        #print('src_batch s',src1.size())\n",
    "        \n",
    "        src_padding_mask1=create_mask(src1,-100)\n",
    "        src_padding_mask2=create_mask(src2,-100)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        '''#trysimplesttrans'''\n",
    "        \n",
    "        #output=model(tgt,tgt)\n",
    "        \n",
    "        \n",
    "        \n",
    "        output1,output2 = model(src1,src2,src_padding_mask1,src_padding_mask2)  \n",
    "        #output = model(src)   #!!!!!!!\n",
    "        #imshow(src1)\n",
    "        #imshow(tgt1)\n",
    "        \n",
    "        #print('out1',output1,output1.size())\n",
    "        #print('out2',output2,output2.size())\n",
    "        \n",
    "        \n",
    "\n",
    " \n",
    "        #print('train_sizes',src.size(),output[:,:n_nodes,:n_nodes].size(),y.size())\n",
    "        \n",
    "        \n",
    "        epoch_loss = loss_function(output1, src1)\n",
    "        epoch_loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        if i % 5 == 0 and i>0:\n",
    "            t1 = time.time()\n",
    "            epochs_per_sec = 10/(t1 - t0) \n",
    "            if verbose:\n",
    "                print(f\"Epoch: {i} loss {epoch_loss.item()} @ {epochs_per_sec} epochs per second\")\n",
    "            loss_over_time.append(epoch_loss.item())\n",
    "            t0 = t1\n",
    "            np.savetxt('./'+'train_loss.txt', np.c_[loss_over_time],delimiter='\\t',header='trainloss')\n",
    "            perf.append(epochs_per_sec)\n",
    "        try:\n",
    "            print(c)\n",
    "            d=len(loss_over_time)\n",
    "            if np.sqrt((np.mean(loss_over_time[d-10:-1])-np.mean(loss_over_time[d-20:d-10]))**2) < np.std(loss_over_time[d-10:-1])/50:\n",
    "                print('loss not reducing')\n",
    "                print(np.mean(loss_over_time[d-10:-1])-np.mean(loss_over_time[d-20:d-10]))\n",
    "                print(np.std(loss_over_time[d-10:-1])/10)\n",
    "                print(d)\n",
    "                break\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        i=i+1\n",
    "        \n",
    "        '''\n",
    "        if i % 5 == 0 and i>0:\n",
    "        \n",
    "    \n",
    "        \n",
    "            if eval:\n",
    "                u = np.random.random_integers(490)\n",
    "                src_t, tgt_t, y_t = loadgraph(easy=True)\n",
    "                \n",
    "                n_nodes=0\n",
    "                for h in range(len(src_t[0])):\n",
    "                    if torch.sum(src_t[0][h])!=0:\n",
    "                        n_nodes=n_nodes+1\n",
    "                \n",
    "                max_len=len(src_t[0])\n",
    "                \n",
    "                output_t = model(src_t,tgt_t,n_nodes)\n",
    "\n",
    "                test_loss = loss_function(output_t[:,:n_nodes,:n_nodes], y_t)\n",
    "\n",
    "                test_error.append(test_loss.item())\n",
    "                \n",
    "                np.savetxt('./'+'test_loss.txt', np.c_[test_error],delimiter='\\t',header='testloss')\n",
    "\n",
    "            \n",
    "        \n",
    "        i=i+1\n",
    "            \n",
    "    print('Mean Performance', np.mean(perf))\n",
    "    return model, loss_over_time, test_error\n",
    "    '''\n",
    "        \n",
    "        \n",
    "class makeAdja:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def forward(self,z:Tensor,\n",
    "                mask1: Tensor,\n",
    "                mask2: Tensor):\n",
    "        Ad = []\n",
    "        for i in range(z.size(0)):\n",
    "            n=len([i for i, e in enumerate(mask1[i]) if e != True])\n",
    "            m=len([i for i, e in enumerate(mask2[i]) if e != True])\n",
    "            Ad.append(z[i,0:n,0:m])\n",
    "        \n",
    "        \n",
    "        return Ad\n",
    "    \n",
    "    \n",
    "    \n",
    "def train_epoch(model, optimizer,loss_fn,train_path):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    \n",
    "    src1, src2, y,d = collate_fn(31,-100,path0=train_path)\n",
    "        \n",
    "    src1= src1.to(DEVICE)\n",
    "    src2= src2.to(DEVICE)\n",
    "    \n",
    "    \n",
    "    src_padding_mask1=create_mask(src1,-100)\n",
    "    src_padding_mask2=create_mask(src2,-100)\n",
    "    \n",
    "    #print('src1',src1.size(),src1)\n",
    "    \n",
    "    #print('src1_mask',src_padding_mask1.size(),src_padding_mask1)\n",
    "    #print('src1_0',src1[:,0,:].size(),src1[:,0,:])\n",
    "    #print('src1_0_mask',src_padding_mask1.size(),src_padding_mask1[:,0,:])\n",
    "    try:\n",
    "        Ad,out1,out2,out_dec1,src1_t1,src2_t2 = model(src1,src2,src_padding_mask1,src_padding_mask2)\n",
    "    except:    \n",
    "        Ad = model(src1,src2,src_padding_mask1,src_padding_mask2)\n",
    "        \n",
    "        \n",
    "    #Ad = complete_postprocess(Ad,d,0.01) #!!!!!!!!!\n",
    "    print('Ad',Ad[0],y[0])\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    \n",
    "    loss = loss_fn.loss(Ad,y)\n",
    "    \n",
    "    #print(Ad[0],y[0])\n",
    "    #print('l',loss)\n",
    "    #print('l',loss.item() / len(src1))\n",
    "    \n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    losses += loss.item()\n",
    "    \n",
    "    \n",
    "\n",
    "    return losses / len(src1)\n",
    "\n",
    "\n",
    "def train_epoch_post_process(model, optimizer,loss_fn):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    \n",
    "    src1, src2, y,d = collate_fn(31,-100)\n",
    "        \n",
    "    src1= src1.to(DEVICE)\n",
    "    src2= src2.to(DEVICE)\n",
    "    \n",
    "    src_padding_mask1=create_mask(src1,-100)\n",
    "    src_padding_mask2=create_mask(src2,-100)\n",
    "    \n",
    "    Ad = model(src1,src2,src_padding_mask1,src_padding_mask2)\n",
    "    \n",
    "    #Ad = complete_postprocess(Ad,d,0.01)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "   \n",
    "    loss = loss_fn.loss(Ad,y)\n",
    "    \n",
    "    print(Ad[0])\n",
    "    print(y[0])\n",
    "    #print('l',loss)\n",
    "    #print('l',loss.item() / len(src1))\n",
    "    \n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    losses += loss.item()\n",
    "    \n",
    "    \n",
    "\n",
    "    return losses / len(src1)\n",
    "\n",
    "\n",
    "\n",
    "class Loss():\n",
    "    def __init__(self,pen,tra_to_tens=False):\n",
    "        self.pen=pen\n",
    "        self.trans=tra_to_tens\n",
    "        \n",
    "    def loss (self,Ad,y):\n",
    "        convert_tensor = transforms.ToTensor()\n",
    "        loss=0\n",
    "        \n",
    "        for i in range(len(Ad)):\n",
    "            l = nn.CrossEntropyLoss()\n",
    "            if self.trans:\n",
    "                Ad[i]=convert_tensor(Ad[i])[0]\n",
    "                \n",
    "            \n",
    "            #print(Ad[i], y[i])\n",
    "            \n",
    "            s = l(Ad[i], y[i])\n",
    "            #if i==0:\n",
    "             #   print('loss',Ad[i], y[i],s)\n",
    "            loss=loss+s\n",
    "                \n",
    "        if self.trans:\n",
    "            loss = Variable(loss, requires_grad = True)\n",
    "        return loss\n",
    "    \n",
    "\n",
    "\n",
    "def evaluate(model,loss_fn,test_path):\n",
    "    #model.eval()\n",
    "    losses = 0\n",
    "\n",
    "    src1, src2, y,d = collate_fn(31,-100,train=False,path0=test_path)\n",
    "        \n",
    "    src1= src1.to(DEVICE)\n",
    "    src2= src2.to(DEVICE)\n",
    "    \n",
    "    src_padding_mask1=create_mask(src1,-100)\n",
    "    src_padding_mask2=create_mask(src2,-100)\n",
    "    \n",
    "    try:\n",
    "        Ad,out1,out2,out_dec1,src1_t1,src2_t2 = model(src1,src2,src_padding_mask1,src_padding_mask2)\n",
    "    except:    \n",
    "        Ad = model(src1,src2,src_padding_mask1,src_padding_mask2)\n",
    "\n",
    "    \n",
    "   \n",
    "    loss = loss_fn.loss(Ad,y)\n",
    "    \n",
    "    losses += loss.item()\n",
    "    \n",
    "        \n",
    "\n",
    "    return losses / len(src1)\n",
    "\n",
    "\n",
    "def postprocess(A):\n",
    "    pp_A=[]\n",
    "    for i in range(len(A)):\n",
    "        ind=torch.argmax(A[i], dim=0)\n",
    "        B=np.zeros(A[i].shape)\n",
    "        for j in range(len(ind)):\n",
    "            B[ind[j],j]=1\n",
    "        pp_A.append(B)\n",
    "    return pp_A\n",
    "\n",
    "def square(m):\n",
    "    return m.shape[0] == m.shape[1]\n",
    "\n",
    "\n",
    "def postprocess_2(Ad):\n",
    "    pp_A=[]\n",
    "    for h in range(len(Ad)):\n",
    "        row_ind, col_ind = linear_sum_assignment(1-Ad[h].detach().numpy())\n",
    "\n",
    "        z=np.zeros(Ad[h].shape)\n",
    "\n",
    "\n",
    "        for i,j in zip(row_ind, col_ind):\n",
    "            z[i,j]=1\n",
    "    \n",
    "        \n",
    "        if square(z):\n",
    "            pp_A.append(z)\n",
    "            \n",
    "        \n",
    "        \n",
    "        else:\n",
    "            zero_col=np.where(~z.any(axis=0))[0]\n",
    "            c_A=Ad[h].detach().numpy()\n",
    "            z[:,zero_col] = c_A[:,zero_col]\n",
    "            #print(z)\n",
    "            pp_A.append(z)\n",
    "        \n",
    "            \n",
    "       # else:\n",
    "        #    z2 = np.zeros(Ad[h].shape)\n",
    "        #    zero_col=np.where(~z.any(axis=0))[0]\n",
    "            \n",
    "         #   for k,l in zip(ind,zero_col):\n",
    "         #       z2[k,l]=1\n",
    "         #   pp_A.append(z+z2)  \n",
    "        \n",
    "    return pp_A\n",
    "\n",
    "\n",
    "\n",
    "def postprocess_3(Ad):\n",
    "    pp_A=[]\n",
    "    \n",
    "    row_ind, col_ind = linear_sum_assignment(1-Ad[0])\n",
    "    \n",
    "    print(1-Ad[0])\n",
    "    print(row_ind, col_ind)\n",
    "    \n",
    "    z=np.zeros(Ad[0].shape)\n",
    "\n",
    "\n",
    "    for i,j in zip(row_ind, col_ind):\n",
    "        z[i,j]=1\n",
    "    \n",
    "    \n",
    "    print(z)\n",
    "    '''\n",
    "    for h in range(len(Ad)):\n",
    "        row_ind, col_ind = linear_sum_assignment(1-Ad[h])\n",
    "\n",
    "        z=np.zeros(Ad[h].shape)\n",
    "\n",
    "\n",
    "        for i,j in zip(row_ind, col_ind):\n",
    "            z[i,j]=1\n",
    "    \n",
    "        \n",
    "        if square(z):\n",
    "            pp_A.append(z)\n",
    "            \n",
    "        \n",
    "        \n",
    "        else:\n",
    "            zero_col=np.where(~z.any(axis=0))[0]\n",
    "            c_A=Ad[h].detach().numpy()\n",
    "            z[:,zero_col] = c_A[:,zero_col]\n",
    "            #print(z)\n",
    "            pp_A.append(z)\n",
    "        \n",
    "            \n",
    "       # else:\n",
    "        #    z2 = np.zeros(Ad[h].shape)\n",
    "        #    zero_col=np.where(~z.any(axis=0))[0]\n",
    "            \n",
    "         #   for k,l in zip(ind,zero_col):\n",
    "         #       z2[k,l]=1\n",
    "         #   pp_A.append(z+z2) \n",
    "    '''\n",
    "        \n",
    "    return pp_A\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def postprocess_linAss(Ad):\n",
    "    pp_A=[]\n",
    "    for h in range(len(Ad)):\n",
    "        row_ind, col_ind = linear_sum_assignment(1-Ad[h].detach().numpy())\n",
    "\n",
    "        z=np.zeros(Ad[h].shape)\n",
    "\n",
    "\n",
    "        for i,j in zip(row_ind, col_ind):\n",
    "            z[i,j]=1\n",
    "    \n",
    "        \n",
    "        if square(z):\n",
    "            pp_A.append(z)\n",
    "        else:\n",
    "            f=Ad[h].detach().numpy()\n",
    "            l=np.ones(len(f))*2\n",
    "            l=l.astype(int)\n",
    "            \n",
    "            \n",
    "            f2=np.repeat(f, l, axis=0)\n",
    "            row_ind, col_ind = linear_sum_assignment(1-f)\n",
    "            z=np.zeros(f.shape)\n",
    "            \n",
    "            for i,j in zip(row_ind, col_ind):\n",
    "                z[i,j]=1\n",
    "\n",
    "            f2[0::2, :] = z[:] \n",
    "\n",
    "            row_ind_f, col_ind_f = linear_sum_assignment(1-f2)\n",
    "\n",
    "\n",
    "            z3=np.zeros(f2.shape)\n",
    "\n",
    "\n",
    "            for i,j in zip(row_ind_f, col_ind_f):\n",
    "                z3[i,j]=1\n",
    "\n",
    "            f_add = z3[0::2, :] + z3[1::2, :]\n",
    "            \n",
    "            pp_A.append(f_add)\n",
    "\n",
    "        \n",
    "    return pp_A\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def postprocess_MinCostAss(Ad,a):\n",
    "    pp_A=[]\n",
    "    for h in range(len(Ad)):\n",
    "        smcf = min_cost_flow.SimpleMinCostFlow()\n",
    "        c_A = Ad[h]\n",
    "        \n",
    "        #left_n=c_A.size(0)\n",
    "        #right_n=c_A.size(1)\n",
    "        \n",
    "        left_n=c_A.shape[0]\n",
    "        right_n=c_A.shape[1]\n",
    "        \n",
    "        \n",
    "        st=np.zeros(left_n)\n",
    "        con= np.ones(right_n) \n",
    "        for v in range(left_n-1):\n",
    "            con= np.append(con, np.ones(right_n)*(v+2))\n",
    "        #print('con',con) \n",
    "        si = np.arange(left_n+1,left_n+right_n+1)\n",
    "        start_nodes = np.concatenate((st,np.array(con),si))\n",
    "        start_nodes = np.append(start_nodes,0)\n",
    "        start_nodes = [int(x) for x in start_nodes ]\n",
    "        #print(start_nodes)\n",
    "        \n",
    "        st_e = np.arange(1,left_n+1)\n",
    "        con_e = si\n",
    "        for j in range(left_n-1):\n",
    "            con_e = np.append(con_e,si)\n",
    "            \n",
    "        si_e = np.ones(right_n)*left_n+right_n+1\n",
    "        \n",
    "        end_nodes = np.concatenate((st_e,np.array(con_e),si_e))\n",
    "        end_nodes = np.append(end_nodes,si_e[-1])\n",
    "        end_nodes = [int(x) for x in end_nodes ]\n",
    "        #print(end_nodes)\n",
    "        \n",
    "        \n",
    "        tasks = np.max([right_n,left_n])\n",
    "        \n",
    "        cap_0 = np.ones(left_n)\n",
    "        cap_0[0]=right_n-1\n",
    "        \n",
    "        cap_left=np.ones(right_n)\n",
    "        cap_left[0]=right_n\n",
    "        \n",
    "        capacities = np.concatenate((cap_0,np.ones(len(con_e)),cap_left))\n",
    "        capacities = np.append(capacities,tasks)\n",
    "        capacities = [int(x) for x in capacities]\n",
    "        #print(capacities)\n",
    "        \n",
    "        '''\n",
    "        c_A[0]=c_A[0]/c_A[0,0]\n",
    "        c_A[0]=c_A[0]/(1.01*np.max(c_A[0]))\n",
    "        c_A[:,0]=c_A[:,0]/c_A[0,0]\n",
    "        c_A[:,0]=c_A[:,0]/(1.01*np.max(c_A[:,0]))\n",
    "        '''\n",
    "        \n",
    "        #print(c_A)\n",
    "        c= c_A.flatten()                          \n",
    "        #c=torch.flatten(c_A)\n",
    "        #c=c.detach().numpy()  \n",
    "                                    \n",
    "                                    \n",
    "        c=(1-c)*10**4\n",
    "        \n",
    "        #print(c)\n",
    "                                    \n",
    "        costs = np.concatenate((np.zeros(left_n),c,np.zeros(right_n)))\n",
    "        costs = np.append(costs,a*np.mean(c))                            \n",
    "        costs = [int(x) for x in costs]\n",
    "                                    \n",
    "        #print(costs)\n",
    "        \n",
    "        source = 0\n",
    "        sink = left_n+right_n+1\n",
    "        \n",
    "        supplies= tasks \n",
    "        \n",
    "        supplies=np.append(supplies,np.ones(left_n))\n",
    "        supplies=np.append(supplies,np.zeros(right_n))\n",
    "        \n",
    "        #supplies=np.append(supplies,np.zeros(left_n+right_n))\n",
    "        \n",
    "        supplies=np.append(supplies,-(tasks+left_n))\n",
    "        \n",
    "        supplies = [int(x) for x in supplies]\n",
    "        #print(supplies)\n",
    "        #print('____________________________________')\n",
    "        # Add each arc.\n",
    "        for i in range(len(start_nodes)):\n",
    "            #print(start_nodes[i], end_nodes[i],capacities[i], costs[i])\n",
    "            smcf.add_arc_with_capacity_and_unit_cost(start_nodes[i], end_nodes[i],\n",
    "                                                 capacities[i], costs[i])\n",
    "        # Add node supplies.\n",
    "        for i in range(len(supplies)):\n",
    "            smcf.set_node_supply(i, supplies[i])\n",
    "\n",
    "        # Find the minimum cost flow between node 0 and node 10.\n",
    "        status = smcf.solve()\n",
    "\n",
    "        if status == smcf.OPTIMAL:\n",
    "            #print('Total cost = ', smcf.optimal_cost())\n",
    "            #print()\n",
    "            row_ind=[]\n",
    "            col_ind=[]\n",
    "            for arc in range(smcf.num_arcs()):\n",
    "                # Can ignore arcs leading out of source or into sink.\n",
    "                if smcf.tail(arc) != source and smcf.head(arc) != sink:\n",
    "\n",
    "                    # Arcs in the solution have a flow value of 1. Their start and end nodes\n",
    "                    # give an assignment of worker to task.\n",
    "                    if smcf.flow(arc) > 0:\n",
    "                        #p#rint('Worker %d assigned to task %d.  Cost = %d Flow = %d' %\n",
    "                        #      (smcf.tail(arc), smcf.head(arc), smcf.unit_cost(arc),smcf.flow(arc)))\n",
    "                        row_ind.append(smcf.tail(arc)-1)\n",
    "                        col_ind.append(smcf.head(arc)-left_n-1)\n",
    "            z=np.zeros((left_n,right_n))\n",
    "            \n",
    "            for i,j in zip(row_ind, col_ind):\n",
    "                z[i,j]=1\n",
    "             \n",
    "            \n",
    "            #print('z_orig',z)\n",
    "            s=np.sum(z,axis=1)\n",
    "            for e in range(len(s)):\n",
    "                if s[e]>1 and e!=0:\n",
    "                    z[e,0]=0\n",
    "            #print('z_bg_cor',z)      \n",
    "            if (~z.any(axis=0)).any():\n",
    "                z_col_ind=np.where(~z.any(axis=0))[0]\n",
    "                z[:,z_col_ind]=c_A[:,z_col_ind]\n",
    "                #print('---------z_0_col',z)\n",
    "                z=postprocess_MinCostAss(np.array([z]),2*a)[0]\n",
    "                #print('z_0_col_after',z)\n",
    "\n",
    "                    \n",
    "            pp_A.append(z)\n",
    "                    \n",
    "                #else:\n",
    "                    #print('Worker %d assigned to task %d.  Cost = %d  Flow = %d' %\n",
    "                      #    (smcf.tail(arc), smcf.head(arc), smcf.unit_cost(arc),smcf.flow(arc)))\n",
    "                \n",
    "        else:\n",
    "            print('There was an issue with the min cost flow input.')\n",
    "            print(f'Status: {status}')\n",
    "          \n",
    "\n",
    "\n",
    "\n",
    "    return pp_A\n",
    "\n",
    "      \n",
    "'''\n",
    "\n",
    "    start_nodes = np.zeros(c_A.size(0)) + [\n",
    "        1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3\n",
    "    ] + [4, 5, 6, 7]\n",
    "    end_nodes = [1, 2, 3] + [4, 5, 6, 7, 4, 5, 6, 7, 4, 5, 6, 7] + [8,8,8,8]\n",
    "    capacities = [2, 2, 2] + [\n",
    "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
    "    ] + [2, 2, 2, 2]\n",
    "    costs = (\n",
    "        [0, 0, 0] +\n",
    "        c +\n",
    "        [0, 0, 0 ,0])\n",
    "\n",
    "    source = 0\n",
    "    sink = 8\n",
    "    tasks = 4\n",
    "    supplies = [tasks, 0, 0, 0, 0, 0, 0, 0, -tasks]\n",
    "\n",
    "    # Add each arc.\n",
    "    for i in range(len(start_nodes)):\n",
    "        smcf.add_arc_with_capacity_and_unit_cost(start_nodes[i], end_nodes[i],\n",
    "                                                 capacities[i], costs[i])\n",
    "    # Add node supplies.\n",
    "    for i in range(len(supplies)):\n",
    "        smcf.set_node_supply(i, supplies[i])\n",
    "\n",
    "    # Find the minimum cost flow between node 0 and node 10.\n",
    "    status = smcf.solve()\n",
    "\n",
    "    if status == smcf.OPTIMAL:\n",
    "        print('Total cost = ', smcf.optimal_cost())\n",
    "        print()\n",
    "        for arc in range(smcf.num_arcs()):\n",
    "            # Can ignore arcs leading out of source or into sink.\n",
    "            if smcf.tail(arc) != source and smcf.head(arc) != sink:\n",
    "\n",
    "                # Arcs in the solution have a flow value of 1. Their start and end nodes\n",
    "                # give an assignment of worker to task.\n",
    "                if smcf.flow(arc) > 0:\n",
    "                    print('Worker %d assigned to task %d.  Cost = %d Flow = %d' %\n",
    "                          (smcf.tail(arc), smcf.head(arc), smcf.unit_cost(arc),smcf.flow(arc)))\n",
    "                    \n",
    "                #else:\n",
    "                    #print('Worker %d assigned to task %d.  Cost = %d  Flow = %d' %\n",
    "                      #    (smcf.tail(arc), smcf.head(arc), smcf.unit_cost(arc),smcf.flow(arc)))\n",
    "                \n",
    "    else:\n",
    "        print('There was an issue with the min cost flow input.')\n",
    "        print(f'Status: {status}')\n",
    "            pp_A.append(f_add)\n",
    "\n",
    "        \n",
    "    return pp_A\n",
    "\n",
    "'''\n",
    "def find_max_t(run_folder_path):\n",
    "    \"\"\"\n",
    "    Returns the highest PNG number (x) in the given run folder.\n",
    "    \"\"\"\n",
    "    png_files = [f for f in os.listdir(run_folder_path) if f.endswith('.png')]\n",
    "    \n",
    "    if not png_files:  # If the list is empty\n",
    "        return -1  # No PNG files in the folder\n",
    "\n",
    "    # Extract the numbers from filenames, convert to int, and sort\n",
    "    numbers = sorted([int(f.split('.')[0]) for f in png_files])\n",
    "\n",
    "    return numbers[-1]  # Return the last number which is the maximum\n",
    "\n",
    "def make_reconstructed_edgelist(A,run):\n",
    "    \n",
    "    e_start=[2,3,4]\n",
    "    e1=[]\n",
    "    e2=[]\n",
    "    \n",
    "    \n",
    "    for i in range(len(A)):\n",
    "        M=A[i]\n",
    "        print('M0',M)\n",
    "        X=M[0][1:]\n",
    "        M=M[1:,1:]\n",
    "        #print('M1',M)\n",
    "        \n",
    "        \n",
    "        for z in range(len(M)):\n",
    "            for j in range(len(M[0])):\n",
    "                e_mid=np.arange(e_start[-1]+1,e_start[-1]+len(M[0])+1)\n",
    "                if M[z,j]!=0:\n",
    "                    #print(z,e_start)\n",
    "                    e1.append(int(e_start[z]))\n",
    "                    #print('e',e_mid)\n",
    "                    e2.append(int(e_mid[j]))\n",
    "                if z==0 and X[j]!=0:\n",
    "                    e1.append(int(1))\n",
    "                    e2.append(int(e_mid[j]))\n",
    "                    \n",
    "        \n",
    "        e_start=e_mid\n",
    "        #print('mid',e_mid)\n",
    "    \n",
    "    \n",
    "    np.savetxt('./'+str(run)+'_GT'+'/'+'reconstruct.edgelist', np.c_[e1,e2], fmt='%i',delimiter='\\t')\n",
    "    return 0\n",
    "\n",
    "def d_mask_function(x,r_core,alpha):\n",
    "    if x < r_core:\n",
    "        return 1\n",
    "    else:\n",
    "        return (x/r_core)**alpha\n",
    "    \n",
    "    \n",
    "def get_run_folders(path):\n",
    "    \"\"\"Returns a list of run numbers from folders ending with '_GT'.\"\"\"\n",
    "    run_numbers = []\n",
    "    \n",
    "    for folder in os.listdir(path):\n",
    "        if folder.endswith(\"_GT\"):\n",
    "            run_number = int(folder.split('_')[0])\n",
    "            run_numbers.append(run_number)\n",
    "\n",
    "    return run_numbers\n",
    "\n",
    "def select_random_run(path):\n",
    "    \"\"\"Selects and returns a random run number.\"\"\"\n",
    "    run_numbers = get_run_folders(path)\n",
    "    if not run_numbers:\n",
    "        print(\"No valid runs found!\")\n",
    "        return None\n",
    "    \n",
    "    return random.choice(run_numbers)\n",
    "    \n",
    "    \n",
    "def complete_postprocess(Ad,d,a):\n",
    "    \n",
    "    Ad_n = []\n",
    "    #Ad_n=copy.deepcopy(Ad)\n",
    "    \n",
    "    for h in range(len(Ad)):\n",
    "        \n",
    "        A_t,ill_flag=treshold(Ad[h],t=0.5)\n",
    "        \n",
    "        #print('ill_flag',ill_flag)\n",
    "        #print(Ad[h],A_t)\n",
    "        if ill_flag==True:\n",
    "            #Ad[h]=np.multiply(Ad[h].detach().numpy(),d[h].detach().numpy())!!!!!!!!!!!\n",
    "            Ad[h]=Ad[h].detach().numpy()\n",
    "            A_t = postprocess_MinCostAss(np.array([Ad[h]]),a)[0]#!!!!!!!!\n",
    "        \n",
    "        \n",
    "        if isinstance(A_t, torch.Tensor):\n",
    "            A_t = A_t.detach().numpy()\n",
    "        #print(Ad[h],A_t)\n",
    "        Ad_n.append(A_t)\n",
    "    #Ad=postprocess_MinCostAss(Ad)\n",
    "\n",
    "\n",
    "\n",
    "    return Ad_n\n",
    "\n",
    "def treshold(matrix, t):\n",
    "    z=np.where(matrix >= t, 1, 0)\n",
    "    \n",
    "    ill_flag=False\n",
    "\n",
    "      \n",
    "    if (~z.any(axis=0)).any() or any(np.sum(z[:,1:], axis=0)>1):\n",
    "        ill_flag=True\n",
    "          \n",
    "    return z,ill_flag\n",
    "\n",
    "def err_perc(a,b):\n",
    "    w=0\n",
    "    s=0\n",
    "    for i in range(len(a)):\n",
    "        m=a[i]-b[i].detach().numpy()\n",
    "        w=w+0.5*np.sum(np.abs(m))\n",
    "        s=s+np.size(m)\n",
    "    \n",
    "    \n",
    "    print('w,s',w,s)\n",
    "    \n",
    "    return w*100/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99 0.87 0.05 0.08 0.77 0.11]\n",
      " [0.05 0.12 0.19 0.11 0.14 0.93]\n",
      " [0.07 0.12 0.45 0.89 0.23 0.05]\n",
      " [0.04 0.1  0.97 0.65 0.34 0.02]]\n",
      "[[1.   1.   1.   1.   1.   1.  ]\n",
      " [1.   0.75 0.07 0.1  0.08 0.8 ]\n",
      " [1.   0.69 0.07 0.88 0.34 0.02]\n",
      " [1.   0.1  0.9  0.05 0.84 0.02]]\n",
      "[[9.900e-01 8.700e-01 5.000e-02 8.000e-02 7.700e-01 1.100e-01]\n",
      " [5.000e-02 9.000e-02 1.330e-02 1.100e-02 1.120e-02 7.440e-01]\n",
      " [7.000e-02 8.280e-02 3.150e-02 7.832e-01 7.820e-02 1.000e-03]\n",
      " [4.000e-02 1.000e-02 8.730e-01 3.250e-02 2.856e-01 4.000e-04]]\n",
      "[[0.87 0.05 0.08 0.77 0.11]\n",
      " [0.12 0.19 0.11 0.14 0.93]\n",
      " [0.12 0.45 0.89 0.23 0.05]\n",
      " [0.1  0.97 0.65 0.34 0.02]]\n",
      "True\n",
      "0.2222222222222222\n",
      "tensor(0.8848)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "loadgraph() got an unexpected keyword argument 'run'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 37\u001b[0m\n\u001b[1;32m     30\u001b[0m loss \u001b[38;5;241m=\u001b[39m cross_entropy_loss(c, d)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n\u001b[0;32m---> 37\u001b[0m \u001b[43mloadgraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: loadgraph() got an unexpected keyword argument 'run'"
     ]
    }
   ],
   "source": [
    "a = np.array([[0.99, 0.87,0.05,0.08,0.77,0.11], [0.05, 0.12,0.19,0.11,0.14,0.93],[0.07, 0.12,0.45,0.89,0.23,0.05],[0.04, 0.1,0.97,0.65,0.34,0.02]])\n",
    "print(a)\n",
    "\n",
    "b = np.array([[1, 1,1,1,1,1], [1, 0.75,0.07,0.1,0.08,0.8],[1, 0.69,0.07,0.88,0.34,0.02],[1, 0.1,0.9,0.05,0.84,0.02]])\n",
    "print(b)\n",
    "\n",
    "print(np.multiply(a,b))\n",
    "#print(threshold_matrix(a, 0.2))\n",
    "print(a[:,1:])\n",
    "print(any(np.sum(a[:,1:], axis=0)>1))\n",
    "np.concatenate((a, b), axis=0)\n",
    "\n",
    "\n",
    "#np.concatenate((a, b.T), axis=1)\n",
    "c = np.array([[1, 0,0], [0, 1,0],[0, 0,1]])\n",
    "d = np.array([[1, 0,0], [0, 0,1],[0, 0,1]])\n",
    "\n",
    "\n",
    "m=c-d\n",
    "print(np.sum(np.abs(m))/np.size(m))\n",
    "\n",
    "\n",
    "c = torch.from_numpy(c).float()\n",
    "d = torch.from_numpy(d).float()\n",
    "\n",
    "\n",
    "\n",
    "cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "loss = cross_entropy_loss(c, d)\n",
    "\n",
    "print(loss)\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "loadgraph(run=1)\n",
    "\n",
    "#print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAT(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 emb_size: int,\n",
    "                 nhead: int,\n",
    "                 out = False, \n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.05,\n",
    "                 use_transformer: bool = True):\n",
    "        super(CAT, self).__init__()\n",
    "        \n",
    "        \n",
    "        \n",
    "       \n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model=emb_size, nhead=nhead,dim_feedforward=dim_feedforward)\n",
    "        \n",
    "        \n",
    "        self.decoder_1_1 = nn.TransformerDecoder(decoder_layer, num_layers=num_encoder_layers)\n",
    "        self.decoder_1_2 = nn.TransformerDecoder(decoder_layer, num_layers=num_encoder_layers)\n",
    "        self.decoder_2_1 = nn.TransformerDecoder(decoder_layer, num_layers=num_encoder_layers)\n",
    "        self.decoder_2_2 = nn.TransformerDecoder(decoder_layer, num_layers=num_encoder_layers)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.out=out \n",
    "        \n",
    "        self.sig = torch.nn.Sigmoid()\n",
    "        self.Ad = makeAdja()\n",
    "        self.use_transformer=use_transformer\n",
    "    def forward(self,\n",
    "                src_t1: Tensor,\n",
    "                src_t2: Tensor,\n",
    "                src_padding_mask1: Tensor,\n",
    "                src_padding_mask2: Tensor):\n",
    "        \n",
    "        #print('trans_src_before_pos',src_t1,src_t1.size())\n",
    "        #print('trans_src_toke',self.src_tok_emb(src),self.src_tok_emb(src).size())\n",
    "        \n",
    "        half_dim = int(src_t1.size(-1) // 2)\n",
    "\n",
    "        pos_1 = src_t1[:, :, :half_dim]\n",
    "        vis_1 = src_t1[:, :, half_dim:]\n",
    "        \n",
    "        pos_2 = src_t2[:, :, :half_dim]\n",
    "        vis_2 = src_t2[:, :, half_dim:]\n",
    "        \n",
    "        if not self.use_transformer:  # <-- Add this condition\n",
    "            src_t1=vis_1\n",
    "            src_t2=vis_2\n",
    "            src_t1_t = torch.transpose(src_t1, 0, 1)\n",
    "            src_t2_t = torch.transpose(src_t2, 0, 1)\n",
    "            src_t2_t = torch.transpose(src_t2_t, 1, 2)\n",
    "            #embedding_dim = src_t1.shape[-1]  # Assuming the last dimension is the embedding dimension\n",
    "            #scaling_factor = embedding_dim**0.5\n",
    "            A=torch.bmm(src_t1_t, src_t2_t)\n",
    "            #z = A / torch.max(A)\n",
    "            \n",
    "            max_values = A.max(dim=2, keepdim=True).values\n",
    "\n",
    "            # Avoid division by zero in case of rows with all zeros\n",
    "            max_values[max_values == 0] = 1\n",
    "\n",
    "            # Normalize A\n",
    "            z = A / max_values\n",
    "            #print('***A',A.size())\n",
    "            #row_norms = torch.norm(A, dim=2, keepdim=True)\n",
    "    \n",
    "            # Ensure no division by zero by adding a small value\n",
    "            #row_norms += 1e-10\n",
    "\n",
    "            # Normalize each row by its norm\n",
    "            #z = A / row_norms\n",
    "\n",
    "            #z = self.sig(torch.bmm(src_t1_t, src_t2_t))\n",
    "            Ad = self.Ad.forward(z, src_padding_mask1, src_padding_mask2)\n",
    "            return Ad\n",
    "        \n",
    "        #src1_emb = src_t1\n",
    "        #src2_emb = src_t2\n",
    "        #print('pos_1,vis_1',pos_1[:,0,:],vis_1[:,0,:],pos_1.size(),vis_1.size())\n",
    "        #print('src2',src2_emb.size())\n",
    "        #print('trans_src_padd',src_padding_mask1,src_padding_mask1.size()) !!!!!\n",
    "        povi_1 = self.decoder_1_1(vis_1, vis_1,tgt_key_padding_mask=src_padding_mask1,memory_key_padding_mask=src_padding_mask1)\n",
    "        povi_2 = self.decoder_1_2(vis_2, vis_2,tgt_key_padding_mask=src_padding_mask2,memory_key_padding_mask=src_padding_mask2)\n",
    "        \n",
    "        out_1 = self.decoder_2_1(povi_1, povi_2,tgt_key_padding_mask=src_padding_mask1,memory_key_padding_mask=src_padding_mask2)\n",
    "        out_2 = self.decoder_2_2(povi_2, povi_1,tgt_key_padding_mask=src_padding_mask2,memory_key_padding_mask=src_padding_mask1)\n",
    "        \n",
    "\n",
    "        #out1=torch.transpose(out1,0,1)\n",
    "        #out2=torch.transpose(out2,0,1)\n",
    "        #out2=torch.transpose(out2,1,2)\n",
    "        \n",
    "        #z=self.sig(torch.bmm(out1,out2))\n",
    "        \n",
    "        \n",
    "        out_1=torch.transpose(out_1,0,1)\n",
    "        out_2=torch.transpose(out_2,0,1)\n",
    "        out_2=torch.transpose(out_2,1,2)\n",
    "        \n",
    "        z=self.sig(torch.bmm(out_1,out_2))\n",
    "        #print('z',z.size())\n",
    "        \n",
    "        Ad=self.Ad.forward(z,src_padding_mask1,src_padding_mask2)\n",
    "\n",
    "\n",
    "        \n",
    "        if self.out:\n",
    "            return Ad,out1,out2,out_dec1,src_t1,src_t2\n",
    "        else:\n",
    "            return Ad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 24\u001b[0m\n\u001b[1;32m     19\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m Loss(pen\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,tra_to_tens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;66;03m#!!!!!!!\u001b[39;00m\n\u001b[1;32m     22\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(transformer\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m, betas\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;241m0.98\u001b[39m), eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-9\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mstop\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "input_dim=3\n",
    "\n",
    "emb_size= 64 ###!!!!24 for n2v emb\n",
    "nhead= 4    ####!!!! 6 for n2v emb\n",
    "num_encoder_layers = 2\n",
    "\n",
    "\n",
    "transformer = CAT(num_encoder_layers, emb_size, nhead, use_transformer=True)\n",
    "# CAT(num_encoder_layers, emb_size, nhead)\n",
    "\n",
    "\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "loss_fn = Loss(pen=0,tra_to_tens=False) #!!!!!!!\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 3500\n",
    "train_path='/media/mo/Label/HeLa_track_train'\n",
    "test_path='/media/mo/Label/HeLa_track_test'\n",
    "loss_over_time=[]\n",
    "test_error=[]\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(transformer, optimizer,loss_fn,train_path)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(transformer,loss_fn,test_path)\n",
    "    \n",
    "    \n",
    "    loss_over_time.append(train_loss)\n",
    "    np.savetxt('./'+'train_loss_trans_only_vis.txt', np.c_[loss_over_time],delimiter='\\t',header='trainloss')\n",
    "    \n",
    "    test_error.append(val_loss)\n",
    "                \n",
    "    np.savetxt('./'+'test_loss_trans_only_vis.txt', np.c_[test_error],delimiter='\\t',header='testloss')\n",
    "    print('train_loss***',train_loss)\n",
    "    \n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
    "    \n",
    "torch.save(transformer.state_dict(), 'CAT1_vis.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_over_time= np.loadtxt('./test_loss_trans_only_vis.txt',skiprows=1, delimiter='\\t', usecols=(0), unpack=True)\n",
    "test_error= np.loadtxt('./train_loss_distance_only.txt',skiprows=1, delimiter='\\t', usecols=(0), unpack=True)\n",
    "\n",
    "\n",
    "N=100\n",
    "plt.plot(np.convolve(loss_over_time, np.ones(N)/N, mode='valid'),c='red',label='train loss')\n",
    "plt.plot(np.convolve(test_error, np.ones(N)/N, mode='valid'),label='test loss')\n",
    "plt.title('Running mean of loss over epochs')\n",
    "plt.legend()\n",
    "\n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.linspace(0.01,1,num=1)\n",
    "#a=[0.1]\n",
    "\n",
    "transformer.load_state_dict(torch.load('AttTrack2_new.pt',map_location=torch.device('cpu')))\n",
    "transformer.eval()\n",
    "convert_tensor = transforms.ToTensor()\n",
    "lo=[]\n",
    "for k in range(len(a)):\n",
    "    print(lo)\n",
    "    print('k---',k)\n",
    "    g=[]\n",
    "    for v in range(10):\n",
    "        #print('v-',v)\n",
    "\n",
    "\n",
    "        src1, src2, y,d = collate_fn(1,-100,train=False)\n",
    "\n",
    "        src1= src1.to(DEVICE)\n",
    "        src2= src2.to(DEVICE)\n",
    "\n",
    "\n",
    "\n",
    "        src_padding_mask1=create_mask(src1,-100)\n",
    "        src_padding_mask2=create_mask(src2,-100)\n",
    "\n",
    "        Ad = transformer(src1,src2,src_padding_mask1,src_padding_mask2)\n",
    "        #print(Ad[0])\n",
    "\n",
    "        Ad_real = complete_postprocess(Ad,d,a[k])\n",
    "        #print(Ad_real[0])\n",
    "        #print(y[0])\n",
    "        \n",
    "        Ad_real= convert_tensor(Ad_real[0])\n",
    "\n",
    "\n",
    "        l = nn.CrossEntropyLoss()\n",
    "        s = l(Ad_real[0], y[0])\n",
    "        g.append(s)\n",
    "    lo.append(np.mean(g))\n",
    "\n",
    "plt.plot(a,lo)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#postprocess Training\n",
    "\n",
    "\n",
    "transformer = AdjacencyTransformer(num_encoder_layers, emb_size, nhead)\n",
    "\n",
    "\n",
    "NUM_EPOCHS=1000\n",
    "\n",
    "\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "loss_fn = Loss(pen=0,tra_to_tens=True)\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.00001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "loss_over_time=[]\n",
    "test_error=[]\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch_post_process(transformer, optimizer,loss_fn)\n",
    "    end_time = timer()\n",
    "    \n",
    "    \n",
    "    loss_over_time.append(train_loss)\n",
    "    np.savetxt('./'+'train_loss_pp.txt', np.c_[loss_over_time],delimiter='\\t',header='trainloss')\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
    "    \n",
    "#torch.save(transformer.state_dict(), 'AttTrack24.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recon########################\n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tracks(adj_matrices):\n",
    "    tracks = []\n",
    "    label_counter = 1\n",
    "\n",
    "    for t, adj_matrix in enumerate(adj_matrices):\n",
    "        if t==7:\n",
    "            print('t=7ADA',adj_matrix,len(adj_matrix))\n",
    "        if t==8:\n",
    "            print('t=8ADA',adj_matrix,len(adj_matrix))\n",
    "        for i, row in enumerate(adj_matrix[1:], 1):  # Skip the background node's row\n",
    "            linked_cells = [j for j, x in enumerate(row[1:], 1) if x == 1]  # Skip the background node's column\n",
    "            # Detect new cell appearance\n",
    "            if adj_matrix[0][i] == 1 and i != 0:\n",
    "                tracks.append({'L': label_counter, 'B': t, 'E': t + 1, 'P': 0})\n",
    "                label_counter += 1\n",
    "                continue\n",
    "\n",
    "            # Detect cells that disappeared\n",
    "            if adj_matrix[i][0] == 1 and i != 0:\n",
    "                existing_track = find_track_by_cell_label_and_end_time(tracks, i, t)\n",
    "                if existing_track:\n",
    "                    existing_track['E'] = t  # This cell's track ends at current time\n",
    "                continue\n",
    "\n",
    "            # For continuation of cells\n",
    "            if len(linked_cells) == 1:\n",
    "                existing_track = find_track_by_cell_label_and_end_time(tracks, i, t)\n",
    "                if existing_track:\n",
    "                    existing_track['E'] = t + 1\n",
    "                else:\n",
    "                    tracks.append({'L': label_counter, 'B': t, 'E': t + 1, 'P': 0})\n",
    "                    label_counter += 1\n",
    "\n",
    "            # For cell division\n",
    "            elif len(linked_cells) > 1:\n",
    "                parent_track = find_track_by_cell_label_and_end_time(tracks, i, t)\n",
    "                if parent_track:\n",
    "                    parent_track['E'] = t  # The parent cell's track ends at current time\n",
    "                \n",
    "                \n",
    "                                # Assuming there's only one new row added after the split\n",
    "                daughter1 = linked_cells[0]\n",
    "                daughter2 = i + 1 if i + 1 != daughter1 else i + 2\n",
    "\n",
    "                for cell in [daughter1, daughter2]:\n",
    "                    tracks.append({'L': label_counter, 'B': t + 1, 'E': t + 1, 'P': parent_track['L'] if parent_track else 0})\n",
    "                    label_counter += 1\n",
    "                #for cell in linked_cells:\n",
    "                 #   tracks.append({'L': label_counter, 'B': t + 1, 'E': t + 1, 'P': parent_track['L'] if parent_track else 0})\n",
    "                 #   label_counter += 1\n",
    "\n",
    "    return tracks\n",
    "\n",
    "def find_track_by_cell_label_and_end_time(tracks, cell_label, end_time):\n",
    "    \n",
    "    if cell_label==13:\n",
    "        print('13',cell_label,end_time)\n",
    "        print(tracks)\n",
    "    elif cell_label==12:\n",
    "        print('12',cell_label,end_time)\n",
    "        print(tracks)\n",
    "    elif cell_label==11:\n",
    "        print('11',cell_label,end_time)\n",
    "        print(tracks)\n",
    "    if end_time==7:\n",
    "        print('t=7',tracks)\n",
    "    if end_time==8:\n",
    "        print('t=8',tracks)\n",
    "    for track in tracks:\n",
    "        if track['L'] == cell_label and track['E'] == end_time:\n",
    "            return track\n",
    "    return None\n",
    "def write_tracks_to_file(tracks, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        for track in tracks:\n",
    "            f.write(f\"{track['L']} {track['B']} {track['E']} {track['P']}\\n\")\n",
    "\n",
    "def adjacency_to_edgelist(matrices):\n",
    "    edges = []\n",
    "    \n",
    "    # Starting node based on the size of the first matrix\n",
    "    current_start_node = matrices[0].shape[1]-1\n",
    "    \n",
    "    # Target nodes from the previous matrix\n",
    "    previous_targets = list(range(1,matrices[0].shape[0]))\n",
    "    #print(current_start_node,previous_targets)\n",
    "    for matrix in matrices:\n",
    "        # Number of nodes in the current timeframe\n",
    "        num_nodes_t0 = matrix.shape[1]\n",
    "        print('M',matrix)\n",
    "        new_targets = []\n",
    "        \n",
    "        for row in range(matrix.shape[0]):\n",
    "            for col in range(num_nodes_t0):\n",
    "                if matrix[row, col] == 1 and not (row == 0 or col == 0):\n",
    "                    # Use previous_targets for source nodes\n",
    "                   \n",
    "                    source_node = sorted(previous_targets)[row-1]\n",
    "                    target_node = col + current_start_node\n",
    "                    edges.append((source_node, target_node))\n",
    "                    print('row',row,col,source_node,target_node,edges)\n",
    "                    new_targets.append(target_node)\n",
    "                    \n",
    "        # Update the previous targets\n",
    "        previous_targets = new_targets\n",
    "                    \n",
    "        # Update the start node for the next matrix\n",
    "        current_start_node += matrix.shape[1] - 1  # subtracting 1 for the background node\n",
    "\n",
    "    return edges\n",
    "\n",
    "def find_track(node, graph):\n",
    "    \"\"\"Returns the entire track of a node.\"\"\"\n",
    "    track = [node]\n",
    "    while node in graph:\n",
    "        node = graph[node]\n",
    "        track.append(node)\n",
    "    return track\n",
    "\n",
    "def get_track(node, graph):\n",
    "    \"\"\"Returns the track of a node.\"\"\"\n",
    "    track = [node]\n",
    "    while node in graph and len(graph[node]) == 1:\n",
    "        next_node = graph[node][0]\n",
    "        del graph[node]  # Remove the utilized edge\n",
    "        node = next_node\n",
    "        track.append(node)\n",
    "    return track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])\n",
      "Ad [[1.00000000e+00 7.31590912e-15 7.97275700e-12 4.30108482e-09\n",
      "  2.38545130e-08 3.02481868e-12 7.75016318e-08 1.91785654e-09\n",
      "  3.26950456e-16 1.03091446e-09 2.73444136e-13 3.46922661e-07\n",
      "  1.49791163e-07]\n",
      " [4.93716346e-10 1.00000000e+00 1.04394484e-23 6.19355012e-09\n",
      "  9.99994516e-01 9.94373322e-01 7.49736853e-17 8.91764440e-12\n",
      "  1.81057676e-05 6.37778319e-09 9.68627286e-23 1.04678100e-10\n",
      "  2.30149837e-16]\n",
      " [7.19740285e-08 7.69634261e-14 5.73042892e-02 1.15445034e-13\n",
      "  3.43718450e-24 2.03748641e-04 7.79960215e-01 2.82525008e-08\n",
      "  4.81700519e-20 4.99503301e-08 2.94689741e-02 9.94598508e-01\n",
      "  2.77478873e-11]\n",
      " [1.76590062e-11 3.66735169e-21 3.43370019e-04 5.58260024e-01\n",
      "  1.77324162e-11 2.89691284e-20 4.20768220e-06 3.90944804e-14\n",
      "  6.89174678e-15 2.54663180e-13 3.31450178e-06 1.76211010e-17\n",
      "  9.99999285e-01]\n",
      " [1.71316387e-05 1.34420441e-09 2.42762590e-14 8.33189789e-21\n",
      "  4.98503148e-11 8.77408565e-15 3.74472307e-07 9.99999881e-01\n",
      "  3.27814789e-03 2.90527579e-15 1.17481769e-09 1.30445132e-09\n",
      "  2.24678835e-11]\n",
      " [1.72407717e-17 2.03947207e-06 1.80879809e-08 9.34352279e-01\n",
      "  1.27006670e-14 9.84728098e-01 9.22635826e-16 2.64487609e-18\n",
      "  1.09879394e-08 1.00000000e+00 1.18909670e-13 3.06217942e-12\n",
      "  6.86098626e-20]\n",
      " [1.06139778e-05 8.89405347e-15 4.68675876e-10 3.03861908e-10\n",
      "  9.62020278e-01 5.92004440e-21 8.46108887e-17 7.05188408e-11\n",
      "  1.51347948e-08 1.32674132e-16 6.94806643e-11 1.29481170e-12\n",
      "  4.76715481e-03]\n",
      " [2.69141762e-12 7.73027649e-12 1.72344650e-09 9.99993324e-01\n",
      "  7.27819582e-10 3.82577721e-03 1.31043723e-19 3.49320761e-22\n",
      "  2.73891847e-14 1.00000000e+00 1.28035573e-17 4.56075844e-14\n",
      "  7.40768259e-15]\n",
      " [1.68786932e-17 4.15140003e-01 3.79368516e-11 7.44610807e-13\n",
      "  4.99304151e-04 6.79778941e-11 2.94389858e-15 7.13296959e-06\n",
      "  9.99995232e-01 1.44718570e-16 4.57020803e-07 8.26993042e-13\n",
      "  1.22081741e-14]\n",
      " [3.74743151e-13 9.97634053e-01 9.22452692e-09 5.03562675e-17\n",
      "  5.42617151e-09 9.99971509e-01 6.58822491e-16 2.51174602e-12\n",
      "  2.87634919e-16 2.00828687e-09 2.18534204e-08 9.99999762e-01\n",
      "  8.18953332e-20]\n",
      " [2.28113277e-06 1.31013853e-17 2.20873755e-08 8.65094307e-09\n",
      "  1.86426881e-20 2.94094566e-12 9.99997497e-01 8.74393322e-07\n",
      "  6.12674151e-17 1.32747296e-12 1.65368959e-07 8.92402957e-11\n",
      "  3.50428335e-02]\n",
      " [2.65076737e-16 2.91933672e-10 9.13308382e-01 1.55857944e-12\n",
      "  7.80440837e-20 8.98132291e-10 3.51891813e-08 6.34230375e-08\n",
      "  2.20655362e-04 4.15952099e-11 9.98550951e-01 1.03364664e-05\n",
      "  3.99629536e-16]]\n",
      "pp [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n",
      "d tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 0.1001, 0.3663, 0.2349, 0.0910, 0.0601, 0.0826, 0.1786,\n",
      "         0.2455, 0.1958, 0.0548, 0.1183],\n",
      "        [1.0000, 0.0570, 0.6302, 0.1004, 0.0266, 0.0630, 0.3400, 0.2540, 0.1310,\n",
      "         0.0450, 0.2358, 1.0000, 0.0253],\n",
      "        [1.0000, 0.1128, 0.0341, 0.0498, 0.4389, 0.1154, 0.0372, 0.0268, 0.0824,\n",
      "         0.4377, 0.0525, 0.0264, 1.0000],\n",
      "        [1.0000, 0.0845, 0.7318, 0.2665, 0.0319, 0.0437, 0.0929, 1.0000, 0.0954,\n",
      "         0.0439, 0.2586, 0.2444, 0.0261],\n",
      "        [1.0000, 0.4326, 0.2509, 1.0000, 0.0747, 0.0638, 0.0747, 0.2611, 0.1582,\n",
      "         0.0937, 0.4102, 0.0950, 0.0506],\n",
      "        [1.0000, 0.1990, 0.0369, 0.0696, 1.0000, 0.0662, 0.0317, 0.0317, 0.0701,\n",
      "         0.2244, 0.0564, 0.0260, 0.4557],\n",
      "        [1.0000, 0.2490, 0.0639, 0.0930, 0.2619, 0.3119, 0.0717, 0.0448, 0.2525,\n",
      "         1.0000, 0.1180, 0.0460, 0.4063],\n",
      "        [1.0000, 0.2044, 0.2453, 0.1868, 0.0732, 0.3319, 0.3050, 0.1103, 1.0000,\n",
      "         0.2290, 0.8062, 0.1524, 0.0742],\n",
      "        [1.0000, 0.0980, 0.0761, 0.0673, 0.0719, 1.0000, 0.1641, 0.0459, 0.4465,\n",
      "         0.3221, 0.1290, 0.0676, 0.1057],\n",
      "        [1.0000, 0.0615, 0.2084, 0.0758, 0.0325, 0.1523, 1.0000, 0.0922, 0.2737,\n",
      "         0.0699, 0.2137, 0.3765, 0.0351],\n",
      "        [1.0000, 0.1500, 1.0000, 0.4150, 0.0467, 0.0882, 0.2131, 0.5346, 0.3000,\n",
      "         0.0819, 1.0000, 0.3802, 0.0401]], dtype=torch.float64)\n",
      "M [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "row 1 3 1 14 [(1, 14)]\n",
      "row 2 11 2 22 [(1, 14), (2, 22)]\n",
      "row 3 4 3 15 [(1, 14), (2, 22), (3, 15)]\n",
      "row 4 9 4 20 [(1, 14), (2, 22), (3, 15), (4, 20)]\n",
      "row 5 10 5 21 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21)]\n",
      "row 6 5 6 16 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16)]\n",
      "row 7 7 7 18 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18)]\n",
      "row 8 6 8 17 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17)]\n",
      "row 9 2 9 13 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13)]\n",
      "row 10 1 10 12 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12)]\n",
      "row 11 8 11 19 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19)]\n",
      "M [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n",
      "row 1 4 12 26 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26)]\n",
      "row 2 6 13 28 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28)]\n",
      "row 3 5 14 27 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27)]\n",
      "row 4 1 15 23 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23)]\n",
      "row 5 11 16 33 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33)]\n",
      "row 6 10 17 32 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32)]\n",
      "row 7 8 18 30 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30)]\n",
      "row 8 3 19 25 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25)]\n",
      "row 9 7 20 29 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29)]\n",
      "row 10 2 21 24 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24)]\n",
      "row 11 9 22 31 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31)]\n",
      "M [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "row 1 2 23 35 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35)]\n",
      "row 2 9 24 42 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42)]\n",
      "row 3 10 25 43 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43)]\n",
      "row 4 3 26 36 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36)]\n",
      "row 5 4 27 37 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37)]\n",
      "row 6 5 28 38 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38)]\n",
      "row 7 7 29 40 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40)]\n",
      "row 8 6 30 39 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39)]\n",
      "row 9 11 31 44 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44)]\n",
      "row 10 8 32 41 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41)]\n",
      "row 11 1 33 34 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34)]\n",
      "M [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
      "row 1 5 34 49 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49)]\n",
      "row 2 6 35 50 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50)]\n",
      "row 3 11 36 55 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55)]\n",
      "row 4 2 37 46 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46)]\n",
      "row 5 4 38 48 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48)]\n",
      "row 6 3 39 47 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47)]\n",
      "row 7 10 40 54 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54)]\n",
      "row 8 1 41 45 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45)]\n",
      "row 9 9 42 53 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53)]\n",
      "row 10 8 43 52 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52)]\n",
      "row 11 7 44 51 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51)]\n",
      "M [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
      "row 1 4 45 59 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59)]\n",
      "row 2 10 46 65 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65)]\n",
      "row 3 8 47 63 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63)]\n",
      "row 4 9 48 64 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64)]\n",
      "row 5 2 49 57 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57)]\n",
      "row 6 11 50 66 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66)]\n",
      "row 7 3 51 58 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58)]\n",
      "row 8 1 52 56 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56)]\n",
      "row 9 5 53 60 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60)]\n",
      "row 10 7 54 62 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62)]\n",
      "row 11 6 55 61 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61)]\n",
      "M [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "row 1 2 56 68 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68)]\n",
      "row 2 7 57 73 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73)]\n",
      "row 3 9 58 75 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75)]\n",
      "row 4 6 59 72 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72)]\n",
      "row 5 1 60 67 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67)]\n",
      "row 6 10 61 76 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76)]\n",
      "row 7 8 62 74 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74)]\n",
      "row 8 4 63 70 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70)]\n",
      "row 9 11 64 77 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77)]\n",
      "row 10 5 65 71 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71)]\n",
      "row 11 3 66 69 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69)]\n",
      "M [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n",
      "row 1 5 67 82 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82)]\n",
      "row 2 1 68 78 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78)]\n",
      "row 3 8 69 85 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85)]\n",
      "row 4 7 70 84 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84)]\n",
      "row 5 2 71 79 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79)]\n",
      "row 6 6 72 83 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83)]\n",
      "row 7 10 73 87 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87)]\n",
      "row 8 11 74 88 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88)]\n",
      "row 9 3 75 80 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80)]\n",
      "row 10 4 76 81 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81)]\n",
      "row 11 9 77 86 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86)]\n",
      "M [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n",
      "row 1 1 78 89 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89)]\n",
      "row 2 11 79 99 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99)]\n",
      "row 3 12 80 100 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100)]\n",
      "row 4 7 81 95 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95)]\n",
      "row 5 9 82 97 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97)]\n",
      "row 6 4 83 92 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92)]\n",
      "row 7 3 84 91 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91)]\n",
      "row 8 8 85 96 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96)]\n",
      "row 9 5 86 93 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93)]\n",
      "row 10 6 87 94 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94)]\n",
      "row 11 2 88 90 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90)]\n",
      "row 11 10 88 98 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98)]\n",
      "M [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "row 1 9 89 109 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109)]\n",
      "row 2 5 90 105 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105)]\n",
      "row 3 12 91 112 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112)]\n",
      "row 4 11 92 111 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111)]\n",
      "row 5 7 93 107 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111), (93, 107)]\n",
      "row 6 6 94 106 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111), (93, 107), (94, 106)]\n",
      "row 7 3 95 103 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111), (93, 107), (94, 106), (95, 103)]\n",
      "row 8 4 96 104 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111), (93, 107), (94, 106), (95, 103), (96, 104)]\n",
      "row 9 8 97 108 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111), (93, 107), (94, 106), (95, 103), (96, 104), (97, 108)]\n",
      "row 10 10 98 110 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111), (93, 107), (94, 106), (95, 103), (96, 104), (97, 108), (98, 110)]\n",
      "row 11 1 99 101 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111), (93, 107), (94, 106), (95, 103), (96, 104), (97, 108), (98, 110), (99, 101)]\n",
      "row 12 2 100 102 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111), (93, 107), (94, 106), (95, 103), (96, 104), (97, 108), (98, 110), (99, 101), (100, 102)]\n",
      "M [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "row 1 5 101 117 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111), (93, 107), (94, 106), (95, 103), (96, 104), (97, 108), (98, 110), (99, 101), (100, 102), (101, 117)]\n",
      "row 2 6 102 118 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111), (93, 107), (94, 106), (95, 103), (96, 104), (97, 108), (98, 110), (99, 101), (100, 102), (101, 117), (102, 118)]\n",
      "row 3 8 103 120 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111), (93, 107), (94, 106), (95, 103), (96, 104), (97, 108), (98, 110), (99, 101), (100, 102), (101, 117), (102, 118), (103, 120)]\n",
      "row 4 11 104 123 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111), (93, 107), (94, 106), (95, 103), (96, 104), (97, 108), (98, 110), (99, 101), (100, 102), (101, 117), (102, 118), (103, 120), (104, 123)]\n",
      "row 5 7 105 119 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111), (93, 107), (94, 106), (95, 103), (96, 104), (97, 108), (98, 110), (99, 101), (100, 102), (101, 117), (102, 118), (103, 120), (104, 123), (105, 119)]\n",
      "row 6 10 106 122 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111), (93, 107), (94, 106), (95, 103), (96, 104), (97, 108), (98, 110), (99, 101), (100, 102), (101, 117), (102, 118), (103, 120), (104, 123), (105, 119), (106, 122)]\n",
      "row 7 12 107 124 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111), (93, 107), (94, 106), (95, 103), (96, 104), (97, 108), (98, 110), (99, 101), (100, 102), (101, 117), (102, 118), (103, 120), (104, 123), (105, 119), (106, 122), (107, 124)]\n",
      "row 8 9 108 121 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111), (93, 107), (94, 106), (95, 103), (96, 104), (97, 108), (98, 110), (99, 101), (100, 102), (101, 117), (102, 118), (103, 120), (104, 123), (105, 119), (106, 122), (107, 124), (108, 121)]\n",
      "row 9 4 109 116 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111), (93, 107), (94, 106), (95, 103), (96, 104), (97, 108), (98, 110), (99, 101), (100, 102), (101, 117), (102, 118), (103, 120), (104, 123), (105, 119), (106, 122), (107, 124), (108, 121), (109, 116)]\n",
      "row 10 3 110 115 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111), (93, 107), (94, 106), (95, 103), (96, 104), (97, 108), (98, 110), (99, 101), (100, 102), (101, 117), (102, 118), (103, 120), (104, 123), (105, 119), (106, 122), (107, 124), (108, 121), (109, 116), (110, 115)]\n",
      "row 11 1 111 113 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111), (93, 107), (94, 106), (95, 103), (96, 104), (97, 108), (98, 110), (99, 101), (100, 102), (101, 117), (102, 118), (103, 120), (104, 123), (105, 119), (106, 122), (107, 124), (108, 121), (109, 116), (110, 115), (111, 113)]\n",
      "row 12 2 112 114 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111), (93, 107), (94, 106), (95, 103), (96, 104), (97, 108), (98, 110), (99, 101), (100, 102), (101, 117), (102, 118), (103, 120), (104, 123), (105, 119), (106, 122), (107, 124), (108, 121), (109, 116), (110, 115), (111, 113), (112, 114)]\n",
      "M [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "row 1 11 113 135 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111), (93, 107), (94, 106), (95, 103), (96, 104), (97, 108), (98, 110), (99, 101), (100, 102), (101, 117), (102, 118), (103, 120), (104, 123), (105, 119), (106, 122), (107, 124), (108, 121), (109, 116), (110, 115), (111, 113), (112, 114), (113, 135)]\n",
      "row 2 4 114 128 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111), (93, 107), (94, 106), (95, 103), (96, 104), (97, 108), (98, 110), (99, 101), (100, 102), (101, 117), (102, 118), (103, 120), (104, 123), (105, 119), (106, 122), (107, 124), (108, 121), (109, 116), (110, 115), (111, 113), (112, 114), (113, 135), (114, 128)]\n",
      "row 3 12 115 136 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111), (93, 107), (94, 106), (95, 103), (96, 104), (97, 108), (98, 110), (99, 101), (100, 102), (101, 117), (102, 118), (103, 120), (104, 123), (105, 119), (106, 122), (107, 124), (108, 121), (109, 116), (110, 115), (111, 113), (112, 114), (113, 135), (114, 128), (115, 136)]\n",
      "row 4 6 116 130 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111), (93, 107), (94, 106), (95, 103), (96, 104), (97, 108), (98, 110), (99, 101), (100, 102), (101, 117), (102, 118), (103, 120), (104, 123), (105, 119), (106, 122), (107, 124), (108, 121), (109, 116), (110, 115), (111, 113), (112, 114), (113, 135), (114, 128), (115, 136), (116, 130)]\n",
      "row 5 5 117 129 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111), (93, 107), (94, 106), (95, 103), (96, 104), (97, 108), (98, 110), (99, 101), (100, 102), (101, 117), (102, 118), (103, 120), (104, 123), (105, 119), (106, 122), (107, 124), (108, 121), (109, 116), (110, 115), (111, 113), (112, 114), (113, 135), (114, 128), (115, 136), (116, 130), (117, 129)]\n",
      "row 6 9 118 133 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111), (93, 107), (94, 106), (95, 103), (96, 104), (97, 108), (98, 110), (99, 101), (100, 102), (101, 117), (102, 118), (103, 120), (104, 123), (105, 119), (106, 122), (107, 124), (108, 121), (109, 116), (110, 115), (111, 113), (112, 114), (113, 135), (114, 128), (115, 136), (116, 130), (117, 129), (118, 133)]\n",
      "row 7 7 119 131 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111), (93, 107), (94, 106), (95, 103), (96, 104), (97, 108), (98, 110), (99, 101), (100, 102), (101, 117), (102, 118), (103, 120), (104, 123), (105, 119), (106, 122), (107, 124), (108, 121), (109, 116), (110, 115), (111, 113), (112, 114), (113, 135), (114, 128), (115, 136), (116, 130), (117, 129), (118, 133), (119, 131)]\n",
      "row 8 8 120 132 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111), (93, 107), (94, 106), (95, 103), (96, 104), (97, 108), (98, 110), (99, 101), (100, 102), (101, 117), (102, 118), (103, 120), (104, 123), (105, 119), (106, 122), (107, 124), (108, 121), (109, 116), (110, 115), (111, 113), (112, 114), (113, 135), (114, 128), (115, 136), (116, 130), (117, 129), (118, 133), (119, 131), (120, 132)]\n",
      "row 9 10 121 134 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111), (93, 107), (94, 106), (95, 103), (96, 104), (97, 108), (98, 110), (99, 101), (100, 102), (101, 117), (102, 118), (103, 120), (104, 123), (105, 119), (106, 122), (107, 124), (108, 121), (109, 116), (110, 115), (111, 113), (112, 114), (113, 135), (114, 128), (115, 136), (116, 130), (117, 129), (118, 133), (119, 131), (120, 132), (121, 134)]\n",
      "row 10 2 122 126 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111), (93, 107), (94, 106), (95, 103), (96, 104), (97, 108), (98, 110), (99, 101), (100, 102), (101, 117), (102, 118), (103, 120), (104, 123), (105, 119), (106, 122), (107, 124), (108, 121), (109, 116), (110, 115), (111, 113), (112, 114), (113, 135), (114, 128), (115, 136), (116, 130), (117, 129), (118, 133), (119, 131), (120, 132), (121, 134), (122, 126)]\n",
      "row 11 3 123 127 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111), (93, 107), (94, 106), (95, 103), (96, 104), (97, 108), (98, 110), (99, 101), (100, 102), (101, 117), (102, 118), (103, 120), (104, 123), (105, 119), (106, 122), (107, 124), (108, 121), (109, 116), (110, 115), (111, 113), (112, 114), (113, 135), (114, 128), (115, 136), (116, 130), (117, 129), (118, 133), (119, 131), (120, 132), (121, 134), (122, 126), (123, 127)]\n",
      "row 12 1 124 125 [(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111), (93, 107), (94, 106), (95, 103), (96, 104), (97, 108), (98, 110), (99, 101), (100, 102), (101, 117), (102, 118), (103, 120), (104, 123), (105, 119), (106, 122), (107, 124), (108, 121), (109, 116), (110, 115), (111, 113), (112, 114), (113, 135), (114, 128), (115, 136), (116, 130), (117, 129), (118, 133), (119, 131), (120, 132), (121, 134), (122, 126), (123, 127), (124, 125)]\n",
      "[(1, 14), (2, 22), (3, 15), (4, 20), (5, 21), (6, 16), (7, 18), (8, 17), (9, 13), (10, 12), (11, 19), (12, 26), (13, 28), (14, 27), (15, 23), (16, 33), (17, 32), (18, 30), (19, 25), (20, 29), (21, 24), (22, 31), (23, 35), (24, 42), (25, 43), (26, 36), (27, 37), (28, 38), (29, 40), (30, 39), (31, 44), (32, 41), (33, 34), (34, 49), (35, 50), (36, 55), (37, 46), (38, 48), (39, 47), (40, 54), (41, 45), (42, 53), (43, 52), (44, 51), (45, 59), (46, 65), (47, 63), (48, 64), (49, 57), (50, 66), (51, 58), (52, 56), (53, 60), (54, 62), (55, 61), (56, 68), (57, 73), (58, 75), (59, 72), (60, 67), (61, 76), (62, 74), (63, 70), (64, 77), (65, 71), (66, 69), (67, 82), (68, 78), (69, 85), (70, 84), (71, 79), (72, 83), (73, 87), (74, 88), (75, 80), (76, 81), (77, 86), (78, 89), (79, 99), (80, 100), (81, 95), (82, 97), (83, 92), (84, 91), (85, 96), (86, 93), (87, 94), (88, 90), (88, 98), (89, 109), (90, 105), (91, 112), (92, 111), (93, 107), (94, 106), (95, 103), (96, 104), (97, 108), (98, 110), (99, 101), (100, 102), (101, 117), (102, 118), (103, 120), (104, 123), (105, 119), (106, 122), (107, 124), (108, 121), (109, 116), (110, 115), (111, 113), (112, 114), (113, 135), (114, 128), (115, 136), (116, 130), (117, 129), (118, 133), (119, 131), (120, 132), (121, 134), (122, 126), (123, 127), (124, 125)]\n",
      "rn0 [88, 90, 98, 105, 110, 115, 119]\n",
      "allTra0 [[1, 14, 27, 37, 46, 65, 71, 79, 99, 101, 117, 129], [2, 22, 31, 44, 51, 58, 75, 80, 100, 102, 118, 133], [3, 15, 23, 35, 50, 66, 69, 85, 96, 104, 123, 127], [4, 20, 29, 40, 54, 62, 74, 88], [5, 21, 24, 42, 53, 60, 67, 82, 97, 108, 121, 134], [6, 16, 33, 34, 49, 57, 73, 87, 94, 106, 122, 126], [7, 18, 30, 39, 47, 63, 70, 84, 91, 112, 114, 128], [8, 17, 32, 41, 45, 59, 72, 83, 92, 111, 113, 135], [9, 13, 28, 38, 48, 64, 77, 86, 93, 107, 124, 125], [10, 12, 26, 36, 55, 61, 76, 81, 95, 103, 120, 132], [11, 19, 25, 43, 52, 56, 68, 78, 89, 109, 116, 130]]\n",
      "node 88 {88: [90, 98], 90: [105], 98: [110], 105: [119], 110: [115], 115: [136], 119: [131]}\n",
      "allTra1 [[1, 14, 27, 37, 46, 65, 71, 79, 99, 101, 117, 129], [2, 22, 31, 44, 51, 58, 75, 80, 100, 102, 118, 133], [3, 15, 23, 35, 50, 66, 69, 85, 96, 104, 123, 127], [4, 20, 29, 40, 54, 62, 74, 88], [5, 21, 24, 42, 53, 60, 67, 82, 97, 108, 121, 134], [6, 16, 33, 34, 49, 57, 73, 87, 94, 106, 122, 126], [7, 18, 30, 39, 47, 63, 70, 84, 91, 112, 114, 128], [8, 17, 32, 41, 45, 59, 72, 83, 92, 111, 113, 135], [9, 13, 28, 38, 48, 64, 77, 86, 93, 107, 124, 125], [10, 12, 26, 36, 55, 61, 76, 81, 95, 103, 120, 132], [11, 19, 25, 43, 52, 56, 68, 78, 89, 109, 116, 130], [88]]\n",
      "rn1 [88, 90, 98, 105, 110, 115, 119]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 72\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallTra1\u001b[39m\u001b[38;5;124m'\u001b[39m,all_tracks)\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrn1\u001b[39m\u001b[38;5;124m'\u001b[39m,remaining_nodes)\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mstop\u001b[49m)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Determine the parent for each node (0 if no parent)\u001b[39;00m\n\u001b[1;32m     75\u001b[0m parent_dict \u001b[38;5;241m=\u001b[39m {node: \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m start_nodes}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "#recon+testerror\n",
    "transformer.load_state_dict(torch.load('CAT1_vis.pt',map_location=torch.device('cpu')))\n",
    "transformer.eval()\n",
    "test_path='/media/mo/Label/HeLa_track_test'\n",
    "for r in range(1):\n",
    "    r=8\n",
    "    src1, src2, y,d = collate_fn(31,-100,recon=True,train=False,run=r,path0=test_path)\n",
    "\n",
    "    #print(src1.size())\n",
    "    src1= src1.to(DEVICE)\n",
    "    src2= src2.to(DEVICE)\n",
    "    \n",
    "    src_padding_mask1=create_mask(src1,-100)\n",
    "    src_padding_mask2=create_mask(src2,-100)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    Ad = transformer(src1,src2,src_padding_mask1,src_padding_mask2)\n",
    "    \n",
    "    #print('y',y[25])\n",
    "    #print('Ad',len(Ad))\n",
    "    \n",
    "    \n",
    "    #val_loss = evaluate(transformer,loss_fn)\n",
    "    #print('L',val_loss)\n",
    "    a=0.1\n",
    "    #print(Ad)\n",
    "    pp_A = complete_postprocess(Ad,d,a)\n",
    "    \n",
    "    #err_p=err_perc(pp_A,y)\n",
    "    #print('err',r,err_p)\n",
    "\n",
    "#print(src1.size())\n",
    "\n",
    "    print('y',y[7])\n",
    "    print('Ad',Ad[7])\n",
    "    print('pp',pp_A[7])\n",
    "    print('d',d[7])\n",
    "\n",
    "#for i in range(5):\n",
    "#    print(pp_A[i])\n",
    "    \n",
    "    edgelist=adjacency_to_edgelist(pp_A)\n",
    "    print(edgelist)\n",
    "    \n",
    "    start_nodes = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "\n",
    "    # Convert edgelist into a dictionary for easier lookup\n",
    "    graph = {}\n",
    "    for start, end in edgelist:\n",
    "        graph.setdefault(start, []).append(end)\n",
    "    all_tracks = []\n",
    "\n",
    "    # Discover tracks from initial nodes\n",
    "    for node in start_nodes:\n",
    "        all_tracks.append(get_track(node, graph))\n",
    "\n",
    "    # Discover tracks for daughter cells until the graph is exhausted\n",
    "    remaining_nodes = list(graph.keys())\n",
    "    print('rn0',remaining_nodes)\n",
    "    print('allTra0',all_tracks)\n",
    "    while remaining_nodes:\n",
    "        node = remaining_nodes[0]\n",
    "        print('node',node,graph)\n",
    "        all_tracks.append(get_track(node, graph))\n",
    "        remaining_nodes = list(graph.keys())\n",
    "        print('allTra1',all_tracks)\n",
    "        print('rn1',remaining_nodes)\n",
    "        print(stop)\n",
    "\n",
    "    # Determine the parent for each node (0 if no parent)\n",
    "    parent_dict = {node: 0 for node in start_nodes}\n",
    "    for track in all_tracks:\n",
    "        if track[0] not in start_nodes:\n",
    "            parent_dict[track[0]] = track[-1]\n",
    "\n",
    "    # Writing the data to man_track.txt\n",
    "    with open('man_track.txt', 'w') as file:\n",
    "        for track in all_tracks:\n",
    "            L = track[0]\n",
    "            B = timetable[track[0]]\n",
    "            E = timetable[track[-1]]\n",
    "            P = parent_dict[L]\n",
    "\n",
    "            if E != B:\n",
    "                file.write(f\"{L} {B} {E} {P}\\n\")\n",
    "\n",
    "                # Handle splits\n",
    "                if track[-1] in graph:\n",
    "                    for child in graph[track[-1]]:\n",
    "                        file.write(f\"{child} {E + 1} {timetable.get(child, E)} {L}\\n\")\n",
    "\n",
    "    print(\"File 'man_track.txt' written successfully!\")\n",
    "\n",
    "    #make_reconstructed_edgelist(Ad,run=r)\n",
    "    #tracks = generate_tracks(pp_A)\n",
    "    \n",
    "    #for track in tracks:\n",
    "    #    print(f\"{track['L']} {track['B']} {track['E']} {track['P']}\")\n",
    "    #write_tracks_to_file(tracks, 'man_track.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tracks(adj_matrices):\n",
    "    tracks = []\n",
    "    label_counter = 1\n",
    "\n",
    "    for t, adj_matrix in enumerate(adj_matrices):\n",
    "        for i, row in enumerate(adj_matrix[1:], 1):  # Skip the background node's row\n",
    "            linked_cells = [j for j, x in enumerate(row[1:], 1) if x == 1]  # Skip the background node's column\n",
    "            \n",
    "            # Detect new cell appearance\n",
    "            if adj_matrix[0][i] == 1 and i != 0:\n",
    "                tracks.append({'L': label_counter, 'B': t, 'E': t + 1, 'P': 0})\n",
    "                label_counter += 1\n",
    "                continue\n",
    "\n",
    "            # Detect cells that disappeared\n",
    "            if adj_matrix[i][0] == 1 and i != 0:\n",
    "                existing_track = find_track_by_cell_label_and_end_time(tracks, i, t)\n",
    "                if existing_track:\n",
    "                    existing_track['E'] = t  # This cell's track ends at current time\n",
    "                continue\n",
    "\n",
    "            # For continuation of cells\n",
    "            if len(linked_cells) == 1:\n",
    "                existing_track = find_track_by_cell_label_and_end_time(tracks, i, t)\n",
    "                if existing_track:\n",
    "                    existing_track['E'] = t + 1\n",
    "\n",
    "            # For cell division\n",
    "            elif len(linked_cells) > 1:\n",
    "                parent_track = find_track_by_cell_label_and_end_time(tracks, i, t)\n",
    "                if parent_track:\n",
    "                    parent_track['E'] = t  # The parent cell's track ends at current time\n",
    "\n",
    "                # Assuming there's only one new row added after the split\n",
    "                daughter1 = linked_cells[0]\n",
    "                daughter2 = i + 1 if i + 1 != daughter1 else i + 2\n",
    "\n",
    "                for cell in [daughter1, daughter2]:\n",
    "                    tracks.append({'L': label_counter, 'B': t + 1, 'E': t + 1, 'P': parent_track['L'] if parent_track else 0})\n",
    "                    label_counter += 1\n",
    "\n",
    "    return tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Umap AdjacencyTrans2\n",
    "\n",
    "\n",
    "emb_size= 150 ###!!!!24 for n2v emb\n",
    "nhead= 6    ###!!!! 6 for n2v emb\n",
    "num_encoder_layers = 3\n",
    "\n",
    "\n",
    "transformer = AdjacencyTransformer_2(num_encoder_layers, emb_size, nhead,out=True)\n",
    "\n",
    "\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "loss_fn = Loss(pen=0)\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "transformer.load_state_dict(torch.load('AttTrack_2.pt',map_location=torch.device('cpu')))\n",
    "\n",
    "\n",
    "NUM_EPOCHS = 2\n",
    "\n",
    "loss_over_time=[]\n",
    "test_error=[]\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(transformer, optimizer,loss_fn)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(transformer,loss_fn)\n",
    "    \n",
    "    \n",
    "    loss_over_time.append(train_loss)\n",
    "    np.savetxt('./'+'train_loss_Ad2.txt', np.c_[loss_over_time],delimiter='\\t',header='trainloss')\n",
    "    \n",
    "    test_error.append(val_loss)\n",
    "                \n",
    "    np.savetxt('./'+'test_loss_Ad2.txt', np.c_[test_error],delimiter='\\t',header='testloss')\n",
    "\n",
    "    \n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "loss_over_time= np.loadtxt('./train_loss_Ad2.txt',skiprows=1, delimiter='\\t', usecols=(0), unpack=True)\n",
    "test_error= np.loadtxt('./test_loss_Ad2.txt',skiprows=1, delimiter='\\t', usecols=(0), unpack=True)\n",
    "\n",
    "\n",
    "N=1\n",
    "\n",
    "plt.plot(np.convolve(np.log10(loss_over_time), np.ones(N)/N, mode='valid'),c='red')\n",
    "plt.plot(np.convolve(np.log10(test_error), np.ones(N)/N, mode='valid'))    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import umap.umap_ as umap\n",
    "\n",
    "\n",
    "transformer.load_state_dict(torch.load('AttTrack_2.pt',map_location=torch.device('cpu')))\n",
    "transformer.eval()\n",
    "\n",
    "run=95\n",
    "t= 8\n",
    "src1, src2, y,d = collate_fn(31,-100,recon=True,train=False,run=run)\n",
    "src_padding_mask1=create_mask(src1,-100)\n",
    "src_padding_mask2=create_mask(src2,-100)\n",
    "\n",
    "\n",
    "Ad,out1,out2,out_dec1,src_t1,src_t2 = transformer(src1,src2,src_padding_mask1,src_padding_mask2)\n",
    "\n",
    "\n",
    "\n",
    "out_dec1=torch.transpose(out_dec1,2,1)\n",
    "out_dec1=torch.transpose(out_dec1,1,0)\n",
    "print(out_dec1.shape)\n",
    "\n",
    "\n",
    "src_t1=src_t1[:,t,:]#[1:]\n",
    "src_t2=src_t2[:,t,:]#[1:]\n",
    "\n",
    "ind1=np.where(src_t1 == -100)\n",
    "ind2=np.where(src_t2 == -100)\n",
    "\n",
    "a=out1.detach().numpy()\n",
    "b=out_dec1.detach().numpy()\n",
    "\n",
    "a=a[:,t,:]#[1:]\n",
    "b=b[:,t,:]#[1:]\n",
    "\n",
    "a=a[0:ind1[0][0]]\n",
    "\n",
    "b=b[0:ind2[0][0]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "blue_list=['#2a186c','#2e1f98','#1a3b9f','#0c5294','#16638d','#25738a','#328388','#3c9387','#45a383','#53b47c','#69c46f']\n",
    "red_list=['#2f0303','#6e0302','#9a0303','#c40303','#f30203','#ff1f03','#ff4a04','#fe7104','#ffa001','#fec701','#fef903']\n",
    "c_list=[]\n",
    "\n",
    "for p in range(len(a)):\n",
    "    c_list.append(blue_list[p])\n",
    "    \n",
    "for t in range(len(b)):\n",
    "    c_list.append(red_list[t])\n",
    "\n",
    "#print(c_list)\n",
    "c_list=['blue']*len(a)+['black']*len(b)\n",
    "\n",
    "#print(src_t1.shape)\n",
    "\n",
    "src=np.vstack((a,b))\n",
    "\n",
    "'''\n",
    "mnist = fetch_openml(\"mnist_784\", version=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    mnist.data, mnist.target, stratify=mnist.target, random_state=42\n",
    ")\n",
    "'''\n",
    "print(src.shape)\n",
    "reducer = umap.UMAP(metric='cosine',n_neighbors=4)\n",
    "embedding = reducer.fit_transform(src)\n",
    "#print(embedding_train,embedding_train.shape)\n",
    "#embedding_test = reducer.transform(X_test)\n",
    "print(embedding)\n",
    "plt.scatter(embedding[:, 0],embedding[:, 1],c=c_list)\n",
    "plt.gca().set_aspect('equal')\n",
    "'''[[11.102701   9.834718 ]\n",
    " [10.975245  11.376655 ]\n",
    " [11.55883   10.9941   ]\n",
    " [10.942158  10.440168 ]\n",
    " [10.304249  10.682447 ]\n",
    " [10.096922  10.017049 ]\n",
    " [10.49952   12.192604 ]\n",
    " [ 8.663966  11.4105625]\n",
    " [ 9.177266  12.255981 ]\n",
    " [ 8.936496  10.613881 ]\n",
    " [10.011719  11.911004 ]\n",
    " [ 9.29462   11.477478 ]\n",
    " [ 9.607173  10.698044 ]]'''\n",
    "\n",
    "#plt.savefig('./umap_1_12_16.png',transparent=False)\n",
    "#plt.savefig('./umap_1_12_16.png',transparent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2)\n",
    "print(src.shape)\n",
    "tsne_results = tsne.fit_transform(src)\n",
    "\n",
    "\n",
    "\n",
    "print(tsne_results)\n",
    "\n",
    "plt.scatter(tsne_results[:,0],tsne_results[:,1],c=c_list)\n",
    "plt.gca().set_aspect('equal')\n",
    "#plt.savefig('./tsne_1_12_16.png',transparent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
