{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 17:30:45.239630: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/mo/anaconda3/envs/cell/lib/python3.9/site-packages/cv2/../../../../lib:\n",
      "2023-08-17 17:30:45.239661: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/mo/anaconda3/envs/cell/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/mo/anaconda3/envs/cell/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIlEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import errno\n",
    "\n",
    "import traceback\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import deepcell\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from deepcell.datasets.tracked import hek293,nih_3t3_bench,nih_3t3,hek293_bench,hela_s3_bench,raw2647_bench\n",
    "from deepcell.datasets.cytoplasm import hela,nih_3t3,cho\n",
    "from PIL import Image\n",
    "import imageio\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "from skimage import io\n",
    "import tifffile as tiff\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from skimage.transform import resize\n",
    "from deepcell_tracking.trk_io import load_trks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ctc_2_CNet_track(path_X,suff_X,path_Y,suff_Y,start_ind,prompt='hela_ctc',alt=0,save_dir_org='/home/mo/Desktop/IWR/Cell_GT_Proj/CNet_cells_track/',test=False,step=1,specific_i=None):\n",
    "    \n",
    "    #data=[]\n",
    "    test_entries = []\n",
    "    train_entries = []\n",
    "    l_ind=start_ind\n",
    "    if specific_i is not None:\n",
    "        end=1\n",
    "    else:\n",
    "        end=350\n",
    "        \n",
    "    for i in range(end):\n",
    "        test=False\n",
    "        save_dir=save_dir_org\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            \n",
    "            ind=i+step\n",
    "            path_r_X0 = path_X + suff_X + '{:03d}'.format(ind) + '.tif'\n",
    "            path_r_Y0 = path_Y + suff_Y + '{:03d}'.format(ind) + '.tif'\n",
    "            path_r_X1 = path_X + suff_X + '{:03d}'.format(i) + '.tif'\n",
    "            path_r_Y1 = path_Y + suff_Y + '{:03d}'.format(i) + '.tif'\n",
    "            \n",
    "            if specific_i is not None:\n",
    "            \n",
    "                path_r_X0 = path_X + suff_X + '{:03d}'.format(specific_i+1) + '.tif'\n",
    "                path_r_Y0 = path_Y + suff_Y + '{:03d}'.format(specific_i+1) + '.tif'\n",
    "                path_r_X1 = path_X + suff_X + '{:03d}'.format(specific_i) + '.tif'\n",
    "                path_r_Y1 = path_Y + suff_Y + '{:03d}'.format(specific_i) + '.tif'\n",
    "              \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "            img_r_X0 = tiff.imread(path_r_X0)\n",
    "            img_r_Y0 = tiff.imread(path_r_Y0)\n",
    "            img_r_X1 = tiff.imread(path_r_X1)\n",
    "            img_r_Y1 = tiff.imread(path_r_Y1)\n",
    "\n",
    "            max_X = np.max(img_r_X0)\n",
    "            img_r_X0 = (img_r_X0/max_X)*255\n",
    "            img_r_X1 = (img_r_X1/max_X)*255\n",
    "            \n",
    "         \n",
    "\n",
    "            \n",
    "         \n",
    "            start_x = np.random.randint(0, img_r_X0.shape[1] - 512)\n",
    "            end_x = start_x + 512\n",
    "            start_y = np.random.randint(0, img_r_X0.shape[0] - 512)\n",
    "            end_y = start_y + 512\n",
    "\n",
    "            img_r_X0 = img_r_X0[start_y:end_y, start_x:end_x]\n",
    "            img_r_X1 = img_r_X1[start_y:end_y, start_x:end_x]\n",
    "            img_r_Y0 = img_r_Y0[start_y:end_y, start_x:end_x]\n",
    "            img_r_Y1 = img_r_Y1[start_y:end_y, start_x:end_x]\n",
    "\n",
    "            \n",
    "            probability = 0.1  # 10% probability\n",
    "\n",
    "            # Generate a random number between 0 and 1\n",
    "            random_number = random.random()\n",
    "\n",
    "            # Check if the random number is less than the desired probability\n",
    "            if random_number < probability:\n",
    "                test=True\n",
    "                #print('is_True',)\n",
    "                \n",
    "            if test:\n",
    "                save_dir='/home/mo/Desktop/IWR/Cell_GT_Proj/CNet_cells_track_rd/'\n",
    "                \n",
    "            \n",
    "            img_r_Y1=connect_matching_dots(img_r_Y0,img_r_Y1,path_Y,ind, img_r_X0)\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "            im0 = ax.imshow(img_r_Y0, cmap='viridis')\n",
    "            fig.colorbar(im0, ax=ax)\n",
    "            fig.canvas.draw()\n",
    "            combined_imag0 = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "            combined_imag0 = combined_imag0.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "            im1 = ax.imshow(img_r_Y1, cmap='viridis')\n",
    "            fig.colorbar(im1, ax=ax)\n",
    "            fig.canvas.draw()\n",
    "            combined_imag1 = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "            combined_imag1 = combined_imag1.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "\n",
    "            combined_imag0 = (combined_imag0 * 255).astype(np.uint8)\n",
    "            combined_imag1 = (combined_imag1 * 255).astype(np.uint8)\n",
    "            \n",
    "            j=random.randint(1, 10000)\n",
    "\n",
    "            output_path_X0 = save_dir + 'target/' + str(start_ind + i + 1)+'_'+ str(i)+ '.png'\n",
    "            output_path_Y0 = save_dir + 'source/' + str(start_ind + i + 1) +'_'+ str(i)+ '.png'\n",
    "            output_path_X1 = save_dir + 'target/' + str(start_ind + i) + '_'+ str(i)+'.png'\n",
    "            output_path_Y1 = save_dir + 'source/' + str(start_ind + i) + '_'+ str(i)+'.png'\n",
    "            \n",
    "            \n",
    "            img_r_Y1 = (img_r_Y1).astype(np.uint8)\n",
    "            \n",
    "            \n",
    "            img_r_X1,img_r_Y1=augment_images(img_r_X1, img_r_Y1, alt)\n",
    "            \n",
    "            #cv2.imwrite(output_path_Y0, combined_imag0)\n",
    "            cv2.imwrite(output_path_Y1, img_r_Y1)\n",
    "            #cv2.imwrite(output_path_X0, img_r_X0)\n",
    "            cv2.imwrite(output_path_X1, img_r_X1)\n",
    "            l_ind = l_ind + 1\n",
    "        \n",
    "    \n",
    "\n",
    "            \n",
    "\n",
    "            entry = {\n",
    "            \"source\": 'source/' + str(start_ind + i) + '_'+ str(i)+'.png',\n",
    "            \"target\": 'target/' + str(start_ind + i) + '_'+ str(i)+'.png',\n",
    "            \"prompt\": prompt\n",
    "            }\n",
    "\n",
    "            # Append the entry to the data list\n",
    "            #data.append(entry)\n",
    "            \n",
    "            if test:\n",
    "                test_entries.append(entry)\n",
    "                \n",
    "            else:\n",
    "                train_entries.append(entry)\n",
    "                \n",
    "\n",
    "            \n",
    "\n",
    "                # Write the data list as JSON to a file\n",
    "\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            if not str(e).startswith(\"[Errno 2]\"):\n",
    "                 traceback.print_exc()\n",
    "                    #print(\"An error occurred:\", str(e))\n",
    "\n",
    "    save_list=['/home/mo/Desktop/IWR/Cell_GT_Proj/CNet_cells_track/','/home/mo/Desktop/IWR/Cell_GT_Proj/CNet_cells_track_rd/']    \n",
    "    for h in range(2): \n",
    "        save_dir=save_list[h]\n",
    "        if h==0:\n",
    "            data = train_entries\n",
    "        else:\n",
    "            data = test_entries\n",
    "    \n",
    "        output_path = save_dir+\"/prompt.json\"    \n",
    "        existing_data = []\n",
    "\n",
    "\n",
    "\n",
    "        # Read existing data from the JSON file, if it exists\n",
    "        try:\n",
    "            with open(output_path, \"r\") as infile:\n",
    "                for line in infile:\n",
    "                    line = line.strip()  # Remove leading/trailing whitespaces\n",
    "                    if line:\n",
    "                        data_j = json.loads(line)\n",
    "                        existing_data.append(data_j)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "\n",
    "        #print('!!!!!!ex',existing_data)\n",
    "        #print('!!!!!!dat',data)\n",
    "        # Append new entries to the existing data\n",
    "        existing_data=existing_data+data\n",
    "        #print('!!!!!!ex2',existing_data)\n",
    "\n",
    "        # Write the updated data to the JSON file\n",
    "        with open(output_path, \"w\") as outfile:\n",
    "            for entry in existing_data:\n",
    "                #print('ent',entry)\n",
    "                json.dump(entry, outfile)\n",
    "                outfile.write('\\n') \n",
    "\n",
    "    return l_ind\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def augment_images(image_X, image_Y, alt):\n",
    "\n",
    "    # Rotate the images based on the 'alt' value\n",
    "    rotate_degrees = alt * 90  # Rotate by 90, 180, 270, or 360 degrees\n",
    "    aug = iaa.Affine(rotate=rotate_degrees)\n",
    "    augmented_images = aug(images=[image_X, image_Y])\n",
    "    \n",
    "    # Return the augmented images\n",
    "    augmented_image_X, augmented_image_Y = augmented_images\n",
    "    return augmented_image_X, augmented_image_Y\n",
    "\n",
    "\n",
    "\n",
    "def generate_similar_positions(positions,num):\n",
    "    positions = np.array(positions)\n",
    "    # Step 1: Calculate pairwise distances\n",
    "    pairwise_distances = np.linalg.norm(positions[:, None] - positions, axis=2)\n",
    "\n",
    "    # Step 2: Create an empty list for new positions\n",
    "    new_positions = []\n",
    "    \n",
    "    n_clusters=int(np.sqrt(len(positions)/2))\n",
    "    n_clusters=int(len(positions)/2)\n",
    "\n",
    "    # Step 3: Generate random distances with the same distribution\n",
    "    random_distances = np.random.choice(pairwise_distances.flatten(), size=len(positions)-1)\n",
    "\n",
    "    # Step 4: Apply KMeans clustering to the positions\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    kmeans.fit(positions)\n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "    # Step 5-11: Generate new positions\n",
    "    for random_distance in random_distances:\n",
    "        # Step 6: Randomly select two cluster centers\n",
    "        idx1, idx2 = np.random.choice(len(cluster_centers), size=2, replace=False)\n",
    "        p1, p2 = cluster_centers[idx1], cluster_centers[idx2]\n",
    "\n",
    "        # Step 7-9: Calculate displacement vector and new position\n",
    "        displacement = (p2 - p1) / np.linalg.norm(p2 - p1)\n",
    "        new_position = p1 + displacement * random_distance\n",
    "\n",
    "        # Step 10: Append new position to the list\n",
    "        new_positions.append(new_position)\n",
    "\n",
    "    # Step 11: Convert the list to numpy array\n",
    "    new_positions = np.array(new_positions)\n",
    "    \n",
    "    if num != None and len(new_positions)-num > 2:\n",
    "        #print('nn1',new_positions,num)\n",
    "        #new_positions = random.sample(new_positions, len(new_positions))\n",
    "        #print('nn2',new_positions,num)\n",
    "        new_positions=new_positions[:num]\n",
    "        \n",
    "\n",
    "    return new_positions\n",
    "\n",
    "\n",
    "def random_number():\n",
    "    if random.random() < 0.25:  # Random float:  0.0 <= x < 1.0\n",
    "        return True, random.randint(1, 6)  # Random int: 1 <= x <= 6\n",
    "    else:\n",
    "        return False, None\n",
    "\n",
    "'''\n",
    "def connect_matching_dots(img1, img2, path, t, cells, test=False,deep=False,lineage=None):\n",
    "    # Find unique pixel values in both images\n",
    "    unique_values_1 = np.unique(img1)\n",
    "    unique_values_2 = np.unique(img2)\n",
    "    \n",
    "    #print('cmd',img1.shape,img2.shape,cells.shape)\n",
    "\n",
    "    # Create an output image for dots and lines separately\n",
    "    output_img_dots = np.zeros_like(img1)\n",
    "    output_img_lines = np.zeros_like(img1)\n",
    "    output_img_splits = np.zeros_like(img1)\n",
    "\n",
    "    # Initialize 3-channel image with zeros\n",
    "    output_img_dots = np.stack((output_img_dots,)*3, axis=-1)\n",
    "    output_img_lines = np.stack((output_img_lines,)*3, axis=-1)\n",
    "    output_img_splits = np.stack((np.zeros_like(img1),)*3, axis=-1)\n",
    "\n",
    "    # Draw dots in blue\n",
    "    output_img_dots[:, :, 2] = cells  # RGB color for Blue \n",
    "\n",
    "    # Draw lines and circles in green\n",
    "    for value in unique_values_1[unique_values_1 > 0]:\n",
    "        # Find the coordinates of matching dots in both images\n",
    "        coordinates_img1 = np.argwhere(img1 == value)\n",
    "        coordinates_img2 = np.argwhere(img2 == value)\n",
    "\n",
    "        if coordinates_img2.size > 0: \n",
    "            coord1 = np.mean(coordinates_img1, axis=0, dtype=int)\n",
    "            coord2 = np.mean(coordinates_img2, axis=0, dtype=int)\n",
    "            if test:\n",
    "                coord2 = test_transform(coord1, coord2)\n",
    "            cv2.line(output_img_lines, tuple(coord1[::-1]), tuple(coord2[::-1]), color=[55, 200, 0], thickness=3)\n",
    "            cv2.circle(output_img_lines, tuple(coord2[::-1]), 8, color=[0, 255, 0], thickness=-1)  # Filled circle\n",
    "        else:\n",
    "            if deep:\n",
    "                cs = check_split_deep(path, t, value,lineage)\n",
    "            else:\n",
    "                cs = check_split(path, t, value)\n",
    "                \n",
    "            #print('cs', cs)\n",
    "            if cs[0]:\n",
    "                coordinates_img1 = np.argwhere(img1 == value)\n",
    "                coordinates_img2 = np.argwhere(img2 == cs[1])\n",
    "                if coordinates_img2.size > 0: \n",
    "                    coord1 = np.mean(coordinates_img1, axis=0, dtype=int)\n",
    "                    coord2 = np.mean(coordinates_img2, axis=0, dtype=int)\n",
    "                    \n",
    "                    cv2.line(output_img_splits, tuple(coord1[::-1]), tuple(coord2[::-1]), color=[200, 55, 0], thickness=3)\n",
    "                    cv2.circle(output_img_splits, tuple(coord2[::-1]), 8, color=[255, 0, 0], thickness=-1)  # Filled circle\n",
    "\n",
    "    # Stack images along the channel dimension: Red for splits, Green for lines, Blue for dots\n",
    "    output_img = output_img_dots + output_img_lines + output_img_splits\n",
    "    return output_img\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def connect_matching_dots(img1, img2, path, t, cells, frame,test=False, deep=False, lineage=None):\n",
    "    # Find unique pixel values and their counts in both images\n",
    "    unique_values_1, counts_1 = np.unique(img1, return_counts=True)\n",
    "    unique_values_2, counts_2 = np.unique(img2, return_counts=True)\n",
    "    counts_2_dict = dict(zip(unique_values_2, counts_2))\n",
    "    \n",
    "    # Create an output image for dots and lines separately\n",
    "    output_img_dots = np.zeros_like(img1)\n",
    "    output_img_lines = np.zeros_like(img1)\n",
    "    output_img_splits = np.zeros_like(img1)\n",
    "\n",
    "    # Initialize 3-channel image with zeros\n",
    "    output_img_dots = np.stack((output_img_dots,)*3, axis=-1)\n",
    "    output_img_lines = np.stack((output_img_lines,)*3, axis=-1)\n",
    "    output_img_splits = np.stack((np.zeros_like(img1),)*3, axis=-1)\n",
    "\n",
    "    # Draw dots in blue\n",
    "    output_img_dots[:, :, 2] = cells  \n",
    "\n",
    "    # Draw lines and circles in green\n",
    "    for value in unique_values_1[unique_values_1 > 0]:\n",
    "        # Find the coordinates of matching dots in both images\n",
    "        coordinates_img1 = np.argwhere(img1 == value)\n",
    "        coordinates_img2 = np.argwhere(img2 == value)\n",
    "\n",
    "        if coordinates_img2.size > 0: \n",
    "            \n",
    "            \n",
    "            coord1 = np.mean(coordinates_img1, axis=0, dtype=int)\n",
    "            coord2 = np.mean(coordinates_img2, axis=0, dtype=int)\n",
    "            \n",
    "            flag=check_split_timeframe(frame, value, lineage[t])\n",
    "\n",
    "            # Define the radius for this specific point\n",
    "            if value in counts_2_dict:\n",
    "                radius = int(map_value_linear(counts_2_dict[value],10, 1500, 2, 8))\n",
    "            else:\n",
    "                radius = 8  # Default radius if not in dictionary\n",
    "            \n",
    "            if test:\n",
    "                coord2 = test_transform(coord1, coord2)\n",
    "            \n",
    "            if flag==0:\n",
    "                cv2.line(output_img_lines, tuple(coord1[::-1]), tuple(coord2[::-1]), color=[55, 200, 0], thickness=3)\n",
    "                cv2.circle(output_img_lines, tuple(coord2[::-1]), radius, color=[0, 255, 0], thickness=-1) # Filled circle\n",
    "            elif flag==1:\n",
    "                cv2.line(output_img_lines, tuple(coord1[::-1]), tuple(coord2[::-1]), color=[100, 255, 0], thickness=3)\n",
    "                cv2.circle(output_img_lines, tuple(coord2[::-1]), radius, color=[255, 255, 0], thickness=-1) # Filled circle\n",
    "            elif flag==2:\n",
    "                #print('flag2',t,frame)\n",
    "                cv2.line(output_img_lines, tuple(coord1[::-1]), tuple(coord2[::-1]), color=[55, 200, 0], thickness=3)\n",
    "                cv2.circle(output_img_lines, tuple(coord2[::-1]), radius, color=[255, 255, 0], thickness=-1) # Filled \n",
    "                \n",
    "                \n",
    "           \n",
    "        else:\n",
    "            if deep:\n",
    "                cs = check_split_deep(path, t, value, lineage)\n",
    "            else:\n",
    "                cs = check_split(path, t, value)\n",
    "                \n",
    "            if cs[0]:\n",
    "                coordinates_img1 = np.argwhere(img1 == value)\n",
    "                coordinates_img2 = np.argwhere(img2 == cs[1])\n",
    "                if coordinates_img2.size > 0: \n",
    "                    coord1 = np.mean(coordinates_img1, axis=0, dtype=int)\n",
    "                    coord2 = np.mean(coordinates_img2, axis=0, dtype=int)\n",
    "                    cv2.line(output_img_splits, tuple(coord1[::-1]), tuple(coord2[::-1]), color=[200, 55, 0], thickness=3)\n",
    "                    cv2.circle(output_img_splits, tuple(coord2[::-1]), radius, color=[255, 0, 0], thickness=-1)  # Filled circle\n",
    "\n",
    "    # Stack images along the channel dimension: Red for splits, Green for lines, Blue for dots\n",
    "    output_img = output_img_dots + output_img_lines + output_img_splits\n",
    "    return output_img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def check_split(path,t,value):\n",
    "    data = np.loadtxt(path+'man_track.txt')\n",
    "\n",
    "    # Split the data into columns\n",
    "    start = data[:, 1]\n",
    "    ide = data[:, 0][start==t]\n",
    "    \n",
    "    end = data[:, 2][start==t]\n",
    "    parent = data[:, 3][start==t]\n",
    "    \n",
    "    try:\n",
    "        par = parent[ide==value]\n",
    "        print('p_t_pa_v',par,t,path,value)\n",
    "        \n",
    "        if len(ide[parent==par])==2:\n",
    "            print('ide',ide[parent==par])\n",
    "            return True,par[0]\n",
    "        else:\n",
    "            return False,0\n",
    "        \n",
    "    except:\n",
    "        return False,0\n",
    "    \n",
    "    \n",
    "def check_split_deep(path,j,value,lineage):\n",
    "    \n",
    "    par=lineage[j][value]['parent']\n",
    "    \n",
    "    if par != None:\n",
    "        #print('csd',j,value,par)\n",
    "        return True,par\n",
    "    else:\n",
    "        return False,0\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def test_transform(coord1, coord2_mean):\n",
    "    distance = np.linalg.norm(coord2_mean - coord1)\n",
    "    scale_factor = 3  # Distance scale factor\n",
    "\n",
    "    if distance > 0:\n",
    "        # Generate a random orientation\n",
    "        angle = random.uniform(0, 2 * np.pi)\n",
    "\n",
    "        # Calculate the new coordinate\n",
    "        direction = (coord2_mean - coord1) / distance\n",
    "        offset = direction * scale_factor * distance\n",
    "        offset_rotated = np.array([np.cos(angle), -np.sin(angle), np.sin(angle), np.cos(angle)]).reshape((2, 2)).dot(offset)\n",
    "        coord2 = coord2_mean + offset_rotated.astype(int)\n",
    "    else:\n",
    "        # If the distance is 0, set coord2 to coord2_mean\n",
    "        coord2 = coord2_mean\n",
    "    return coord2\n",
    "\n",
    "def deep_2_CNet_track(X,Y,lineage,start_ind,prompt='hela_ctc',alt=0,save_dir_org='/media/mo/Label/CNet_deepcell_track/',test=False,step=1,specific_i=None):\n",
    "    test_entries = []\n",
    "    train_entries = []\n",
    "    data=[]\n",
    "    l_ind=start_ind\n",
    "    if test:\n",
    "        end_j= 1\n",
    "    else:\n",
    "        end_j= X.shape[0]\n",
    "        \n",
    "    \n",
    "    for j in range(X.shape[0]):\n",
    "        for i in range(X.shape[1]-step):\n",
    "            test=False\n",
    "            save_dir=save_dir_org\n",
    "            \n",
    "            frame_X0 = X[j, i+step, :, :, :]\n",
    "            frame_X1 = X[j, i, :, :, :]\n",
    "            frame_Y0 = Y[j, i+step, :, :, :]\n",
    "            frame_Y1 = Y[j, i, :, :, :]\n",
    "            if np.mean(frame_X0) != 0:\n",
    "\n",
    "                #print('mean_j_i',j,i, np.mean(frame_X))\n",
    "                #output_path_Y_c = save_dir+'source/'+str(start_ind+i)+'contr.png'\n",
    "\n",
    "                max_X=np.max(X[j,...])\n",
    "                frame_X0 = (frame_X0/max_X)*255\n",
    "                frame_X1 = (frame_X1/max_X)*255\n",
    "                #frame_Y = (frame_Y/max_X)*255\n",
    "\n",
    "\n",
    "                #print('shape',frame_X.shape)\n",
    "                #start_x = np.random.randint(0, frame_X.shape[0] - 512)\n",
    "                start_x = 0\n",
    "                end_x = start_x + 512\n",
    "                #start_y = np.random.randint(0, frame_X.shape[1] - 512)\n",
    "                start_y=0\n",
    "                end_y = start_y + 512\n",
    "\n",
    "                # Crop the random region from img_r_X\n",
    "                img_r_X0 = np.squeeze(frame_X0[start_y:end_y, start_x:end_x])\n",
    "                img_r_X1 = np.squeeze(frame_X1[start_y:end_y, start_x:end_x])\n",
    "\n",
    "                # Crop the random region from img_r_Y\n",
    "                img_r_Y0 = np.squeeze(frame_Y0[start_y:end_y, start_x:end_x])\n",
    "                img_r_Y1 = np.squeeze(frame_Y1[start_y:end_y, start_x:end_x])\n",
    "                \n",
    "                \n",
    "                probability = 0.1  # 10% probability\n",
    "\n",
    "                # Generate a random number between 0 and 1\n",
    "                random_number = random.random()\n",
    "\n",
    "\n",
    "                \n",
    "                if random_number < probability:\n",
    "                      test=True\n",
    "                \n",
    "                # Specify the output file path\n",
    "                if test:\n",
    "                    save_dir='/media/mo/Label/CNet_deepcell_track_rd/'\n",
    "                      \n",
    "                img_r_Y1=connect_matching_dots(img_r_Y0,img_r_Y1,'None',j, img_r_X0, i+step,deep=True,lineage=lineage)\n",
    "                \n",
    "                #print('save_dir',save_dir)\n",
    "\n",
    "                output_path_X1 = save_dir + 'target/' +str(start_ind+i+1)+'_'+str(j)+'.png'\n",
    "                output_path_Y1 = save_dir + 'source/' +str(start_ind+i+1)+'_'+str(j)+'.png'\n",
    "\n",
    "\n",
    "                img_r_X1,img_r_Y1=augment_images(img_r_X1, img_r_Y1, alt)\n",
    "                \n",
    "                img_r_Y1 = (img_r_Y1).astype(np.uint8)\n",
    "                \n",
    "                \n",
    "\n",
    "                #cv2.imwrite(output_path_Y0, combined_imag0)\n",
    "                cv2.imwrite(output_path_Y1, img_r_Y1)\n",
    "                #cv2.imwrite(output_path_X0, img_r_X0)\n",
    "                cv2.imwrite(output_path_X1, img_r_X1)\n",
    "                l_ind = l_ind + 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                entry = {\n",
    "                \"source\": 'source/' + str(start_ind+i+1)+'_'+str(j)+'.png',\n",
    "                \"target\": 'target/' + str(start_ind+i+1)+'_'+str(j)+'.png',\n",
    "                \"prompt\": prompt\n",
    "                }\n",
    "\n",
    "                # Append the entry to the data list\n",
    "                #data.append(entry)\n",
    "\n",
    "                if test:\n",
    "                    test_entries.append(entry)\n",
    "\n",
    "                else:\n",
    "                    train_entries.append(entry)\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "                # Write the data list as JSON to a file\n",
    "\n",
    "\n",
    "\n",
    "      \n",
    "    save_list=['/media/mo/Label/CNet_deepcell_track/','/media/mo/Label/CNet_deepcell_track_rd/']    \n",
    "    for h in range(2): \n",
    "        save_dir=save_list[h]\n",
    "        if h==0:\n",
    "            data = train_entries\n",
    "        else:\n",
    "            data = test_entries\n",
    "    \n",
    "        output_path = save_dir+\"/prompt.json\"    \n",
    "        existing_data = []\n",
    "\n",
    "\n",
    "\n",
    "        # Read existing data from the JSON file, if it exists\n",
    "        try:\n",
    "            with open(output_path, \"r\") as infile:\n",
    "                for line in infile:\n",
    "                    line = line.strip()  # Remove leading/trailing whitespaces\n",
    "                    if line:\n",
    "                        data_j = json.loads(line)\n",
    "                        existing_data.append(data_j)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "\n",
    "        #print('!!!!!!ex',existing_data)\n",
    "        #print('!!!!!!dat',data)\n",
    "        # Append new entries to the existing data\n",
    "        existing_data=existing_data+data\n",
    "        #print('!!!!!!ex2',existing_data)\n",
    "\n",
    "        # Write the updated data to the JSON file\n",
    "        with open(output_path, \"w\") as outfile:\n",
    "            for entry in existing_data:\n",
    "                #print('ent',entry)\n",
    "                json.dump(entry, outfile)\n",
    "                outfile.write('\\n') \n",
    "\n",
    "    return l_ind\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def map_value_linear(value, in_min, in_max, out_min, out_max):\n",
    "    # Ensure the input value is within the input range\n",
    "    value = max(min(value, in_max), in_min)\n",
    "    \n",
    "    if value==in_min:\n",
    "        return 1\n",
    "    elif value== in_max:\n",
    "        return 8\n",
    "\n",
    "    # Map the value to the output range using linear interpolation\n",
    "    return int((value - in_min) * (out_max - out_min) / (in_max - in_min) + out_min)\n",
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def check_split_timeframe(t, cell_id, lineage):\n",
    "    # Loop through each cell in the lineage\n",
    "    for cell_data in lineage.values():\n",
    "        # Check if the cell_id is a daughter of the current cell\n",
    "        if cell_id in cell_data['daughters']:\n",
    "            # Calculate the difference between the current timeframe and frame_div\n",
    "            time_difference = t - cell_data['frame_div']\n",
    "            \n",
    "            # Check the conditions for flag=1 and flag=2\n",
    "            if time_difference == 2:\n",
    "                return 1\n",
    "            elif time_difference == 3:\n",
    "                return 2\n",
    "    \n",
    "    # If neither condition is met, return flag=0\n",
    "    return 0\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mstop\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "print(stop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_X = ['/home/mo/Desktop/IWR/Cell_GT_Proj/CTC_datasets/Fluo-C2DL-Huh7/01/']#,\n",
    "          #'/home/mo/Desktop/IWR/Cell_GT_Proj/CTC_datasets/Fluo-C2DL-Huh7/02/']\n",
    "suff_X = 't' \n",
    "\n",
    "\n",
    "path_Y = ['/home/mo/Desktop/IWR/Cell_GT_Proj/CTC_datasets/Fluo-C2DL-Huh7/01_GT/TRA/']#\n",
    "          #'/home/mo/Desktop/IWR/Cell_GT_Proj/CTC_datasets/Fluo-C2DL-Huh7/02_GT/TRA/']\n",
    "suff_Y='man_track'\n",
    "\n",
    "prompt_a='hela_ctc, cell, microscopy image, grayscale'\n",
    "prompt_b='fluo_ctc, cell, tracking, microscopy image, grayscale'\n",
    "\n",
    "alt=[0,1,2,3]\n",
    "steps=[1,3,5]\n",
    "l_ind=0\n",
    "split_path_0=[3]\n",
    "split_path_1=[23,17,25,14,26]\n",
    "\n",
    "for g in range(4):\n",
    "    for k in range(len(path_X)):\n",
    "        for q in steps:\n",
    "            for h in range(len(alt)):\n",
    "                if k < 2:\n",
    "                    prompt_ctc=prompt_a\n",
    "                else:\n",
    "                    prompt_ctc=prompt_b\n",
    "                l_ind=ctc_2_CNet_track(path_X[k],suff_X,path_Y[k],suff_Y,start_ind=l_ind,prompt=prompt_b,alt=alt[h],step=q)\n",
    "            #print(l_ind)\n",
    "\n",
    "\n",
    "        if k==0:\n",
    "            split_i=split_path_0\n",
    "        else:\n",
    "            split_i=split_path_1\n",
    "\n",
    "        for t in split_i:\n",
    "            l_ind=ctc_2_CNet_track(path_X[k],suff_X,path_Y[k],suff_Y,start_ind=l_ind,prompt=prompt_b,alt=alt[h],specific_i=t)\n",
    "\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'label': 1, 'frames': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], 'daughters': [], 'capped': False, 'frame_div': None, 'parent': None}, 2: {'label': 2, 'frames': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], 'daughters': [], 'capped': False, 'frame_div': None, 'parent': None}, 3: {'label': 3, 'frames': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], 'daughters': [], 'capped': False, 'frame_div': None, 'parent': None}, 4: {'label': 4, 'frames': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], 'daughters': [], 'capped': False, 'frame_div': None, 'parent': None}, 5: {'label': 5, 'frames': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], 'daughters': [], 'capped': False, 'frame_div': None, 'parent': None}, 6: {'label': 6, 'frames': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], 'daughters': [], 'capped': False, 'frame_div': None, 'parent': None}, 7: {'label': 7, 'frames': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], 'daughters': [], 'capped': False, 'frame_div': None, 'parent': None}, 8: {'label': 8, 'frames': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], 'daughters': [], 'capped': False, 'frame_div': None, 'parent': None}, 9: {'label': 9, 'frames': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], 'daughters': [29, 30], 'capped': False, 'frame_div': 28, 'parent': None}, 10: {'label': 10, 'frames': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], 'daughters': [], 'capped': False, 'frame_div': None, 'parent': None}, 11: {'label': 11, 'frames': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], 'daughters': [], 'capped': False, 'frame_div': None, 'parent': None}, 12: {'label': 12, 'frames': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], 'daughters': [], 'capped': False, 'frame_div': None, 'parent': None}, 13: {'label': 13, 'frames': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], 'daughters': [], 'capped': False, 'frame_div': None, 'parent': None}, 14: {'label': 14, 'frames': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], 'daughters': [], 'capped': False, 'frame_div': None, 'parent': None}, 15: {'label': 15, 'frames': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], 'daughters': [], 'capped': False, 'frame_div': None, 'parent': None}, 16: {'label': 16, 'frames': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], 'daughters': [], 'capped': False, 'frame_div': None, 'parent': None}, 17: {'label': 17, 'frames': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], 'daughters': [], 'capped': False, 'frame_div': None, 'parent': None}, 18: {'label': 18, 'frames': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], 'daughters': [], 'capped': False, 'frame_div': None, 'parent': None}, 19: {'label': 19, 'frames': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], 'daughters': [], 'capped': False, 'frame_div': None, 'parent': None}, 20: {'label': 20, 'frames': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], 'daughters': [], 'capped': False, 'frame_div': None, 'parent': None}, 21: {'label': 21, 'frames': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], 'daughters': [31, 32], 'capped': False, 'frame_div': 34, 'parent': None}, 22: {'label': 22, 'frames': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], 'daughters': [], 'capped': False, 'frame_div': None, 'parent': None}, 23: {'label': 23, 'frames': [0, 1, 2, 3, 4], 'daughters': [], 'capped': False, 'frame_div': None, 'parent': None}, 24: {'label': 24, 'frames': [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], 'daughters': [], 'capped': False, 'frame_div': None, 'parent': None}, 25: {'label': 25, 'frames': [18, 19, 20, 21], 'daughters': [], 'capped': False, 'frame_div': None, 'parent': None}, 26: {'label': 26, 'frames': [21, 22, 23, 24, 25], 'daughters': [27], 'capped': False, 'frame_div': 25, 'parent': None}, 27: {'label': 27, 'frames': [26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], 'daughters': [], 'capped': False, 'frame_div': None, 'parent': 26}, 28: {'label': 28, 'frames': [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], 'daughters': [], 'capped': False, 'frame_div': None, 'parent': None}, 29: {'label': 29, 'frames': [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], 'daughters': [], 'capped': False, 'frame_div': None, 'parent': 9}, 30: {'label': 30, 'frames': [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], 'daughters': [], 'capped': False, 'frame_div': None, 'parent': 9}, 31: {'label': 31, 'frames': [35, 36, 37, 38, 39, 40, 41], 'daughters': [], 'capped': False, 'frame_div': None, 'parent': 21}, 32: {'label': 32, 'frames': [35, 36, 37, 38, 39, 40, 41], 'daughters': [], 'capped': False, 'frame_div': None, 'parent': 21}, 33: {'label': 33, 'frames': [39, 40, 41], 'daughters': [], 'capped': False, 'frame_div': None, 'parent': None}}\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/media/mo/Label/DynamicNuclearNet-tracking-v1_0/'\n",
    "data = load_trks(os.path.join(data_dir, 'test.trks'))\n",
    "\n",
    "X = data['X']\n",
    "Y = data['y']\n",
    "lineages = data['lineages']\n",
    "print(lineages[0])\n",
    "prompt='cell, microscopy, image'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 8, 'frames': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], 'daughters': [], 'capped': False, 'frame_div': None, 'parent': None}\n"
     ]
    }
   ],
   "source": [
    "print(lineages[0][8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!! 1 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "alt=[0,1,2,3]\n",
    "#alt=[0]\n",
    "steps=[1]\n",
    "l_ind=0\n",
    "for q in steps:\n",
    "    for h in range(len(alt)):\n",
    "        print('!!!!!!!!!!!!!!!!!!!!!!!!',q,h)\n",
    "        l_ind=deep_2_CNet_track(X,Y,lineages,start_ind=l_ind,prompt=prompt,alt=alt[h],step=q)\n",
    "            #print(l_ind)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#deep_2_CNet_track(X,Y,lineages,start_ind=0,prompt=prompt,alt=0)\n",
    "\n",
    "\n",
    "#alt=[0,1,2,3]\n",
    "\n",
    "#l_ind=0\n",
    "#for h in range(len(alt)):\n",
    "#    l_ind=deep_2_CNet(X,y,start_ind=l_ind,prompt=prompt,alt=alt[h])\n",
    "#    print(l_ind)\n",
    "        \n",
    "        \n",
    "#l_ind=0\n",
    "#for h in range(len(alt)):\n",
    "#    l_ind=deep_2_CNet(X,y,start_ind=l_ind,prompt=prompt,alt=alt[h],test=True)\n",
    "#    print(l_ind)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the image folder\n",
    "image_folder = \"/home/mo/Desktop/IWR/Cell_GT_Proj/image_log/val\"\n",
    "\n",
    "# Create a new folder for the combined images\n",
    "output_folder = \"/home/mo/Desktop/IWR/Cell_GT_Proj/image_log/assembled_val\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Get a list of all image files in the folder\n",
    "image_files = [filename for filename in os.listdir(image_folder) if filename.endswith(\".png\")]\n",
    "\n",
    "# Process each set of corresponding images\n",
    "for image_file in image_files:\n",
    "    # Extract the common identifier from the image filename\n",
    "    identifier = image_file.split(\"_gs-\", 1)[1].split(\".\")[0]\n",
    "\n",
    "    # Construct the filenames of the three corresponding images\n",
    "    samples_file = os.path.join(image_folder, f\"samples_cfg_scale_9.00_gs-{identifier}.png\")\n",
    "    reconstruction_file = os.path.join(image_folder, f\"reconstruction_gs-{identifier}.png\")\n",
    "    control_file = os.path.join(image_folder, f\"control_gs-{identifier}.png\")\n",
    "\n",
    "    # Open the images\n",
    "    samples_image = Image.open(samples_file)\n",
    "    reconstruction_image = Image.open(reconstruction_file)\n",
    "    control_image = Image.open(control_file)\n",
    "\n",
    "    # Resize the images by half\n",
    "    new_size = (samples_image.width // 2, samples_image.height // 2)\n",
    "    samples_image = samples_image.resize(new_size)\n",
    "    reconstruction_image = reconstruction_image.resize(new_size)\n",
    "    control_image = control_image.resize(new_size)\n",
    "\n",
    "    # Create a new image with the combined images\n",
    "    combined_image = Image.new(\"RGB\", (new_size[0], new_size[1] * 2))\n",
    "    combined_image.paste(samples_image, (0, 0))\n",
    "    #combined_image.paste(reconstruction_image, (0, new_size[1]))\n",
    "    combined_image.paste(control_image, (0, new_size[1]))\n",
    "\n",
    "    # Save the combined image in the output folder\n",
    "    output_file = os.path.join(output_folder, f\"combined_{identifier}.png\")\n",
    "    combined_image.save(output_file)\n",
    "\n",
    "    # Print the saved file path\n",
    "    print(f\"Combined image saved: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
